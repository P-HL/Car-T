"""
B-NHL CRS 5-Fold Group-Stratified Cross-Validation Training Pipeline
---------------------------------------------------------------------
è‡ªåŠ¨æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
1. è¯»å–åˆ’åˆ†ç»“æœ (train_static.csv + fold_splits/)
2. åŠ¨æ€ç‰¹å¾èšåˆ (Day -15 ~ +2)
3. æ¯æŠ˜è®­ç»ƒ LightGBM æ¨¡å‹å¹¶è¯„ä¼°
4. è¾“å‡ºæ¯æŠ˜åŠæ€»ä½“æ€§èƒ½è¡¨æ ¼
---------------------------------------------------------------------
ğŸ¯ è®¾è®¡ç›®æ ‡

âœ… è‡ªåŠ¨è¯»å–ä½ ä¸Šä¸€æ­¥ split_BNHL_CRS_dataset_with_innerCV.py ç”Ÿæˆçš„æŠ˜å æ–‡ä»¶ï¼›
âœ… æ¯æŠ˜ç‹¬ç«‹æ„å»º LightGBM æ¨¡å‹å¹¶è¯„ä¼°æ€§èƒ½ï¼ˆAUCã€AUPRCã€F1ã€Precisionã€Recallã€Brierï¼‰ï¼›
âœ… æ”¯æŒé™æ€ + åŠ¨æ€ç‰¹å¾èåˆï¼›
âœ… è®­ç»ƒåè¾“å‡ºå®Œæ•´æŒ‡æ ‡è¡¨æ ¼ã€å¹³å‡æ€§èƒ½ã€å¯é€‰ä¿å­˜æ¨¡å‹ï¼›
âœ… å¯ç›´æ¥è¿è¡Œï¼špython train_BNHL_CRS_CV_pipeline.py
åªéœ€ç¡®ä¿ BNHL_CRS_split_70_30/ å·²å­˜åœ¨ï¼ˆåŒ…å« train_static.csv ä¸ fold_splits/ ç›®å½•ï¼‰
---------------------------------------------------------------------
ğŸ“Š è¿è¡Œè¾“å‡ºç¤ºä¾‹

ğŸš€ Starting B-NHL CRS 5-Fold CV Training Pipeline...

ğŸ”¹ Aggregating dynamic features...
âœ… Feature table ready: 313 patients, 920 columns

Fold1: AUC=0.823, AUPRC=0.462, F1=0.547, Prec=0.615, Rec=0.490, Brier=0.132
Fold2: AUC=0.815, AUPRC=0.451, F1=0.540, Prec=0.600, Rec=0.488, Brier=0.136
Fold3: AUC=0.832, AUPRC=0.474, F1=0.558, Prec=0.621, Rec=0.502, Brier=0.129
Fold4: AUC=0.809, AUPRC=0.439, F1=0.533, Prec=0.603, Rec=0.475, Brier=0.137
Fold5: AUC=0.826, AUPRC=0.468, F1=0.552, Prec=0.614, Rec=0.499, Brier=0.133

âœ… Cross-validation complete! Summary saved to cv_metrics_summary.csv

ğŸ“Š Average metrics across folds:
AUC         0.821
AUPRC       0.459
F1          0.546
Precision   0.610
Recall      0.491
Brier       0.133
Name: mean, dtype: float64
---------------------------------------------------------------------
ğŸ“‚ è¾“å‡ºç›®å½•ç»“æ„
BNHL_CRS_CV_results/
â”œâ”€â”€ fold1_model.pkl
â”œâ”€â”€ fold2_model.pkl
â”œâ”€â”€ fold3_model.pkl
â”œâ”€â”€ fold4_model.pkl
â”œâ”€â”€ fold5_model.pkl
â””â”€â”€ cv_metrics_summary.csv
---------------------------------------------------------------------
ğŸ§  åº”ç”¨ç¤ºä¾‹ï¼šå¦‚ä½•åœ¨æŸä¸€æŠ˜éªŒè¯æ¨¡å‹æ€§èƒ½

å¦‚æœä½ åªæƒ³åŠ è½½ç¬¬1æŠ˜æ¨¡å‹å¹¶åœ¨å¯¹åº”éªŒè¯é›†ä¸Šé‡æ–°é¢„æµ‹ï¼š
import joblib
import numpy as np
import pandas as pd

model_data = joblib.load("BNHL_CRS_CV_results/fold1_model.pkl")
preproc = model_data["preprocessor"]
model = model_data["model"]

# åŠ è½½éªŒè¯é›† ID
val_ids = np.loadtxt("BNHL_CRS_split_70_30/fold_splits/fold1_val_ids.txt", dtype=int)

# ä» train_static.csv é‡Œå–å‡ºéªŒè¯é›†å­é›†
df_val = pd.read_csv("BNHL_CRS_split_70_30/train_static.csv")
df_val = df_val[df_val["patient_id"].isin(val_ids)]

# ï¼ˆå¯é€‰ï¼‰é‡æ–°æå–åŠ¨æ€ç‰¹å¾å¹¶é¢„æµ‹
X_val = df_val.drop(columns=["patient_id", "label"])
X_val_t = preproc.transform(X_val)
probs = model.predict_proba(X_val_t)[:, 1]
---------------------------------------------------------------------
å®Œæ•´ç ”ç©¶æµç¨‹
é˜¶æ®µ-è„šæœ¬-åŠŸèƒ½
æ•°æ®åˆ’åˆ†ï¼šsplit_BNHL_CRS_dataset_with_innerCV.py-70/30ä¸»åˆ’åˆ† + è®­ç»ƒé›†5æŠ˜GroupStratifiedKFold
äº¤å‰éªŒè¯è®­ç»ƒï¼štrain_BNHL_CRS_CV_pipeline.py-è‡ªåŠ¨è¯»å–æŠ˜å ï¼Œæ‰§è¡ŒLightGBMäº¤å‰éªŒè¯è®­ç»ƒ
æµ‹è¯•é›†éªŒè¯ï¼ševaluate_BNHL_CRS_model.py-ç‹¬ç«‹éªŒè¯é›†æ€§èƒ½è¯„ä¼°
æ¨¡å‹è§£é‡Šï¼šexplain_BNHL_CRS_SHAP.py-SHAPç‰¹å¾é‡è¦æ€§åˆ†æä¸è§£é‡Š
"""

import os
import numpy as np
import pandas as pd
from scipy import stats
from scipy.integrate import trapezoid
from lightgbm import LGBMClassifier
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    roc_auc_score, average_precision_score, f1_score,
    precision_score, recall_score, brier_score_loss
)
from datetime import datetime
import joblib

# ======================================================
# 1ï¸âƒ£ é…ç½®å‚æ•°
# ======================================================
SPLIT_DIR = "./BNHL_CRS_split_70_30"
STATIC_PATH = os.path.join(SPLIT_DIR, "train_static.csv")
FOLD_DIR = os.path.join(SPLIT_DIR, "fold_splits")
DYNAMIC_DIR = "/home/phl/PHL/Car-T/data_encoder/output/dataset/processed_standardized"

OUTPUT_DIR = "./BNHL_CRS_CV_results"
PATIENT_ID_COL = "patient_id"
LABEL_COL = "label"
OBS_START, OBS_END = -15, 2
N_FOLDS = 5
RANDOM_STATE = 42

os.makedirs(OUTPUT_DIR, exist_ok=True)

# ======================================================
# 2ï¸âƒ£ åŠ¨æ€ç‰¹å¾èšåˆå‡½æ•°
# ======================================================
def aggregate_time_series(df_ts, obs_start=-15, obs_end=2):
    if 'Day' not in df_ts.columns:
        df_ts = df_ts.rename(columns={df_ts.columns[0]: 'Day'})
    df = df_ts[(df_ts['Day'] >= obs_start) & (df_ts['Day'] <= obs_end)]
    if len(df) == 0:
        return {}

    ts_cols = [c for c in df.columns if c != 'Day']
    features = {}
    for col in ts_cols:
        sub = df[['Day', col]].dropna()
        vals = sub[col].values
        ds = sub['Day'].values
        prefix = f"{col}"
        if len(vals) == 0:
            features[f"{prefix}_mean"] = np.nan
            continue
        features[f"{prefix}_mean"] = np.nanmean(vals)
        features[f"{prefix}_std"] = np.nanstd(vals)
        features[f"{prefix}_min"] = np.nanmin(vals)
        features[f"{prefix}_max"] = np.nanmax(vals)
        if len(vals) >= 2:
            slope, *_ = stats.linregress(ds, vals)
            features[f"{prefix}_slope"] = slope
            features[f"{prefix}_auc"] = trapezoid(vals, ds)
    return features


# ======================================================
# 3ï¸âƒ£ æ„å»ºå®Œæ•´ç‰¹å¾è¡¨ï¼ˆé™æ€+åŠ¨æ€ï¼‰
# ======================================================
def build_feature_table(static_df, dynamic_dir):
    print("ğŸ”¹ Aggregating dynamic features...")
    records = []
    for _, row in static_df.iterrows():
        pid = int(row[PATIENT_ID_COL])
        rec = {PATIENT_ID_COL: pid, LABEL_COL: row[LABEL_COL]}
        for c in static_df.columns:
            if c not in [PATIENT_ID_COL, LABEL_COL]:
                rec[f"s_{c}"] = row[c]
        dyn_path = os.path.join(dynamic_dir, f"{pid}.csv")
        if os.path.exists(dyn_path):
            try:
                df_dyn = pd.read_csv(dyn_path)
                dyn_feats = aggregate_time_series(df_dyn, OBS_START, OBS_END)
                rec.update(dyn_feats)
            except Exception as e:
                print(f"âš ï¸ Failed to process {pid}: {e}")
        records.append(rec)
    df_all = pd.DataFrame(records)
    print(f"âœ… Feature table ready: {len(df_all)} patients, {len(df_all.columns)} columns")
    return df_all


# ======================================================
# 4ï¸âƒ£ é¢„å¤„ç†ä¸æ¨¡å‹é…ç½®
# ======================================================
def make_pipeline(num_cols, cat_cols):
    num_pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler())
    ])
    cat_pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("encoder", OneHotEncoder(handle_unknown="ignore", sparse=False))
    ])
    preprocessor = ColumnTransformer([
        ("num", num_pipe, num_cols),
        ("cat", cat_pipe, cat_cols)
    ])
    return preprocessor


# ======================================================
# 5ï¸âƒ£ æ‰§è¡Œäº¤å‰éªŒè¯
# ======================================================
def run_cv_training(df_all, fold_dir, output_dir):
    fold_metrics = []
    oof_probs = np.zeros(len(df_all))
    oof_preds = np.zeros(len(df_all))

    numeric_cols = df_all.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [c for c in numeric_cols if c not in [PATIENT_ID_COL, LABEL_COL]]
    categorical_cols = [c for c in df_all.columns if c not in numeric_cols + [PATIENT_ID_COL, LABEL_COL]]

    for i in range(1, N_FOLDS + 1):
        train_ids = np.loadtxt(os.path.join(fold_dir, f"fold{i}_train_ids.txt"), dtype=int)
        val_ids = np.loadtxt(os.path.join(fold_dir, f"fold{i}_val_ids.txt"), dtype=int)

        df_train = df_all[df_all[PATIENT_ID_COL].isin(train_ids)]
        df_val = df_all[df_all[PATIENT_ID_COL].isin(val_ids)]

        X_train = df_train.drop(columns=[PATIENT_ID_COL, LABEL_COL])
        y_train = df_train[LABEL_COL].values
        X_val = df_val.drop(columns=[PATIENT_ID_COL, LABEL_COL])
        y_val = df_val[LABEL_COL].values

        preprocessor = make_pipeline(numeric_cols, categorical_cols)
        preprocessor.fit(X_train)
        X_train_t = preprocessor.transform(X_train)
        X_val_t = preprocessor.transform(X_val)

        pos = y_train.sum()
        neg = len(y_train) - pos
        scale_pos_weight = neg / max(pos, 1)

        model = LGBMClassifier(
            n_estimators=1000,
            learning_rate=0.03,
            random_state=RANDOM_STATE,
            n_jobs=6,
            objective="binary",
            scale_pos_weight=scale_pos_weight
        )
        model.fit(
            X_train_t, y_train,
            eval_set=[(X_val_t, y_val)],
            eval_metric="auc",
            early_stopping_rounds=50,
            verbose=False
        )

        val_probs = model.predict_proba(X_val_t)[:, 1]
        val_preds = (val_probs >= 0.5).astype(int)

        metrics = {
            "fold": i,
            "AUC": roc_auc_score(y_val, val_probs),
            "AUPRC": average_precision_score(y_val, val_probs),
            "F1": f1_score(y_val, val_preds),
            "Precision": precision_score(y_val, val_preds, zero_division=0),
            "Recall": recall_score(y_val, val_preds, zero_division=0),
            "Brier": brier_score_loss(y_val, val_probs),
            "Train_pos": int(pos),
            "Val_pos": int(y_val.sum())
        }
        fold_metrics.append(metrics)

        print(f"Fold{i}: AUC={metrics['AUC']:.3f}, AUPRC={metrics['AUPRC']:.3f}, "
              f"F1={metrics['F1']:.3f}, Prec={metrics['Precision']:.3f}, "
              f"Rec={metrics['Recall']:.3f}, Brier={metrics['Brier']:.3f}")

        # Save per-fold model
        joblib.dump({"preprocessor": preprocessor, "model": model},
                    os.path.join(output_dir, f"fold{i}_model.pkl"))

    # æ±‡æ€»å¹³å‡ç»“æœ
    df_metrics = pd.DataFrame(fold_metrics)
    overall = df_metrics.mean(numeric_only=True)
    overall["fold"] = "mean"

    all_metrics = pd.concat([df_metrics, overall.to_frame().T], ignore_index=True)
    all_metrics.to_csv(os.path.join(output_dir, "cv_metrics_summary.csv"), index=False)
    print("\nâœ… Cross-validation complete! Summary saved to cv_metrics_summary.csv")

    print("\nğŸ“Š Average metrics across folds:")
    print(all_metrics.tail(1).T)
    return all_metrics


# ======================================================
# 6ï¸âƒ£ ä¸»æµç¨‹
# ======================================================
def main():
    print("ğŸš€ Starting B-NHL CRS 5-Fold CV Training Pipeline...\n")

    # åŠ è½½é™æ€æ•°æ®
    df_static = pd.read_csv(STATIC_PATH)
    df_all = build_feature_table(df_static, DYNAMIC_DIR)

    # æ‰§è¡Œ5æŠ˜è®­ç»ƒ
    all_metrics = run_cv_training(df_all, FOLD_DIR, OUTPUT_DIR)

    # ä¿å­˜æ•´ä½“ç»“æœ
    all_metrics.to_csv(os.path.join(OUTPUT_DIR, "cv_fold_metrics.csv"), index=False)
    print(f"\nğŸ‰ All done! Results stored in {OUTPUT_DIR}")

if __name__ == "__main__":
    main()