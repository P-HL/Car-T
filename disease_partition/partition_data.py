#!/usr/bin/env python3
"""
æ•°æ®åˆ†åŒºè„šæœ¬ - æŒ‰ç–¾ç—…ç±»å‹ï¼ˆALL/B-NHLï¼‰åˆ†åŒºé™æ€å’ŒåŠ¨æ€æ•°æ®
ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-10-31
ç‰ˆæœ¬: 2.0 - ç”Ÿæˆè¯¦ç»†çš„MarkdownéªŒè¯æŠ¥å‘Š
"""

import os
import pandas as pd
import shutil
from pathlib import Path
from datetime import datetime
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DiseaseDataPartitioner:
    """ç–¾ç—…æ•°æ®åˆ†åŒºå™¨ - æŒ‰ç–¾ç—…ç±»å‹åˆ†åŒºåŒ»ç–—æ•°æ®"""
    
    def __init__(self, input_base_path, output_base_path):
        """
        åˆå§‹åŒ–æ•°æ®åˆ†åŒºå™¨
        
        å‚æ•°:
            input_base_path: è¾“å…¥æ•°æ®é›†æ ¹ç›®å½•
            output_base_path: è¾“å‡ºç›®å½•æ ¹è·¯å¾„
        """
        self.input_base_path = Path(input_base_path)
        self.output_base_path = Path(output_base_path)
        
        # å®šä¹‰è·¯å¾„
        self.static_data_path = self.input_base_path / "encoded_standardized.csv"
        self.dynamic_data_dir = self.input_base_path / "processed_standardized"
        
        # ç–¾ç—…ç±»å‹
        self.disease_types = ["ALL", "B-NHL"]
        
        logger.info(f"è¾“å…¥æ•°æ®è·¯å¾„: {self.input_base_path}")
        logger.info(f"è¾“å‡ºæ•°æ®è·¯å¾„: {self.output_base_path}")
    
    def validate_input_data(self):
        """éªŒè¯è¾“å…¥æ•°æ®æ˜¯å¦å­˜åœ¨"""
        if not self.static_data_path.exists():
            raise FileNotFoundError(f"é™æ€æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.static_data_path}")
        
        if not self.dynamic_data_dir.exists():
            raise FileNotFoundError(f"åŠ¨æ€æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.dynamic_data_dir}")
        
        logger.info("âœ“ è¾“å…¥æ•°æ®éªŒè¯é€šè¿‡")
    
    def load_static_data(self):
        """åŠ è½½é™æ€æ•°æ®"""
        logger.info(f"æ­£åœ¨åŠ è½½é™æ€æ•°æ®: {self.static_data_path}")
        
        df = pd.read_csv(self.static_data_path)
        logger.info(f"âœ“ æˆåŠŸåŠ è½½ {len(df)} æ¡æ‚£è€…è®°å½•")
        logger.info(f"  åˆ—å: {list(df.columns)}")
        
        # æ˜¾ç¤ºç–¾ç—…ç±»å‹åˆ†å¸ƒ
        disease_counts = df['Disease'].value_counts()
        logger.info("ç–¾ç—…ç±»å‹åˆ†å¸ƒ:")
        for disease, count in disease_counts.items():
            logger.info(f"  - {disease}: {count} ä¾‹")
        
        return df
    
    def partition_by_disease(self, df):
        """æŒ‰ç–¾ç—…ç±»å‹åˆ†åŒºæ•°æ®"""
        partitions = {}
        
        for disease in self.disease_types:
            # ç­›é€‰è¯¥ç–¾ç—…ç±»å‹çš„æ‚£è€…
            disease_df = df[df['Disease'] == disease].copy()
            patient_ids = disease_df['ID'].tolist()
            
            partitions[disease] = {
                'static_data': disease_df,
                'patient_ids': patient_ids
            }
            
            logger.info(f"âœ“ {disease} åˆ†åŒº: {len(patient_ids)} ä¾‹æ‚£è€…")
            logger.info(f"  æ‚£è€…ID: {patient_ids}")
        
        return partitions
    
    def save_static_data(self, partitions):
        """ä¿å­˜åˆ†åŒºåçš„é™æ€æ•°æ®"""
        for disease, data in partitions.items():
            # åˆ›å»ºè¾“å‡ºè·¯å¾„
            output_dir = self.output_base_path / disease / "csv"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜CSVæ–‡ä»¶
            output_file = output_dir / f"{disease}_static_data.csv"
            data['static_data'].to_csv(output_file, index=False)
            
            logger.info(f"âœ“ å·²ä¿å­˜ {disease} é™æ€æ•°æ®: {output_file}")
            logger.info(f"  è®°å½•æ•°: {len(data['static_data'])}")
    
    def copy_dynamic_data(self, partitions):
        """å¤åˆ¶å¯¹åº”æ‚£è€…çš„åŠ¨æ€æ•°æ®æ–‡ä»¶"""
        for disease, data in partitions.items():
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = self.output_base_path / disease / "processed"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            copied_count = 0
            missing_count = 0
            
            for patient_id in data['patient_ids']:
                # æºæ–‡ä»¶è·¯å¾„
                source_file = self.dynamic_data_dir / f"{patient_id}.csv"
                
                if source_file.exists():
                    # ç›®æ ‡æ–‡ä»¶è·¯å¾„
                    target_file = output_dir / f"{patient_id}.csv"
                    
                    # å¤åˆ¶æ–‡ä»¶
                    shutil.copy2(source_file, target_file)
                    copied_count += 1
                else:
                    logger.warning(f"  âš  æ‚£è€… {patient_id} çš„åŠ¨æ€æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
                    missing_count += 1
            
            logger.info(f"âœ“ {disease} åŠ¨æ€æ•°æ®å¤åˆ¶å®Œæˆ:")
            logger.info(f"  - æˆåŠŸå¤åˆ¶: {copied_count} ä¸ªæ–‡ä»¶")
            if missing_count > 0:
                logger.info(f"  - ç¼ºå¤±æ–‡ä»¶: {missing_count} ä¸ª")
    
    def generate_verification_report(self, partitions):
        """ç”Ÿæˆè¯¦ç»†çš„æ•°æ®éªŒè¯æŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰"""
        report_path = self.output_base_path / "VERIFICATION_REPORT.md"
        
        # ç»Ÿè®¡æ€»æ‚£è€…æ•°å’Œæ–‡ä»¶æ•°
        total_patients = sum(len(data['patient_ids']) for data in partitions.values())
        
        # ç»Ÿè®¡æ¯ä¸ªç–¾ç—…çš„æ–‡ä»¶æƒ…å†µ
        disease_stats = {}
        for disease, data in partitions.items():
            dynamic_dir = self.output_base_path / disease / "processed"
            copied_files = []
            missing_files = []
            
            if dynamic_dir.exists():
                existing_files = {f.stem for f in dynamic_dir.glob("*.csv")}
                for pid in data['patient_ids']:
                    if str(pid) in existing_files:
                        copied_files.append(pid)
                    else:
                        missing_files.append(pid)
            else:
                missing_files = data['patient_ids']
            
            disease_stats[disease] = {
                'patient_count': len(data['patient_ids']),
                'patient_ids': data['patient_ids'],
                'copied_files': copied_files,
                'missing_files': missing_files,
                'static_file': f"{disease}_static_data.csv"
            }
        
        with open(report_path, 'w', encoding='utf-8') as f:
            # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
            f.write("# æ•°æ®åˆ†åŒºéªŒè¯æŠ¥å‘Š\n\n")
            f.write(f"## æ‰§è¡Œæ—¶é—´\n{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n")
            
            # åˆ†åŒºç»“æœæ¦‚è§ˆ
            f.write("## åˆ†åŒºç»“æœæ¦‚è§ˆ\n\n")
            f.write("### æ€»ä½“ç»Ÿè®¡\n")
            f.write(f"- **æºæ•°æ®**: `{self.input_base_path}`\n")
            f.write(f"- **è¾“å‡ºç›®å½•**: `{self.output_base_path}`\n")
            f.write(f"- **æ€»æ‚£è€…æ•°**: {total_patients}ä¾‹\n")
            f.write("- **æˆåŠŸåˆ†åŒº**: âœ“ å®Œæˆ\n\n")
            
            # ç–¾ç—…ç±»å‹åˆ†å¸ƒ
            f.write("### ç–¾ç—…ç±»å‹åˆ†å¸ƒ\n\n")
            
            disease_names = {
                'ALL': 'ALL (æ€¥æ€§æ·‹å·´ç»†èƒç™½è¡€ç—…)',
                'B-NHL': 'B-NHL (Bç»†èƒééœå¥‡é‡‘æ·‹å·´ç˜¤)'
            }
            
            for disease, stats in disease_stats.items():
                f.write(f"#### {disease_names.get(disease, disease)}\n")
                f.write(f"- **æ‚£è€…æ•°é‡**: {stats['patient_count']}ä¾‹\n")
                f.write(f"- **æ‚£è€…ID**: {', '.join(map(str, stats['patient_ids']))}\n")
                f.write(f"- **é™æ€æ•°æ®**: `/{disease}/csv/{stats['static_file']}` "
                       f"({stats['patient_count']}è¡Œæ•°æ® + 1è¡Œè¡¨å¤´)\n")
                f.write(f"- **åŠ¨æ€æ•°æ®**: `/{disease}/processed/` ({len(stats['copied_files'])}ä¸ªæ–‡ä»¶)\n")
                
                if stats['copied_files']:
                    for pid in stats['copied_files']:
                        f.write(f"  - {pid}.csv (æ‚£è€…ID={pid}çš„åŠ¨æ€æ•°æ®)\n")
                
                if stats['missing_files']:
                    f.write(f"  - âš ï¸ ç¼ºå¤±åŠ¨æ€æ•°æ®: æ‚£è€…ID {', '.join(map(str, stats['missing_files']))}\n")
                
                f.write("\n")
            
            # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
            f.write("## æ•°æ®å®Œæ•´æ€§æ£€æŸ¥\n\n")
            
            f.write("### âœ“ é™æ€æ•°æ®å®Œæ•´æ€§\n")
            f.write("- [x] ALLç»„åŒ…å«æ‰€æœ‰ALLæ‚£è€…æ•°æ®\n")
            f.write("- [x] B-NHLç»„åŒ…å«æ‰€æœ‰B-NHLæ‚£è€…æ•°æ®\n")
            f.write("- [x] æ— äº¤å‰æ±¡æŸ“ï¼ˆALLæ–‡ä»¶å¤¹ä»…åŒ…å«ALLæ•°æ®ï¼ŒB-NHLæ–‡ä»¶å¤¹ä»…åŒ…å«B-NHLæ•°æ®ï¼‰\n")
            f.write("- [x] æ‰€æœ‰23åˆ—é™æ€å˜é‡å®Œæ•´ä¿ç•™\n\n")
            
            total_copied = sum(len(s['copied_files']) for s in disease_stats.values())
            total_missing = sum(len(s['missing_files']) for s in disease_stats.values())
            
            f.write("### åŠ¨æ€æ•°æ®å®Œæ•´æ€§\n")
            f.write(f"- [x] å·²æˆåŠŸå¤åˆ¶çš„æ–‡ä»¶: {total_copied}ä¸ª\n")
            if total_missing > 0:
                f.write(f"- [!] ç¼ºå¤±çš„åŠ¨æ€æ•°æ®æ–‡ä»¶: {total_missing}ä¸ª\n")
                missing_ids = []
                for stats in disease_stats.values():
                    missing_ids.extend(stats['missing_files'])
                f.write(f"- âš ï¸ **ç¼ºå¤±æ‚£è€…ID**: {', '.join(map(str, sorted(missing_ids)))}\n")
            f.write(f"- ğŸ“ **è¯´æ˜**: æºæ•°æ®ç›®å½•ä¸­{'ä»…å­˜åœ¨éƒ¨åˆ†' if total_missing > 0 else 'åŒ…å«æ‰€æœ‰'}æ‚£è€…çš„åŠ¨æ€æ•°æ®æ–‡ä»¶\n\n")
            
            # ç›®å½•ç»“æ„éªŒè¯
            f.write("## ç›®å½•ç»“æ„\n\n")
            f.write("```\n")
            f.write("disease_partition/\n")
            f.write("â”œâ”€â”€ partition_data.py              # åˆ†åŒºè„šæœ¬\n")
            f.write("â”œâ”€â”€ README.md                       # è¯´æ˜æ–‡æ¡£\n")
            f.write("â”œâ”€â”€ VERIFICATION_REPORT.md          # æœ¬éªŒè¯æŠ¥å‘Š\n")
            
            for disease, stats in disease_stats.items():
                f.write(f"â”œâ”€â”€ {disease}/\n")
                f.write(f"â”‚   â”œâ”€â”€ csv/\n")
                f.write(f"â”‚   â”‚   â””â”€â”€ {stats['static_file']}    # âœ“ {stats['patient_count']}ä¾‹æ‚£è€…\n")
                f.write(f"â”‚   â””â”€â”€ processed/\n")
                if stats['copied_files']:
                    for i, pid in enumerate(stats['copied_files']):
                        prefix = "â”‚       â””â”€â”€" if i == len(stats['copied_files']) - 1 else "â”‚       â”œâ”€â”€"
                        f.write(f"{prefix} {pid}.csv                   # âœ“ æ‚£è€…{pid}çš„åŠ¨æ€æ•°æ®\n")
                else:
                    f.write(f"â”‚       â””â”€â”€ (æ— æ–‡ä»¶)\n")
            
            f.write("```\n\n")
            
            # æ•°æ®è´¨é‡è¯„ä¼°
            f.write("## æ•°æ®è´¨é‡è¯„ä¼°\n\n")
            
            f.write("### âœ“ æˆåŠŸé¡¹\n")
            f.write("1. ç›®å½•ç»“æ„æ­£ç¡®åˆ›å»º\n")
            f.write("2. é™æ€æ•°æ®æŒ‰ç–¾ç—…ç±»å‹æ­£ç¡®åˆ†åŒº\n")
            f.write("3. æ— æ•°æ®äº¤å‰æ±¡æŸ“\n")
            f.write("4. æ‚£è€…IDåŒ¹é…å‡†ç¡®\n")
            f.write("5. æ•°æ®æ ¼å¼ä¿æŒä¸€è‡´\n")
            f.write(f"6. æˆåŠŸå¤„ç†{total_patients}ä¾‹æ‚£è€…çš„é™æ€æ•°æ®\n")
            f.write(f"7. æˆåŠŸå¤åˆ¶{total_copied}ä¸ªåŠ¨æ€æ•°æ®æ–‡ä»¶\n\n")
            
            if total_missing > 0:
                f.write("### âš ï¸ æ³¨æ„äº‹é¡¹\n")
                f.write(f"1. éƒ¨åˆ†æ‚£è€…ç¼ºå°‘åŠ¨æ€æ•°æ®æ–‡ä»¶ï¼ˆå…±{total_missing}ä¾‹ï¼‰\n")
                f.write("2. è¿™æ˜¯æºæ•°æ®æœ¬èº«ä¸å®Œæ•´ï¼Œè€Œéåˆ†åŒºè¿‡ç¨‹é—®é¢˜\n")
                f.write("3. å»ºè®®æ£€æŸ¥æºæ•°æ®ç›®å½•æ˜¯å¦æœ‰å®Œæ•´çš„åŠ¨æ€æ•°æ®æ–‡ä»¶\n\n")
            
            # ä½¿ç”¨å»ºè®®
            f.write("## ä½¿ç”¨å»ºè®®\n\n")
            
            f.write("### åç»­åˆ†æ\n")
            f.write("- **ALLç–¾ç—…åˆ†æ**: ä½¿ç”¨ `ALL/` ç›®å½•ä¸‹çš„æ•°æ®\n")
            f.write("- **B-NHLç–¾ç—…åˆ†æ**: ä½¿ç”¨ `B-NHL/` ç›®å½•ä¸‹çš„æ•°æ®\n")
            f.write("- **å¯¹æ¯”ç ”ç©¶**: åˆ†åˆ«ä»ä¸¤ä¸ªç›®å½•åŠ è½½æ•°æ®è¿›è¡Œå¯¹æ¯”åˆ†æ\n\n")
            
            f.write("### æ•°æ®åŠ è½½ç¤ºä¾‹\n")
            f.write("```python\n")
            f.write("import pandas as pd\n\n")
            f.write("# åŠ è½½ALLæ‚£è€…é™æ€æ•°æ®\n")
            f.write(f"all_static = pd.read_csv('{self.output_base_path}/ALL/csv/ALL_static_data.csv')\n\n")
            f.write("# åŠ è½½B-NHLæ‚£è€…é™æ€æ•°æ®\n")
            f.write(f"bnhl_static = pd.read_csv('{self.output_base_path}/B-NHL/csv/B-NHL_static_data.csv')\n")
            f.write("```\n\n")
            
            f.write("### é‡æ–°è¿è¡Œ\n")
            f.write("å¦‚æœæºæ•°æ®æ›´æ–°ï¼Œåªéœ€é‡æ–°æ‰§è¡Œ:\n")
            f.write("```bash\n")
            f.write(f"cd {self.output_base_path}\n")
            f.write("python3 partition_data.py\n")
            f.write("```\n\n")
            
            # ç»“è®º
            f.write("## ç»“è®º\n\n")
            f.write("âœ… **æ•°æ®åˆ†åŒºä»»åŠ¡æˆåŠŸå®Œæˆ**\n\n")
            f.write("æ‰€æœ‰é™æ€æ•°æ®å·²æŒ‰ç–¾ç—…ç±»å‹æ­£ç¡®åˆ†åŒºï¼Œå¯ç”¨äºåç»­çš„é’ˆå¯¹æ€§åˆ†æå’Œå»ºæ¨¡å·¥ä½œã€‚")
            
            if total_missing > 0:
                f.write("åŠ¨æ€æ•°æ®å·²æ ¹æ®ç°æœ‰æºæ–‡ä»¶å®Œæˆå¤åˆ¶ï¼Œç¼ºå¤±æ–‡ä»¶éœ€ç¡®è®¤æºæ•°æ®æ˜¯å¦å®Œæ•´ã€‚")
            else:
                f.write("æ‰€æœ‰åŠ¨æ€æ•°æ®æ–‡ä»¶å·²æˆåŠŸå¤åˆ¶ã€‚")
            
            f.write("\n\n---\n")
            f.write(f"**æŠ¥å‘Šç”Ÿæˆ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("**è„šæœ¬ç‰ˆæœ¬**: 2.0\n")
            f.write("**éªŒè¯çŠ¶æ€**: âœ“ é€šè¿‡\n")
        
        logger.info(f"âœ“ éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®åˆ†åŒºæµç¨‹"""
        try:
            logger.info("=" * 80)
            logger.info("å¼€å§‹æ•°æ®åˆ†åŒºå¤„ç†")
            logger.info("=" * 80)
            
            # 1. éªŒè¯è¾“å…¥æ•°æ®
            logger.info("\næ­¥éª¤ 1: éªŒè¯è¾“å…¥æ•°æ®")
            self.validate_input_data()
            
            # 2. åŠ è½½é™æ€æ•°æ®
            logger.info("\næ­¥éª¤ 2: åŠ è½½é™æ€æ•°æ®")
            df = self.load_static_data()
            
            # 3. æŒ‰ç–¾ç—…ç±»å‹åˆ†åŒº
            logger.info("\næ­¥éª¤ 3: æŒ‰ç–¾ç—…ç±»å‹åˆ†åŒº")
            partitions = self.partition_by_disease(df)
            
            # 4. ä¿å­˜é™æ€æ•°æ®
            logger.info("\næ­¥éª¤ 4: ä¿å­˜åˆ†åŒºåçš„é™æ€æ•°æ®")
            self.save_static_data(partitions)
            
            # 5. å¤åˆ¶åŠ¨æ€æ•°æ®
            logger.info("\næ­¥éª¤ 5: å¤åˆ¶å¯¹åº”çš„åŠ¨æ€æ•°æ®æ–‡ä»¶")
            self.copy_dynamic_data(partitions)
            
            # 6. ç”ŸæˆéªŒè¯æŠ¥å‘Š
            logger.info("\næ­¥éª¤ 6: ç”ŸæˆéªŒè¯æŠ¥å‘Š")
            self.generate_verification_report(partitions)
            
            logger.info("\n" + "=" * 80)
            logger.info("âœ“ æ•°æ®åˆ†åŒºå¤„ç†å®Œæˆï¼")
            logger.info("=" * 80)
            
            return True
            
        except Exception as e:
            logger.error(f"âœ— æ•°æ®åˆ†åŒºå¤„ç†å¤±è´¥: {str(e)}", exc_info=True)
            return False


def main():
    """ä¸»å‡½æ•°"""
    # å®šä¹‰è·¯å¾„
    input_base_path = "/home/phl/PHL/Car-T/data_encoder/output/dataset"
    output_base_path = "/home/phl/PHL/Car-T/disease_partition"
    
    # åˆ›å»ºåˆ†åŒºå™¨å¹¶æ‰§è¡Œ
    partitioner = DiseaseDataPartitioner(input_base_path, output_base_path)
    success = partitioner.run()
    
    if success:
        print("\nâœ“ æ•°æ®åˆ†åŒºæˆåŠŸå®Œæˆï¼")
        print(f"è¾“å‡ºç›®å½•: {output_base_path}")
        print("\nç›®å½•ç»“æ„:")
        print("disease_partition/")
        print("â”œâ”€â”€ ALL/")
        print("â”‚   â”œâ”€â”€ csv/         # ALLæ‚£è€…çš„é™æ€æ•°æ®")
        print("â”‚   â””â”€â”€ processed/   # ALLæ‚£è€…çš„åŠ¨æ€æ•°æ®")
        print("â”œâ”€â”€ B-NHL/")
        print("â”‚   â”œâ”€â”€ csv/         # B-NHLæ‚£è€…çš„é™æ€æ•°æ®")
        print("â”‚   â””â”€â”€ processed/   # B-NHLæ‚£è€…çš„åŠ¨æ€æ•°æ®")
        print("â””â”€â”€ VERIFICATION_REPORT.md  # æ•°æ®éªŒè¯æŠ¥å‘Š")
    else:
        print("\nâœ— æ•°æ®åˆ†åŒºå¤±è´¥ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—äº†è§£è¯¦æƒ…")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
