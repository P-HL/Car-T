import pandas as pd
import numpy as np
import os
from pathlib import Path
import warnings
from typing import Dict, List, Tuple, Optional, Any
import re
import shutil
from datetime import datetime
import argparse
import yaml
import sys


class ConfigManager:
    """
    é…ç½®ç®¡ç†å™¨
    æ”¯æŒå‘½ä»¤è¡Œå‚æ•°ã€YAMLé…ç½®æ–‡ä»¶ã€ç¯å¢ƒå˜é‡å’Œé»˜è®¤å€¼
    ä¼˜å…ˆé¡ºåºï¼šå‘½ä»¤è¡Œå‚æ•° > é…ç½®æ–‡ä»¶ > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼
    """
    
    def __init__(self):
        self.config = {}
        self._load_default_config()
    
    def _load_default_config(self):
        """åŠ è½½é»˜è®¤é…ç½®"""
        self.config = {
            # è·¯å¾„é…ç½®
            'input_dir': '/home/phl/PHL/pytorch-forecasting/datasetcart/processed',
            'output_dir': '/home/phl/PHL/pytorch-forecasting/datasetcart/processed_standardized',
            'static_data_path': '/home/phl/PHL/pytorch-forecasting/datasetcart/encoded_standardized.csv',
            
            # æ•°æ®éªŒè¯é…ç½®
            'expected_file_count': 500,
            'expected_row_count': 46,
            'expected_time_range_start': -15,
            'expected_time_range_end': 30,
            
            # åˆ—åˆ é™¤é…ç½®
            'cbc_columns_to_delete': [2, 4, 6, 8, 10, 15, 16, 17, 18, 19, 21, 22, 23, 24],
            'biochemistry_columns_to_delete': [3, 7],
            'coagulation_columns_to_delete': [8],
            
            # å¯é€‰åˆ—é…ç½®
            'optional_columns': ['VCN001'] + [f'Lymphocyte Subsets{str(i).zfill(3)}' for i in range(1, 12)],
            
            # å˜é‡ç±»åˆ«é…ç½®
            'variable_categories': {
                'CBC': 24,
                'Inflammatory Biomarker': 9,
                'VCN': 1,
                'Lymphocyte Subsets': 11,
                'Coagulation': 8,
                'Electrolytes': 6,
                'Biochemistry': 28,
                'Vital Signs': 6
            },
            
            # å¤„ç†é…ç½®
            'remove_optional_columns': False,
            'verbose': True,
            'progress_interval': 50,
            
            # è¾“å‡ºé…ç½®
            'validation_report_path': 'dynamic_data_validation_report.txt',
            'processing_report_path': 'dynamic_data_processing_report.txt',
            
            # æ­¥éª¤æ§åˆ¶é…ç½®
            'enable_validation': True,
            'enable_processing': True,
            'validation_only': False,
            'processing_only': False,
            'skip_interactive': False,
            
            # é…ç½®æ–‡ä»¶è·¯å¾„
            'config_file': None
        }
    
    def load_from_env(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        env_mapping = {
            'CART_INPUT_DIR': 'input_dir',
            'CART_OUTPUT_DIR': 'output_dir',
            'CART_STATIC_DATA_PATH': 'static_data_path',
            'CART_EXPECTED_FILE_COUNT': 'expected_file_count',
            'CART_EXPECTED_ROW_COUNT': 'expected_row_count',
            'CART_REMOVE_OPTIONAL': 'remove_optional_columns',
            'CART_VERBOSE': 'verbose',
            'CART_PROGRESS_INTERVAL': 'progress_interval',
            'CART_VALIDATION_REPORT': 'validation_report_path',
            'CART_PROCESSING_REPORT': 'processing_report_path',
            'CART_ENABLE_VALIDATION': 'enable_validation',
            'CART_ENABLE_PROCESSING': 'enable_processing',
            'CART_VALIDATION_ONLY': 'validation_only',
            'CART_PROCESSING_ONLY': 'processing_only',
            'CART_SKIP_INTERACTIVE': 'skip_interactive'
        }
        
        for env_var, config_key in env_mapping.items():
            env_value = os.getenv(env_var)
            if env_value is not None:
                # ç±»å‹è½¬æ¢
                if config_key in ['expected_file_count', 'expected_row_count', 'progress_interval']:
                    try:
                        self.config[config_key] = int(env_value)
                    except ValueError:
                        print(f"è­¦å‘Š: ç¯å¢ƒå˜é‡ {env_var} çš„å€¼ '{env_value}' ä¸æ˜¯æœ‰æ•ˆæ•´æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                elif config_key in ['remove_optional_columns', 'verbose', 'enable_validation', 'enable_processing', 
                                  'validation_only', 'processing_only', 'skip_interactive']:
                    self.config[config_key] = env_value.lower() in ['true', '1', 'yes', 'on']
                else:
                    self.config[config_key] = env_value
    
    def load_from_yaml(self, config_file: str):
        """ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®"""
        if not os.path.exists(config_file):
            print(f"è­¦å‘Š: é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                yaml_config = yaml.safe_load(f)
                if yaml_config:
                    self.config.update(yaml_config)
                    print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
        except Exception as e:
            print(f"é”™è¯¯: æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ {config_file}: {e}")
            sys.exit(1)
    
    def load_from_args(self, args: argparse.Namespace):
        """ä»å‘½ä»¤è¡Œå‚æ•°åŠ è½½é…ç½®"""
        for key, value in vars(args).items():
            if value is not None:
                self.config[key] = value
    
    def validate_config(self):
        """éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§"""
        # éªŒè¯è·¯å¾„
        required_paths = ['input_dir']
        for path_key in required_paths:
            path = self.config[path_key]
            if not os.path.exists(path):
                print(f"é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨: {path}")
                sys.exit(1)
        
        # éªŒè¯æ•°å€¼å‚æ•°
        if self.config['expected_file_count'] <= 0:
            print("é”™è¯¯: expected_file_count å¿…é¡»å¤§äº0")
            sys.exit(1)
        
        if self.config['expected_row_count'] <= 0:
            print("é”™è¯¯: expected_row_count å¿…é¡»å¤§äº0")
            sys.exit(1)
        
        if self.config['progress_interval'] <= 0:
            print("é”™è¯¯: progress_interval å¿…é¡»å¤§äº0")
            sys.exit(1)
    
    def get(self, key: str, default=None):
        """è·å–é…ç½®å€¼"""
        return self.config.get(key, default)
    
    def set(self, key: str, value):
        """è®¾ç½®é…ç½®å€¼"""
        self.config[key] = value
    
    def print_config(self):
        """æ‰“å°å½“å‰é…ç½®"""
        print("\nå½“å‰é…ç½®:")
        print("-" * 50)
        for category in ['è·¯å¾„é…ç½®', 'æ•°æ®éªŒè¯é…ç½®', 'åˆ—åˆ é™¤é…ç½®', 'å¤„ç†é…ç½®', 'æ­¥éª¤æ§åˆ¶é…ç½®', 'è¾“å‡ºé…ç½®']:
            print(f"\n{category}:")
            
            if category == 'è·¯å¾„é…ç½®':
                keys = ['input_dir', 'output_dir', 'static_data_path']
            elif category == 'æ•°æ®éªŒè¯é…ç½®':
                keys = ['expected_file_count', 'expected_row_count', 'expected_time_range_start', 'expected_time_range_end']
            elif category == 'åˆ—åˆ é™¤é…ç½®':
                keys = ['cbc_columns_to_delete', 'biochemistry_columns_to_delete', 'coagulation_columns_to_delete']
            elif category == 'å¤„ç†é…ç½®':
                keys = ['remove_optional_columns', 'verbose', 'progress_interval']
            elif category == 'æ­¥éª¤æ§åˆ¶é…ç½®':
                keys = ['enable_validation', 'enable_processing', 'validation_only', 'processing_only', 'skip_interactive']
            else:  # è¾“å‡ºé…ç½®
                keys = ['validation_report_path', 'processing_report_path']
            
            for key in keys:
                if key in self.config:
                    print(f"  {key}: {self.config[key]}")


def create_sample_config():
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    sample_config = {
        'input_dir': '/home/phl/PHL/pytorch-forecasting/datasetcart/processed',
        'output_dir': '/home/phl/PHL/pytorch-forecasting/datasetcart/processed_standardized',
        'static_data_path': '/home/phl/PHL/pytorch-forecasting/datasetcart/encoded_standardized.csv',
        'expected_file_count': 500,
        'expected_row_count': 46,
        'expected_time_range_start': -15,
        'expected_time_range_end': 30,
        'cbc_columns_to_delete': [2, 4, 6, 8, 10, 15, 16, 17, 18, 19, 21, 22, 23, 24],
        'biochemistry_columns_to_delete': [3, 7],
        'coagulation_columns_to_delete': [8],
        'remove_optional_columns': False,
        'verbose': True,
        'progress_interval': 50,
        'enable_validation': True,
        'enable_processing': True,
        'validation_only': False,
        'processing_only': False,
        'skip_interactive': False,
        'validation_report_path': 'dynamic_data_validation_report.txt',
        'processing_report_path': 'dynamic_data_processing_report.txt'
    }
    
    with open('config_sample.yaml', 'w', encoding='utf-8') as f:
        yaml.dump(sample_config, f, default_flow_style=False, allow_unicode=True)
    
    print("âœ… ç¤ºä¾‹é…ç½®æ–‡ä»¶å·²åˆ›å»º: config_sample.yaml")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='CAR-Tæ²»ç–—ä¸´åºŠæ•°æ®å¤„ç†ç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤é…ç½®
  python data_processed_dynamic.py
  
  # æŒ‡å®šè¾“å…¥å’Œè¾“å‡ºç›®å½•
  python data_processed_dynamic.py --input-dir /path/to/input --output-dir /path/to/output
  
  # ä½¿ç”¨é…ç½®æ–‡ä»¶
  python data_processed_dynamic.py --config config.yaml
  
  # åˆ é™¤å¯é€‰åˆ—
  python data_processed_dynamic.py --remove-optional-columns
  
  # åªè¿è¡ŒéªŒè¯æ­¥éª¤
  python data_processed_dynamic.py --validation-only
  
  # åªè¿è¡Œå¤„ç†æ­¥éª¤
  python data_processed_dynamic.py --processing-only
  
  # è·³è¿‡äº¤äº’å¼è¯¢é—®
  python data_processed_dynamic.py --skip-interactive --remove-optional-columns
  
  # ç¦ç”¨éªŒè¯æ­¥éª¤ï¼Œåªè¿è¡Œå¤„ç†
  python data_processed_dynamic.py --no-validation
  
  # ç¦ç”¨å¤„ç†æ­¥éª¤ï¼Œåªè¿è¡ŒéªŒè¯
  python data_processed_dynamic.py --no-processing

ç¯å¢ƒå˜é‡:
  CART_INPUT_DIR              è¾“å…¥ç›®å½•è·¯å¾„
  CART_OUTPUT_DIR             è¾“å‡ºç›®å½•è·¯å¾„
  CART_STATIC_DATA_PATH       é™æ€æ•°æ®æ–‡ä»¶è·¯å¾„
  CART_EXPECTED_FILE_COUNT    é¢„æœŸæ–‡ä»¶æ•°é‡
  CART_EXPECTED_ROW_COUNT     é¢„æœŸè¡Œæ•°
  CART_REMOVE_OPTIONAL        æ˜¯å¦åˆ é™¤å¯é€‰åˆ— (true/false)
  CART_VERBOSE                æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ (true/false)
  CART_PROGRESS_INTERVAL      è¿›åº¦æ˜¾ç¤ºé—´éš”
  CART_VALIDATION_REPORT      éªŒè¯æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
  CART_PROCESSING_REPORT      å¤„ç†æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
  CART_ENABLE_VALIDATION      æ˜¯å¦å¯ç”¨éªŒè¯æ­¥éª¤ (true/false)
  CART_ENABLE_PROCESSING      æ˜¯å¦å¯ç”¨å¤„ç†æ­¥éª¤ (true/false)
  CART_VALIDATION_ONLY        åªè¿è¡ŒéªŒè¯æ­¥éª¤ (true/false)
  CART_PROCESSING_ONLY        åªè¿è¡Œå¤„ç†æ­¥éª¤ (true/false)
  CART_SKIP_INTERACTIVE       è·³è¿‡äº¤äº’å¼è¯¢é—® (true/false)
        """
    )
    
    # è·¯å¾„é…ç½®
    parser.add_argument('--input-dir', dest='input_dir',
                       help='è¾“å…¥æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--output-dir', dest='output_dir',
                       help='è¾“å‡ºæ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--static-data-path', dest='static_data_path',
                       help='é™æ€æ•°æ®æ–‡ä»¶è·¯å¾„')
    
    # æ•°æ®éªŒè¯é…ç½®
    parser.add_argument('--expected-file-count', dest='expected_file_count', type=int,
                       help='é¢„æœŸæ–‡ä»¶æ•°é‡')
    parser.add_argument('--expected-row-count', dest='expected_row_count', type=int,
                       help='é¢„æœŸè¡Œæ•°')
    
    # å¤„ç†é…ç½®
    parser.add_argument('--remove-optional-columns', dest='remove_optional_columns',
                       action='store_true', help='åˆ é™¤å¯é€‰åˆ— (VCN001å’ŒLymphocyte Subsets)')
    parser.add_argument('--no-verbose', dest='verbose', action='store_false',
                       help='ä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    parser.add_argument('--progress-interval', dest='progress_interval', type=int,
                       help='è¿›åº¦æ˜¾ç¤ºé—´éš”')
    
    # è¾“å‡ºé…ç½®
    parser.add_argument('--validation-report', dest='validation_report_path',
                       help='éªŒè¯æŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--processing-report', dest='processing_report_path',
                       help='å¤„ç†æŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    
    # é…ç½®æ–‡ä»¶
    parser.add_argument('--config', dest='config_file',
                       help='YAMLé…ç½®æ–‡ä»¶è·¯å¾„')
    
    # æ­¥éª¤æ§åˆ¶
    parser.add_argument('--validation-only', dest='validation_only', action='store_true',
                       help='åªè¿è¡Œæ•°æ®éªŒè¯æ­¥éª¤')
    parser.add_argument('--processing-only', dest='processing_only', action='store_true',
                       help='åªè¿è¡Œæ•°æ®å¤„ç†æ­¥éª¤')
    parser.add_argument('--no-validation', dest='enable_validation', action='store_false',
                       help='ç¦ç”¨æ•°æ®éªŒè¯æ­¥éª¤')
    parser.add_argument('--no-processing', dest='enable_processing', action='store_false',
                       help='ç¦ç”¨æ•°æ®å¤„ç†æ­¥éª¤')
    parser.add_argument('--skip-interactive', dest='skip_interactive', action='store_true',
                       help='è·³è¿‡äº¤äº’å¼è¯¢é—®ï¼Œä½¿ç”¨é…ç½®å€¼')
    
    # å®ç”¨åŠŸèƒ½
    parser.add_argument('--create-sample-config', action='store_true',
                       help='åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶å¹¶é€€å‡º')
    parser.add_argument('--print-config', action='store_true',
                       help='æ‰“å°å½“å‰é…ç½®å¹¶é€€å‡º')
    
    return parser.parse_args()


class DynamicDataValidator:
    """
    åŠ¨æ€æ‚£è€…æ•°æ®éªŒè¯å™¨
    ç”¨äºéªŒè¯processedæ–‡ä»¶å¤¹ä¸­æ‰€æœ‰CSVæ–‡ä»¶çš„æ•°æ®è´¨é‡å’Œç»“æ„ä¸€è‡´æ€§
    """
    
    def __init__(self, config: ConfigManager):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            config: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.config = config
        self.processed_dir = config.get('input_dir')
        self.static_data_path = config.get('static_data_path')
        
        # æ ¹æ®é…ç½®å®šä¹‰é¢„æœŸçš„åˆ—ç»“æ„
        self.expected_columns = self._define_expected_columns()
        self.expected_column_count = len(self.expected_columns)
        self.expected_row_count = config.get('expected_row_count')
        
        # éªŒè¯ç»“æœå­˜å‚¨
        self.validation_results = {
            'errors': [],
            'warnings': [],
            'processed_files': 0,
            'valid_files': 0,
            'invalid_files': []
        }
    
    def _define_expected_columns(self) -> List[str]:
        """å®šä¹‰é¢„æœŸçš„åˆ—å"""
        columns = []
        variable_categories = self.config.get('variable_categories')
        
        # æ ¹æ®é…ç½®åŠ¨æ€ç”Ÿæˆåˆ—å
        for category, count in variable_categories.items():
            if category == 'VCN':
                columns.append("VCN001")
            else:
                columns.extend([f"{category}{str(i).zfill(3)}" for i in range(1, count + 1)])
        
        return columns
    
    def _is_valid_numeric_or_na(self, value: Any) -> Tuple[bool, str]:
        """
        æ£€æŸ¥å€¼æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æ•°å€¼æˆ–NA
        
        Args:
            value: è¦æ£€æŸ¥çš„å€¼
            
        Returns:
            (is_valid, reason): æ˜¯å¦æœ‰æ•ˆåŠåŸå› 
        """
        if pd.isna(value) or value == 'NA' or value == '':
            return True, "Valid NA"
        
        try:
            float(value)
            return True, "Valid numeric"
        except (ValueError, TypeError):
            return False, f"Invalid value: {value} (type: {type(value).__name__})"
    
    def validate_file_structure(self, file_path: str) -> Dict[str, Any]:
        """
        éªŒè¯å•ä¸ªæ–‡ä»¶çš„ç»“æ„
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        file_name = os.path.basename(file_path)
        result = {
            'file_name': file_name,
            'file_path': file_path,
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'column_count': 0,
            'row_count': 0,
            'data_type_issues': []
        }
        
        try:
            # è¯»å–æ–‡ä»¶
            df = pd.read_csv(file_path, index_col=0)
            result['column_count'] = len(df.columns)
            result['row_count'] = len(df) + 1  # +1 for header
            
            # éªŒè¯åˆ—æ•°
            if result['column_count'] != self.expected_column_count:
                error_msg = f"åˆ—æ•°ä¸åŒ¹é…: é¢„æœŸ {self.expected_column_count} åˆ—ï¼Œå®é™…å‘ç° {result['column_count']} åˆ—"
                result['errors'].append(error_msg)
                result['is_valid'] = False
            
            # éªŒè¯è¡Œæ•°ï¼ˆæ—¶é—´ç‚¹æ•°ï¼‰
            expected_time_start = self.config.get('expected_time_range_start')
            expected_time_end = self.config.get('expected_time_range_end')
            expected_days = list(range(expected_time_start, expected_time_end + 1))
            if len(df) != len(expected_days):
                warning_msg = f"æ—¶é—´ç‚¹æ•°é‡å¼‚å¸¸: é¢„æœŸ {len(expected_days)} ä¸ªæ—¶é—´ç‚¹ï¼Œå®é™…å‘ç° {len(df)} ä¸ª"
                result['warnings'].append(warning_msg)
            
            # éªŒè¯åˆ—å
            actual_columns = df.columns.tolist()
            if actual_columns != self.expected_columns:
                # æ£€æŸ¥æ˜¯å¦åªæ˜¯é¡ºåºé—®é¢˜
                if set(actual_columns) == set(self.expected_columns):
                    result['warnings'].append("åˆ—åé¡ºåºä¸é¢„æœŸä¸åŒï¼Œä½†åŒ…å«æ‰€æœ‰é¢„æœŸåˆ—")
                else:
                    missing_cols = set(self.expected_columns) - set(actual_columns)
                    extra_cols = set(actual_columns) - set(self.expected_columns)
                    
                    if missing_cols:
                        result['errors'].append(f"ç¼ºå¤±åˆ—: {list(missing_cols)}")
                        result['is_valid'] = False
                    
                    if extra_cols:
                        result['warnings'].append(f"é¢å¤–åˆ—: {list(extra_cols)}")
            
            # éªŒè¯æ•°æ®ç±»å‹
            for row_idx, row in df.iterrows():
                for col_idx, (col_name, value) in enumerate(row.items()):
                    is_valid, reason = self._is_valid_numeric_or_na(value)
                    if not is_valid:
                        issue = {
                            'row': row_idx,
                            'column': col_name,
                            'value': value,
                            'reason': reason,
                            'position': f"è¡Œ {row_idx}, åˆ— {col_name}"
                        }
                        result['data_type_issues'].append(issue)
                        result['is_valid'] = False
            
            # æ£€æŸ¥æ—¶é—´ç´¢å¼•
            try:
                time_indices = df.index.tolist()
                expected_time_start = self.config.get('expected_time_range_start')
                expected_time_end = self.config.get('expected_time_range_end')
                expected_indices = list(range(expected_time_start, expected_time_end + 1))
                if time_indices != expected_indices:
                    result['warnings'].append(f"æ—¶é—´ç´¢å¼•å¼‚å¸¸: é¢„æœŸ {expected_indices[:5]}...{expected_indices[-5:]}, å®é™… {time_indices[:5] if len(time_indices) >= 5 else time_indices}...")
            except Exception as e:
                result['warnings'].append(f"æ—¶é—´ç´¢å¼•æ£€æŸ¥å¤±è´¥: {str(e)}")
                
        except FileNotFoundError:
            result['errors'].append(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            result['is_valid'] = False
        except pd.errors.EmptyDataError:
            result['errors'].append("æ–‡ä»¶ä¸ºç©º")
            result['is_valid'] = False
        except Exception as e:
            result['errors'].append(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
            result['is_valid'] = False
        
        return result
    
    def validate_all_files(self) -> Dict[str, Any]:
        """éªŒè¯æ‰€æœ‰æ–‡ä»¶"""
        print("å¼€å§‹éªŒè¯åŠ¨æ€æ‚£è€…æ•°æ®æ–‡ä»¶...")
        print("=" * 60)
        
        # è·å–æ‰€æœ‰CSVæ–‡ä»¶
        csv_files = list(Path(self.processed_dir).glob("*.csv"))
        total_files = len(csv_files)
        
        print(f"å‘ç° {total_files} ä¸ªCSVæ–‡ä»¶")
        expected_file_count = self.config.get('expected_file_count')
        print(f"é¢„æœŸæ–‡ä»¶æ•°é‡: {expected_file_count}")
        
        if total_files != expected_file_count:
            warning_msg = f"æ–‡ä»¶æ•°é‡è­¦å‘Š: é¢„æœŸ{expected_file_count}ä¸ªæ–‡ä»¶ï¼Œå®é™…å‘ç°{total_files}ä¸ªæ–‡ä»¶"
            self.validation_results['warnings'].append(warning_msg)
            print(f"âš ï¸  {warning_msg}")
        
        print(f"é¢„æœŸæ¯ä¸ªæ–‡ä»¶çš„åˆ—æ•°: {self.expected_column_count}")
        print(f"é¢„æœŸæ¯ä¸ªæ–‡ä»¶çš„è¡Œæ•°: {self.expected_row_count} (å«è¡¨å¤´)")
        print("-" * 60)
        
        # éªŒè¯æ¯ä¸ªæ–‡ä»¶
        valid_count = 0
        error_count = 0
        progress_interval = self.config.get('progress_interval')
        
        for i, file_path in enumerate(csv_files, 1):
            if i % progress_interval == 0 or i == total_files:
                print(f"è¿›åº¦: {i}/{total_files}")
            
            result = self.validate_file_structure(str(file_path))
            self.validation_results['processed_files'] += 1
            
            if result['is_valid']:
                valid_count += 1
            else:
                error_count += 1
                self.validation_results['invalid_files'].append(result)
                
                # è¾“å‡ºé”™è¯¯ä¿¡æ¯
                print(f"\nâŒ æ–‡ä»¶å¼‚å¸¸: {result['file_name']}")
                for error in result['errors']:
                    print(f"   é”™è¯¯: {error}")
                    self.validation_results['errors'].append(f"{result['file_name']}: {error}")
                
                for warning in result['warnings']:
                    print(f"   è­¦å‘Š: {warning}")
                    self.validation_results['warnings'].append(f"{result['file_name']}: {warning}")
                
                # è¾“å‡ºæ•°æ®ç±»å‹é—®é¢˜
                if result['data_type_issues']:
                    print(f"   æ•°æ®ç±»å‹é—®é¢˜ ({len(result['data_type_issues'])}ä¸ª):")
                    for issue in result['data_type_issues'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                        print(f"     - {issue['position']}: {issue['reason']}")
                    if len(result['data_type_issues']) > 5:
                        print(f"     - ... è¿˜æœ‰ {len(result['data_type_issues']) - 5} ä¸ªç±»ä¼¼é—®é¢˜")
        
        self.validation_results['valid_files'] = valid_count
        
        # è¾“å‡ºæ€»ç»“
        self._print_summary()
        
        return self.validation_results
    
    def _print_summary(self):
        """æ‰“å°éªŒè¯æ€»ç»“"""
        print("\n" + "=" * 60)
        print("éªŒè¯ç»“æœæ€»ç»“")
        print("=" * 60)
        
        print(f"å¤„ç†çš„æ–‡ä»¶æ€»æ•°: {self.validation_results['processed_files']}")
        print(f"æœ‰æ•ˆæ–‡ä»¶æ•°: {self.validation_results['valid_files']}")
        print(f"å¼‚å¸¸æ–‡ä»¶æ•°: {len(self.validation_results['invalid_files'])}")
        print(f"é”™è¯¯æ€»æ•°: {len(self.validation_results['errors'])}")
        print(f"è­¦å‘Šæ€»æ•°: {len(self.validation_results['warnings'])}")
        
        if self.validation_results['errors']:
            print(f"\nâŒ å‘ç° {len(self.validation_results['errors'])} ä¸ªé”™è¯¯:")
            for error in self.validation_results['errors'][:10]:  # æ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                print(f"   - {error}")
            if len(self.validation_results['errors']) > 10:
                print(f"   - ... è¿˜æœ‰ {len(self.validation_results['errors']) - 10} ä¸ªé”™è¯¯")
        
        if self.validation_results['warnings']:
            print(f"\nâš ï¸  å‘ç° {len(self.validation_results['warnings'])} ä¸ªè­¦å‘Š:")
            for warning in self.validation_results['warnings'][:10]:  # æ˜¾ç¤ºå‰10ä¸ªè­¦å‘Š
                print(f"   - {warning}")
            if len(self.validation_results['warnings']) > 10:
                print(f"   - ... è¿˜æœ‰ {len(self.validation_results['warnings']) - 10} ä¸ªè­¦å‘Š")
        
        if len(self.validation_results['invalid_files']) == 0:
            print("\nâœ… æ‰€æœ‰æ–‡ä»¶éªŒè¯é€šè¿‡ï¼")
        else:
            print(f"\nâŒ {len(self.validation_results['invalid_files'])} ä¸ªæ–‡ä»¶éœ€è¦æ³¨æ„")
    
    def export_validation_report(self, output_path: str = None):
        """å¯¼å‡ºè¯¦ç»†çš„éªŒè¯æŠ¥å‘Š"""
        if output_path is None:
            output_path = self.config.get('validation_report_path')
            
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("åŠ¨æ€æ‚£è€…æ•°æ®éªŒè¯æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"éªŒè¯æ—¶é—´: {pd.Timestamp.now()}\n")
            f.write(f"æ•°æ®ç›®å½•: {self.processed_dir}\n")
            f.write(f"é¢„æœŸåˆ—æ•°: {self.expected_column_count}\n")
            f.write(f"é¢„æœŸè¡Œæ•°: 46\n\n")
            
            f.write("éªŒè¯ç»“æœæ€»ç»“:\n")
            f.write(f"- å¤„ç†æ–‡ä»¶æ•°: {self.validation_results['processed_files']}\n")
            f.write(f"- æœ‰æ•ˆæ–‡ä»¶æ•°: {self.validation_results['valid_files']}\n")
            f.write(f"- å¼‚å¸¸æ–‡ä»¶æ•°: {len(self.validation_results['invalid_files'])}\n")
            f.write(f"- é”™è¯¯æ€»æ•°: {len(self.validation_results['errors'])}\n")
            f.write(f"- è­¦å‘Šæ€»æ•°: {len(self.validation_results['warnings'])}\n\n")
            
            if self.validation_results['errors']:
                f.write("é”™è¯¯åˆ—è¡¨:\n")
                f.write("-" * 40 + "\n")
                for error in self.validation_results['errors']:
                    f.write(f"âŒ {error}\n")
                f.write("\n")
            
            if self.validation_results['warnings']:
                f.write("è­¦å‘Šåˆ—è¡¨:\n")
                f.write("-" * 40 + "\n")
                for warning in self.validation_results['warnings']:
                    f.write(f"âš ï¸  {warning}\n")
                f.write("\n")
            
            if self.validation_results['invalid_files']:
                f.write("å¼‚å¸¸æ–‡ä»¶è¯¦æƒ…:\n")
                f.write("-" * 40 + "\n")
                for file_result in self.validation_results['invalid_files']:
                    f.write(f"\næ–‡ä»¶: {file_result['file_name']}\n")
                    f.write(f"è·¯å¾„: {file_result['file_path']}\n")
                    f.write(f"åˆ—æ•°: {file_result['column_count']} (é¢„æœŸ: {self.expected_column_count})\n")
                    f.write(f"è¡Œæ•°: {file_result['row_count']} (é¢„æœŸ: 46)\n")
                    
                    if file_result['errors']:
                        f.write("é”™è¯¯:\n")
                        for error in file_result['errors']:
                            f.write(f"  - {error}\n")
                    
                    if file_result['warnings']:
                        f.write("è­¦å‘Š:\n")
                        for warning in file_result['warnings']:
                            f.write(f"  - {warning}\n")
                    
                    if file_result['data_type_issues']:
                        f.write(f"æ•°æ®ç±»å‹é—®é¢˜ ({len(file_result['data_type_issues'])}ä¸ª):\n")
                        for issue in file_result['data_type_issues']:
                            f.write(f"  - {issue['position']}: {issue['reason']}\n")
        
        print(f"\nğŸ“„ è¯¦ç»†éªŒè¯æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_path}")


class DynamicDataProcessor:
    """
    åŠ¨æ€æ‚£è€…æ•°æ®å¤„ç†å™¨
    ç”¨äºæ¸…ç†ã€é‡å‘½åå’Œå¤„ç†processedæ–‡ä»¶å¤¹ä¸­çš„CSVæ–‡ä»¶
    """
    
    def __init__(self, config: ConfigManager):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            config: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.config = config
        self.input_dir = config.get('input_dir')
        self.output_dir = config.get('output_dir')
        
        # å®šä¹‰è¦åˆ é™¤çš„åˆ—
        self.columns_to_delete = self._define_columns_to_delete()
        
        # å®šä¹‰å¯é€‰åˆ é™¤çš„åˆ—ï¼ˆVCN001å’ŒLymphocyte Subsetsåˆ—ï¼‰
        self.optional_columns = config.get('optional_columns')
        
        # å¤„ç†ç»“æœç»Ÿè®¡
        self.processing_results = {
            'processed_files': 0,
            'successful_files': 0,
            'failed_files': [],
            'errors': [],
            'warnings': []
        }
    
    def _define_columns_to_delete(self) -> List[str]:
        """å®šä¹‰è¦åˆ é™¤çš„åˆ—å"""
        columns_to_delete = []
        
        # CBCåˆ—è¦åˆ é™¤çš„
        cbc_to_delete = self.config.get('cbc_columns_to_delete')
        columns_to_delete.extend([f"CBC{str(i).zfill(3)}" for i in cbc_to_delete])
        
        # Biochemistryåˆ—è¦åˆ é™¤çš„
        biochemistry_to_delete = self.config.get('biochemistry_columns_to_delete')
        columns_to_delete.extend([f"Biochemistry{str(i).zfill(3)}" for i in biochemistry_to_delete])
        
        # Coagulationåˆ—è¦åˆ é™¤çš„
        coagulation_to_delete = self.config.get('coagulation_columns_to_delete')
        columns_to_delete.extend([f"Coagulation{str(i).zfill(3)}" for i in coagulation_to_delete])
        
        return columns_to_delete
    
    def _define_optional_columns(self) -> List[str]:
        """å®šä¹‰å¯é€‰åˆ é™¤çš„åˆ—å"""
        return self.config.get('optional_columns')
    
    def _rename_columns_with_same_prefix(self, df: pd.DataFrame, prefix: str) -> pd.DataFrame:
        """
        é‡å‘½åå…·æœ‰ç›¸åŒå‰ç¼€çš„åˆ—ï¼Œä¿æŒè¿ç»­ç¼–å·
        
        Args:
            df: æ•°æ®æ¡†
            prefix: åˆ—å‰ç¼€ï¼ˆå¦‚'CBC', 'Biochemistry', 'Coagulation'ï¼‰
            
        Returns:
            é‡å‘½ååçš„æ•°æ®æ¡†
        """
        # è·å–å…·æœ‰æŒ‡å®šå‰ç¼€çš„åˆ—
        prefix_columns = [col for col in df.columns if col.startswith(prefix)]
        
        if not prefix_columns:
            return df
        
        # æå–ç¼–å·å¹¶æ’åº
        column_numbers = []
        for col in prefix_columns:
            # æå–ç¼–å·éƒ¨åˆ†
            number_part = col.replace(prefix, "")
            try:
                number = int(number_part)
                column_numbers.append((number, col))
            except ValueError:
                # å¦‚æœä¸æ˜¯çº¯æ•°å­—ï¼Œä¿æŒåŸæ ·
                continue
        
        # æŒ‰ç¼–å·æ’åº
        column_numbers.sort(key=lambda x: x[0])
        
        # åˆ›å»ºé‡å‘½åæ˜ å°„
        rename_mapping = {}
        for new_index, (old_number, old_col) in enumerate(column_numbers, 1):
            new_col = f"{prefix}{str(new_index).zfill(3)}"
            if old_col != new_col:
                rename_mapping[old_col] = new_col
        
        # åº”ç”¨é‡å‘½å
        if rename_mapping:
            df = df.rename(columns=rename_mapping)
        
        return df
    
    def process_single_file(self, 
                           input_file_path: str, 
                           output_file_path: str,
                           remove_optional_columns: bool = False) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªCSVæ–‡ä»¶
        
        Args:
            input_file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            remove_optional_columns: æ˜¯å¦åˆ é™¤å¯é€‰åˆ—
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        file_name = os.path.basename(input_file_path)
        result = {
            'file_name': file_name,
            'success': False,
            'original_columns': 0,
            'final_columns': 0,
            'deleted_columns': [],
            'renamed_columns': {},
            'errors': [],
            'warnings': []
        }
        
        try:
            # è¯»å–æ–‡ä»¶
            df = pd.read_csv(input_file_path, index_col=0)
            result['original_columns'] = len(df.columns)
            
            # è®°å½•åˆ é™¤çš„åˆ—
            columns_to_delete = self.columns_to_delete.copy()
            if remove_optional_columns:
                columns_to_delete.extend(self.optional_columns)
            
            # åˆ é™¤æŒ‡å®šåˆ—
            deleted_columns = []
            for col in columns_to_delete:
                if col in df.columns:
                    df = df.drop(columns=[col])
                    deleted_columns.append(col)
                else:
                    result['warnings'].append(f"è¦åˆ é™¤çš„åˆ— '{col}' ä¸å­˜åœ¨äºæ–‡ä»¶ä¸­")
            
            result['deleted_columns'] = deleted_columns
            
            # é‡å‘½åå…·æœ‰ç›¸åŒå‰ç¼€çš„åˆ—
            prefixes_to_rename = ['CBC', 'Biochemistry', 'Coagulation']
            
            for prefix in prefixes_to_rename:
                # è®°å½•é‡å‘½åå‰çš„åˆ—å
                old_columns = [col for col in df.columns if col.startswith(prefix)]
                
                # æ‰§è¡Œé‡å‘½å
                df = self._rename_columns_with_same_prefix(df, prefix)
                
                # è®°å½•é‡å‘½åæ˜ å°„
                new_columns = [col for col in df.columns if col.startswith(prefix)]
                if len(old_columns) == len(new_columns):
                    for old_col, new_col in zip(sorted(old_columns), sorted(new_columns)):
                        if old_col != new_col:
                            result['renamed_columns'][old_col] = new_col
            
            result['final_columns'] = len(df.columns)
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_file_path), exist_ok=True)
            
            # ä¿å­˜å¤„ç†åçš„æ–‡ä»¶
            df.to_csv(output_file_path)
            result['success'] = True
            
        except FileNotFoundError:
            result['errors'].append(f"æ–‡ä»¶ä¸å­˜åœ¨: {input_file_path}")
        except pd.errors.EmptyDataError:
            result['errors'].append("æ–‡ä»¶ä¸ºç©º")
        except Exception as e:
            result['errors'].append(f"å¤„ç†å¤±è´¥: {str(e)}")
        
        return result
    
    def process_all_files(self, 
                         remove_optional_columns: bool = False,
                         verbose: bool = True) -> Dict[str, Any]:
        """
        å¤„ç†æ‰€æœ‰CSVæ–‡ä»¶
        
        Args:
            remove_optional_columns: æ˜¯å¦åˆ é™¤å¯é€‰åˆ—ï¼ˆVCN001å’ŒLymphocyte Subsetsï¼‰
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        print(f"å¼€å§‹å¤„ç†åŠ¨æ€æ‚£è€…æ•°æ®æ–‡ä»¶...")
        print("=" * 70)
        
        # è·å–æ‰€æœ‰CSVæ–‡ä»¶
        csv_files = list(Path(self.input_dir).glob("*.csv"))
        total_files = len(csv_files)
        
        print(f"è¾“å…¥ç›®å½•: {self.input_dir}")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"å‘ç° {total_files} ä¸ªCSVæ–‡ä»¶")
        print(f"å¯é€‰åˆ—åˆ é™¤: {'æ˜¯' if remove_optional_columns else 'å¦'}")
        
        # æ˜¾ç¤ºå°†è¦åˆ é™¤çš„åˆ—
        cbc_to_delete = self.config.get('cbc_columns_to_delete')
        biochemistry_to_delete = self.config.get('biochemistry_columns_to_delete')
        coagulation_to_delete = self.config.get('coagulation_columns_to_delete')
        
        print(f"\nè¦åˆ é™¤çš„åˆ—:")
        print(f"- CBCåˆ—: {[f'CBC{str(i).zfill(3)}' for i in cbc_to_delete]}")
        print(f"- Biochemistryåˆ—: {[f'Biochemistry{str(i).zfill(3)}' for i in biochemistry_to_delete]}")
        print(f"- Coagulationåˆ—: {[f'Coagulation{str(i).zfill(3)}' for i in coagulation_to_delete]}")
        
        if remove_optional_columns:
            print(f"- å¯é€‰åˆ—: {self.optional_columns}")
        
        print("-" * 70)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        
        # å¤„ç†è¿›åº¦ç»Ÿè®¡
        successful_count = 0
        failed_count = 0
        
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        progress_interval = self.config.get('progress_interval')
        for i, input_file_path in enumerate(csv_files, 1):
            if verbose and (i % progress_interval == 0 or i == total_files):
                print(f"è¿›åº¦: {i}/{total_files}")
            
            # æ„å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
            file_name = input_file_path.name
            output_file_path = os.path.join(self.output_dir, file_name)
            
            # å¤„ç†æ–‡ä»¶
            result = self.process_single_file(
                str(input_file_path), 
                output_file_path, 
                remove_optional_columns
            )
            
            self.processing_results['processed_files'] += 1
            
            if result['success']:
                successful_count += 1
                if verbose and result['warnings']:
                    print(f"\nâš ï¸  æ–‡ä»¶ {result['file_name']} æœ‰è­¦å‘Š:")
                    for warning in result['warnings']:
                        print(f"   - {warning}")
            else:
                failed_count += 1
                self.processing_results['failed_files'].append(result)
                
                # è¾“å‡ºé”™è¯¯ä¿¡æ¯
                print(f"\nâŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {result['file_name']}")
                for error in result['errors']:
                    print(f"   é”™è¯¯: {error}")
                    self.processing_results['errors'].append(f"{result['file_name']}: {error}")
                
                for warning in result['warnings']:
                    print(f"   è­¦å‘Š: {warning}")
                    self.processing_results['warnings'].append(f"{result['file_name']}: {warning}")
        
        self.processing_results['successful_files'] = successful_count
        
        # è¾“å‡ºå¤„ç†æ€»ç»“
        self._print_processing_summary()
        
        return self.processing_results
    
    def _print_processing_summary(self):
        """æ‰“å°å¤„ç†æ€»ç»“"""
        print("\n" + "=" * 70)
        print("æ•°æ®å¤„ç†ç»“æœæ€»ç»“")
        print("=" * 70)
        
        print(f"å¤„ç†çš„æ–‡ä»¶æ€»æ•°: {self.processing_results['processed_files']}")
        print(f"æˆåŠŸå¤„ç†çš„æ–‡ä»¶: {self.processing_results['successful_files']}")
        print(f"å¤„ç†å¤±è´¥çš„æ–‡ä»¶: {len(self.processing_results['failed_files'])}")
        print(f"é”™è¯¯æ€»æ•°: {len(self.processing_results['errors'])}")
        print(f"è­¦å‘Šæ€»æ•°: {len(self.processing_results['warnings'])}")
        
        if self.processing_results['errors']:
            print(f"\nâŒ å‘ç° {len(self.processing_results['errors'])} ä¸ªé”™è¯¯:")
            for error in self.processing_results['errors'][:10]:  # æ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                print(f"   - {error}")
            if len(self.processing_results['errors']) > 10:
                print(f"   - ... è¿˜æœ‰ {len(self.processing_results['errors']) - 10} ä¸ªé”™è¯¯")
        
        if self.processing_results['warnings']:
            print(f"\nâš ï¸  å‘ç° {len(self.processing_results['warnings'])} ä¸ªè­¦å‘Š:")
            for warning in self.processing_results['warnings'][:5]:  # æ˜¾ç¤ºå‰5ä¸ªè­¦å‘Š
                print(f"   - {warning}")
            if len(self.processing_results['warnings']) > 5:
                print(f"   - ... è¿˜æœ‰ {len(self.processing_results['warnings']) - 5} ä¸ªè­¦å‘Š")
        
        if len(self.processing_results['failed_files']) == 0:
            print("\nâœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")
            print(f"ğŸ“ å¤„ç†åçš„æ–‡ä»¶ä¿å­˜åœ¨: {self.output_dir}")
        else:
            print(f"\nâŒ {len(self.processing_results['failed_files'])} ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥")
    
    def export_processing_report(self, output_path: str = None):
        """å¯¼å‡ºè¯¦ç»†çš„å¤„ç†æŠ¥å‘Š"""
        if output_path is None:
            output_path = self.config.get('processing_report_path')
            
        cbc_to_delete = self.config.get('cbc_columns_to_delete')
        biochemistry_to_delete = self.config.get('biochemistry_columns_to_delete')
        coagulation_to_delete = self.config.get('coagulation_columns_to_delete')
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("åŠ¨æ€æ‚£è€…æ•°æ®å¤„ç†æŠ¥å‘Š\n")
            f.write("=" * 70 + "\n\n")
            
            f.write(f"å¤„ç†æ—¶é—´: {datetime.now()}\n")
            f.write(f"è¾“å…¥ç›®å½•: {self.input_dir}\n")
            f.write(f"è¾“å‡ºç›®å½•: {self.output_dir}\n\n")
            
            f.write("åˆ é™¤çš„åˆ—:\n")
            f.write(f"- CBCåˆ—: {[f'CBC{str(i).zfill(3)}' for i in cbc_to_delete]}\n")
            f.write(f"- Biochemistryåˆ—: {[f'Biochemistry{str(i).zfill(3)}' for i in biochemistry_to_delete]}\n")
            f.write(f"- Coagulationåˆ—: {[f'Coagulation{str(i).zfill(3)}' for i in coagulation_to_delete]}\n\n")
            
            f.write("å¤„ç†ç»“æœæ€»ç»“:\n")
            f.write(f"- å¤„ç†æ–‡ä»¶æ•°: {self.processing_results['processed_files']}\n")
            f.write(f"- æˆåŠŸæ–‡ä»¶æ•°: {self.processing_results['successful_files']}\n")
            f.write(f"- å¤±è´¥æ–‡ä»¶æ•°: {len(self.processing_results['failed_files'])}\n")
            f.write(f"- é”™è¯¯æ€»æ•°: {len(self.processing_results['errors'])}\n")
            f.write(f"- è­¦å‘Šæ€»æ•°: {len(self.processing_results['warnings'])}\n\n")
            
            if self.processing_results['errors']:
                f.write("é”™è¯¯åˆ—è¡¨:\n")
                f.write("-" * 40 + "\n")
                for error in self.processing_results['errors']:
                    f.write(f"âŒ {error}\n")
                f.write("\n")
            
            if self.processing_results['warnings']:
                f.write("è­¦å‘Šåˆ—è¡¨:\n")
                f.write("-" * 40 + "\n")
                for warning in self.processing_results['warnings']:
                    f.write(f"âš ï¸  {warning}\n")
                f.write("\n")
            
            if self.processing_results['failed_files']:
                f.write("å¤±è´¥æ–‡ä»¶è¯¦æƒ…:\n")
                f.write("-" * 40 + "\n")
                for file_result in self.processing_results['failed_files']:
                    f.write(f"\næ–‡ä»¶: {file_result['file_name']}\n")
                    
                    if file_result['errors']:
                        f.write("é”™è¯¯:\n")
                        for error in file_result['errors']:
                            f.write(f"  - {error}\n")
                    
                    if file_result['warnings']:
                        f.write("è­¦å‘Š:\n")
                        for warning in file_result['warnings']:
                            f.write(f"  - {warning}\n")
        
        print(f"\nğŸ“„ è¯¦ç»†å¤„ç†æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_path}")


class StepExecutor:
    """
    æ­¥éª¤æ‰§è¡Œå™¨
    ç®¡ç†æ•°æ®éªŒè¯å’Œå¤„ç†æ­¥éª¤çš„æ‰§è¡Œ
    """
    
    def __init__(self, config: ConfigManager):
        """
        åˆå§‹åŒ–æ­¥éª¤æ‰§è¡Œå™¨
        
        Args:
            config: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.config = config
        self.validation_results = None
        self.processing_results = None
    
    def validate_step_configuration(self):
        """éªŒè¯æ­¥éª¤é…ç½®çš„æœ‰æ•ˆæ€§"""
        validation_only = self.config.get('validation_only')
        processing_only = self.config.get('processing_only')
        enable_validation = self.config.get('enable_validation')
        enable_processing = self.config.get('enable_processing')
        
        # æ£€æŸ¥äº’æ–¥é€‰é¡¹
        if validation_only and processing_only:
            print("é”™è¯¯: ä¸èƒ½åŒæ—¶æŒ‡å®š --validation-only å’Œ --processing-only")
            sys.exit(1)
        
        # åº”ç”¨ä¸“ç”¨æ­¥éª¤è®¾ç½®
        if validation_only:
            self.config.set('enable_validation', True)
            self.config.set('enable_processing', False)
        elif processing_only:
            self.config.set('enable_validation', False)
            self.config.set('enable_processing', True)
        
        # æ£€æŸ¥æ˜¯å¦è‡³å°‘å¯ç”¨ä¸€ä¸ªæ­¥éª¤
        final_validation = self.config.get('enable_validation')
        final_processing = self.config.get('enable_processing')
        
        if not final_validation and not final_processing:
            print("é”™è¯¯: å¿…é¡»è‡³å°‘å¯ç”¨ä¸€ä¸ªæ­¥éª¤ï¼ˆéªŒè¯æˆ–å¤„ç†ï¼‰")
            sys.exit(1)
    
    def print_execution_plan(self):
        """æ‰“å°æ‰§è¡Œè®¡åˆ’"""
        enable_validation = self.config.get('enable_validation')
        enable_processing = self.config.get('enable_processing')
        skip_interactive = self.config.get('skip_interactive')
        
        print("\nğŸ“‹ æ‰§è¡Œè®¡åˆ’:")
        print("-" * 50)
        
        if enable_validation:
            print("âœ… æ•°æ®éªŒè¯æ­¥éª¤: å¯ç”¨")
        else:
            print("âŒ æ•°æ®éªŒè¯æ­¥éª¤: ç¦ç”¨")
        
        if enable_processing:
            print("âœ… æ•°æ®å¤„ç†æ­¥éª¤: å¯ç”¨")
        else:
            print("âŒ æ•°æ®å¤„ç†æ­¥éª¤: ç¦ç”¨")
        
        if skip_interactive:
            print("âš™ï¸  äº¤äº’æ¨¡å¼: ç¦ç”¨ï¼ˆä½¿ç”¨é…ç½®å€¼ï¼‰")
        else:
            print("âš™ï¸  äº¤äº’æ¨¡å¼: å¯ç”¨")
        
        print("-" * 50)
    
    def execute_validation_step(self) -> bool:
        """
        æ‰§è¡Œæ•°æ®éªŒè¯æ­¥éª¤
        
        Returns:
            bool: éªŒè¯æ˜¯å¦æˆåŠŸ
        """
        if not self.config.get('enable_validation'):
            print("â­ï¸  è·³è¿‡æ•°æ®éªŒè¯æ­¥éª¤ï¼ˆå·²ç¦ç”¨ï¼‰")
            return True
        
        print("\nğŸ” æ‰§è¡Œæ•°æ®éªŒè¯æ­¥éª¤")
        print("=" * 60)
        
        validator = DynamicDataValidator(self.config)
        print(f"é¢„æœŸå˜é‡ç±»åˆ«æ€»æ•°: {validator.expected_column_count}")
        print("å˜é‡ç±»åˆ«åˆ†å¸ƒ:")
        
        variable_categories = self.config.get('variable_categories')
        for category, count in variable_categories.items():
            if category == 'VCN':
                print(f"- {category}: {count}ä¸ªå˜é‡ ({category}001)")
            else:
                print(f"- {category}: {count}ä¸ªå˜é‡ ({category}001-{category}{str(count).zfill(3)})")
        
        # æ‰§è¡ŒéªŒè¯
        self.validation_results = validator.validate_all_files()
        validator.export_validation_report()
        
        # æ£€æŸ¥éªŒè¯ç»“æœ
        has_valid_files = self.validation_results['valid_files'] > 0
        
        if has_valid_files:
            print(f"âœ… éªŒè¯å®Œæˆï¼šå‘ç° {self.validation_results['valid_files']} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
        else:
            print("âŒ éªŒè¯å¤±è´¥ï¼šæ²¡æœ‰å‘ç°æœ‰æ•ˆæ–‡ä»¶")
        
        return has_valid_files
    
    def execute_processing_step(self, validation_success: bool = True) -> bool:
        """
        æ‰§è¡Œæ•°æ®å¤„ç†æ­¥éª¤
        
        Args:
            validation_success: éªŒè¯æ­¥éª¤æ˜¯å¦æˆåŠŸ
            
        Returns:
            bool: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        if not self.config.get('enable_processing'):
            print("â­ï¸  è·³è¿‡æ•°æ®å¤„ç†æ­¥éª¤ï¼ˆå·²ç¦ç”¨ï¼‰")
            return True
        
        # å¦‚æœå¯ç”¨äº†éªŒè¯æ­¥éª¤ä½†éªŒè¯å¤±è´¥ï¼Œåˆ™è·³è¿‡å¤„ç†
        enable_validation = self.config.get('enable_validation')
        if enable_validation and not validation_success:
            print("â­ï¸  è·³è¿‡æ•°æ®å¤„ç†æ­¥éª¤ï¼ˆéªŒè¯æ­¥éª¤å¤±è´¥ï¼‰")
            return False
        
        print("\nğŸ”§ æ‰§è¡Œæ•°æ®å¤„ç†æ­¥éª¤")
        print("=" * 60)
        
        # ç¡®å®šæ˜¯å¦åˆ é™¤å¯é€‰åˆ—
        remove_optional = self._determine_optional_columns_removal()
        
        if remove_optional:
            print("âœ… å°†åˆ é™¤å¯é€‰åˆ—")
        else:
            print("âœ… å°†ä¿ç•™å¯é€‰åˆ—")
        
        # åˆ›å»ºå¤„ç†å™¨å¹¶æ‰§è¡Œå¤„ç†
        processor = DynamicDataProcessor(self.config)
        self.processing_results = processor.process_all_files(
            remove_optional_columns=remove_optional,
            verbose=self.config.get('verbose')
        )
        
        # å¯¼å‡ºå¤„ç†æŠ¥å‘Š
        processor.export_processing_report()
        
        # æ£€æŸ¥å¤„ç†ç»“æœ
        success = self.processing_results['successful_files'] > 0
        
        if success:
            print(f"âœ… å¤„ç†å®Œæˆï¼šæˆåŠŸå¤„ç† {self.processing_results['successful_files']} ä¸ªæ–‡ä»¶")
            print(f"ğŸ“ å¤„ç†åçš„æ–‡ä»¶ä½äº: {processor.output_dir}")
        else:
            print("âŒ å¤„ç†å¤±è´¥ï¼šæ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡ä»¶")
        
        return success
    
    def _determine_optional_columns_removal(self) -> bool:
        """ç¡®å®šæ˜¯å¦åˆ é™¤å¯é€‰åˆ—"""
        remove_optional = self.config.get('remove_optional_columns')
        skip_interactive = self.config.get('skip_interactive')
        
        # å¦‚æœå·²ç»é€šè¿‡é…ç½®æŒ‡å®šæˆ–è·³è¿‡äº¤äº’ï¼Œç›´æ¥è¿”å›é…ç½®å€¼
        if remove_optional or skip_interactive:
            return remove_optional
        
        # äº¤äº’å¼è¯¢é—®
        print("\né…ç½®é€‰é¡¹:")
        print("æ˜¯å¦åˆ é™¤å¯é€‰åˆ—ï¼ˆVCN001å’ŒLymphocyte Subsets001-011ï¼‰ï¼Ÿ")
        print("1. æ˜¯ - åˆ é™¤æ‰€æœ‰å¯é€‰åˆ—")
        print("2. å¦ - ä¿ç•™å¯é€‰åˆ—ï¼ˆé»˜è®¤ï¼‰")
        
        choice = input("è¯·é€‰æ‹© (1/2ï¼Œé»˜è®¤ä¸º2): ").strip()
        return choice == "1"
    
    def execute_all_steps(self):
        """æ‰§è¡Œæ‰€æœ‰å¯ç”¨çš„æ­¥éª¤"""
        self.validate_step_configuration()
        self.print_execution_plan()
        
        # æ‰§è¡ŒéªŒè¯æ­¥éª¤
        validation_success = self.execute_validation_step()
        
        # æ‰§è¡Œå¤„ç†æ­¥éª¤
        processing_success = self.execute_processing_step(validation_success)
        
        # æ‰“å°æœ€ç»ˆç»“æœ
        self._print_final_results(validation_success, processing_success)
    
    def _print_final_results(self, validation_success: bool, processing_success: bool):
        """æ‰“å°æœ€ç»ˆæ‰§è¡Œç»“æœ"""
        print("\n" + "=" * 80)
        print("æ‰§è¡Œç»“æœæ€»ç»“")
        print("=" * 80)
        
        enable_validation = self.config.get('enable_validation')
        enable_processing = self.config.get('enable_processing')
        
        if enable_validation:
            if validation_success:
                print("âœ… æ•°æ®éªŒè¯æ­¥éª¤: æˆåŠŸå®Œæˆ")
                if self.validation_results:
                    print(f"   - å¤„ç†æ–‡ä»¶æ•°: {self.validation_results['processed_files']}")
                    print(f"   - æœ‰æ•ˆæ–‡ä»¶æ•°: {self.validation_results['valid_files']}")
            else:
                print("âŒ æ•°æ®éªŒè¯æ­¥éª¤: æ‰§è¡Œå¤±è´¥")
        
        if enable_processing:
            if processing_success:
                print("âœ… æ•°æ®å¤„ç†æ­¥éª¤: æˆåŠŸå®Œæˆ")
                if self.processing_results:
                    print(f"   - å¤„ç†æ–‡ä»¶æ•°: {self.processing_results['processed_files']}")
                    print(f"   - æˆåŠŸæ–‡ä»¶æ•°: {self.processing_results['successful_files']}")
            else:
                print("âŒ æ•°æ®å¤„ç†æ­¥éª¤: æ‰§è¡Œå¤±è´¥")
        
        overall_success = (not enable_validation or validation_success) and (not enable_processing or processing_success)
        
        if overall_success:
            print("\nğŸ‰ æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆï¼")
        else:
            print("\nâŒ éƒ¨åˆ†æ­¥éª¤æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æŠ¥å‘Šæ–‡ä»¶äº†è§£è¯¦æƒ…")
        
        print("=" * 80)


# ==================== ä¸»æ‰§è¡Œéƒ¨åˆ† ====================

if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()
    
    # å¤„ç†å®ç”¨åŠŸèƒ½
    if args.create_sample_config:
        create_sample_config()
        sys.exit(0)
    
    # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
    config = ConfigManager()
    
    # æŒ‰ä¼˜å…ˆé¡ºåºåŠ è½½é…ç½®
    config.load_from_env()  # ç¯å¢ƒå˜é‡
    
    if args.config_file:  # é…ç½®æ–‡ä»¶
        config.load_from_yaml(args.config_file)
    
    config.load_from_args(args)  # å‘½ä»¤è¡Œå‚æ•°
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    if args.print_config:
        config.print_config()
        sys.exit(0)
    
    # éªŒè¯é…ç½®
    config.validate_config()
    
    print("=" * 80)
    print("CAR-Tæ²»ç–—ä¸´åºŠæ•°æ®å¤„ç†ç³»ç»Ÿ")
    print("=" * 80)
    
    # åˆ›å»ºå¹¶æ‰§è¡Œæ­¥éª¤
    executor = StepExecutor(config)
    executor.execute_all_steps()