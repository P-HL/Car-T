#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Geminiå¯¹è¯è½¬Markdownè½¬æ¢å™¨
ä¸“é—¨ç”¨äºè½¬æ¢ Gemini API æ ¼å¼çš„å¯¹è¯æ–‡ä»¶

ä½œè€…: GitHub Copilot
ç‰ˆæœ¬: 4.0.0
"""

import os
import re
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional


def extract_conversations_from_gemini_file(file_path: str) -> List[Dict[str, Any]]:
    """
    ç›´æ¥ä»Geminiæ–‡ä»¶ä¸­æå–å¯¹è¯å†…å®¹
    
    Args:
        file_path: Gemini Pythonæ–‡ä»¶è·¯å¾„
        
    Returns:
        å¯¹è¯åˆ—è¡¨
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
        
        # æŸ¥æ‰¾contentsæ•°ç»„çš„èµ·å§‹ä½ç½®
        contents_start = content.find('contents = [')
        if contents_start == -1:
            contents_start = content.find('contents=[')
        
        if contents_start == -1:
            print("âŒ æœªæ‰¾åˆ° contents æ•°ç»„")
            return []
        
        print(f"âœ… æ‰¾åˆ° contents æ•°ç»„ï¼Œèµ·å§‹ä½ç½®: {contents_start}")
        
        # æ‰¾åˆ°å¯¹åº”çš„ç»“æŸä½ç½®ï¼ˆæ‰¾åˆ°åŒ¹é…çš„æ–¹æ‹¬å·ï¼‰
        bracket_count = 0
        contents_end = contents_start
        in_contents = False
        
        for i in range(contents_start, len(content)):
            char = content[i]
            if char == '[':
                bracket_count += 1
                in_contents = True
            elif char == ']':
                bracket_count -= 1
                if in_contents and bracket_count == 0:
                    contents_end = i + 1
                    break
        
        # æå–contentså†…å®¹
        contents_section = content[contents_start:contents_end]
        print(f"âœ… æå– contents éƒ¨åˆ†ï¼Œé•¿åº¦: {len(contents_section)} å­—ç¬¦")
        
        # æŸ¥æ‰¾æ‰€æœ‰çš„text="""..."""å†…å®¹
        conversations = []
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ‰€æœ‰çš„ types.Content å—
        content_pattern = r'types\.Content\s*\(\s*role\s*=\s*["\'](\w+)["\'].*?text\s*=\s*"""(.*?)"""\s*\)'
        matches = re.findall(content_pattern, contents_section, re.DOTALL)
        
        print(f"âœ… æ‰¾åˆ° {len(matches)} ä¸ªå¯¹è¯ç‰‡æ®µ")
        
        for i, (role, text) in enumerate(matches):
            conversations.append({
                'role': role,
                'content': text.strip(),
                'index': i + 1
            })
            print(f"  - {role}: {len(text)} å­—ç¬¦")
        
        return conversations
        
    except Exception as e:
        print(f"âŒ æå–å¯¹è¯æ—¶å‡ºé”™: {e}")
        return []


def extract_metadata_from_file(file_path: str, content: str) -> Dict[str, Any]:
    """
    æå–æ–‡ä»¶å…ƒæ•°æ®
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        content: æ–‡ä»¶å†…å®¹
        
    Returns:
        å…ƒæ•°æ®å­—å…¸
    """
    metadata = {
        'file_name': os.path.basename(file_path),
        'file_path': file_path,
        'creation_time': datetime.now().isoformat(),
        'model': None,
        'api_key_ref': None,
        'file_size': f"{len(content)} å­—ç¬¦",
        'total_lines': len(content.split('\n'))
    }
    
    # æå–æ¨¡å‹ä¿¡æ¯
    model_match = re.search(r'model\s*=\s*["\']([^"\']+)["\']', content)
    if model_match:
        metadata['model'] = model_match.group(1)
    
    # æå–APIå¯†é’¥å¼•ç”¨
    api_key_match = re.search(r'api_key\s*=\s*os\.environ\.get\(["\']([^"\']+)["\']\)', content)
    if api_key_match:
        metadata['api_key_ref'] = api_key_match.group(1)
    
    return metadata


def generate_markdown_document(conversations: List[Dict[str, Any]], metadata: Dict[str, Any]) -> str:
    """
    ç”ŸæˆMarkdownæ–‡æ¡£
    
    Args:
        conversations: å¯¹è¯åˆ—è¡¨
        metadata: å…ƒæ•°æ®
        
    Returns:
        Markdownå†…å®¹
    """
    md_lines = []
    
    # æ ‡é¢˜
    file_name = metadata.get('file_name', 'Unknown')
    md_lines.append(f"# ğŸ“ Gemini å¯¹è¯è®°å½•: {file_name}\n")
    
    # ç”Ÿæˆæ—¶é—´
    creation_time = metadata.get('creation_time', '')
    if creation_time:
        try:
            dt = datetime.fromisoformat(creation_time.replace('Z', '+00:00'))
            formatted_date = dt.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
            md_lines.append(f"**ç”Ÿæˆæ—¶é—´:** {formatted_date}\n")
        except:
            pass
    
    # æ–‡æ¡£ä¿¡æ¯
    md_lines.append("## ğŸ“Š æ–‡æ¡£ä¿¡æ¯\n")
    md_lines.append("| é¡¹ç›® | å€¼ |")
    md_lines.append("|------|-----|")
    md_lines.append(f"| æ–‡ä»¶å | `{metadata.get('file_name', 'N/A')}` |")
    
    if metadata.get('model'):
        md_lines.append(f"| AIæ¨¡å‹ | `{metadata['model']}` |")
    
    if metadata.get('api_key_ref'):
        md_lines.append(f"| APIå¯†é’¥ç¯å¢ƒå˜é‡ | `{metadata['api_key_ref']}` |")
    
    md_lines.append(f"| æ–‡ä»¶å¤§å° | {metadata.get('file_size', 'N/A')} |")
    md_lines.append(f"| æ€»è¡Œæ•° | {metadata.get('total_lines', 'N/A')} è¡Œ |")
    md_lines.append(f"| å¯¹è¯æ•°é‡ | {len(conversations)} æ¡ |\n")
    
    # ç›®å½•ï¼ˆå¦‚æœå¯¹è¯è¾ƒå¤šï¼‰
    user_count = sum(1 for conv in conversations if conv['role'] == 'user')
    if user_count > 3:
        md_lines.append("## ğŸ“‹ ç›®å½•\n")
        round_num = 0
        for conv in conversations:
            if conv['role'] == 'user':
                round_num += 1
                title = conv['content'][:50].replace('\n', ' ').strip()
                if len(conv['content']) > 50:
                    title += '...'
                md_lines.append(f"{round_num}. [å¯¹è¯è½®æ¬¡ {round_num}: {title}](#å¯¹è¯è½®æ¬¡-{round_num})")
        md_lines.append("")
    
    # å¯¹è¯å†…å®¹
    md_lines.append("## ğŸ’¬ å¯¹è¯å†…å®¹\n")
    
    if not conversations:
        md_lines.append("âš ï¸ **æœªæ‰¾åˆ°å¯¹è¯å†…å®¹**\n")
        return '\n'.join(md_lines)
    
    # ç”Ÿæˆå¯¹è¯
    round_num = 0
    i = 0
    
    while i < len(conversations):
        conv = conversations[i]
        
        if conv['role'] == 'user':
            round_num += 1
            md_lines.append(f"### å¯¹è¯è½®æ¬¡ {round_num}\n")
            
            # ç”¨æˆ·æ¶ˆæ¯
            md_lines.append("#### ğŸ‘¤ ç”¨æˆ·\n")
            md_lines.append(format_message_content(conv['content']))
            md_lines.append("")
            
            # æŸ¥æ‰¾å¯¹åº”çš„AIå›å¤
            if i + 1 < len(conversations) and conversations[i + 1]['role'] == 'model':
                ai_conv = conversations[i + 1]
                md_lines.append("#### ğŸ¤– AIåŠ©æ‰‹\n")
                md_lines.append(format_message_content(ai_conv['content']))
                md_lines.append("")
                i += 2
            else:
                i += 1
            
            md_lines.append("---\n")
        
        elif conv['role'] == 'model':
            # ç‹¬ç«‹çš„AIæ¶ˆæ¯
            round_num += 1
            md_lines.append(f"### AIæ¶ˆæ¯ {round_num}\n")
            md_lines.append("#### ğŸ¤– AIåŠ©æ‰‹\n")
            md_lines.append(format_message_content(conv['content']))
            md_lines.append("")
            md_lines.append("---\n")
            i += 1
        else:
            i += 1
    
    return '\n'.join(md_lines)


def format_message_content(content: str) -> str:
    """
    æ ¼å¼åŒ–æ¶ˆæ¯å†…å®¹
    
    Args:
        content: åŸå§‹å†…å®¹
        
    Returns:
        æ ¼å¼åŒ–åçš„å†…å®¹
    """
    # å¦‚æœå·²ç»åŒ…å«ä»£ç å—ï¼Œç›´æ¥è¿”å›
    if '```' in content:
        return content
    
    # æ£€æµ‹æ˜¯å¦æ˜¯ä»£ç å†…å®¹
    code_indicators = [
        'import ', 'def ', 'class ', 'if __name__', 'print(', 'return ',
        'import pandas', 'import numpy', 'import matplotlib', 'import seaborn',
        '.py', '.csv', 'DataFrame', 'plt.', 'sns.', 'def main', '# ',
        'for ', 'while ', 'try:', 'except:', 'with open'
    ]
    
    code_count = sum(1 for indicator in code_indicators if indicator in content)
    
    # å¦‚æœåŒ…å«å¤šä¸ªä»£ç ç‰¹å¾ï¼ŒåŒ…è£…ä¸ºä»£ç å—
    if code_count >= 3 or content.count('\n') > 10:
        return f'```python\n{content}\n```'
    
    return content


def convert_gemini_to_markdown(input_file: str, output_file: Optional[str] = None) -> str:
    """
    è½¬æ¢Geminiæ–‡ä»¶ä¸ºMarkdown
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    print(f"ğŸš€ å¼€å§‹è½¬æ¢æ–‡ä»¶: {input_file}")
    
    # è¯»å–æ–‡ä»¶
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return ""
    
    # æå–å¯¹è¯
    conversations = extract_conversations_from_gemini_file(input_file)
    
    # æå–å…ƒæ•°æ®
    metadata = extract_metadata_from_file(input_file, content)
    
    # ç”ŸæˆMarkdown
    markdown_content = generate_markdown_document(conversations, metadata)
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_file is None:
        input_path = Path(input_file)
        output_file = input_path.parent / f"{input_path.stem}_conversation.md"
    
    # ä¿å­˜æ–‡ä»¶
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        print(f"âœ… è½¬æ¢å®Œæˆ: {output_file}")
        print(f"ğŸ“Š æå–äº† {len(conversations)} æ¡å¯¹è¯")
        return str(output_file)
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return ""


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Geminiå¯¹è¯è½¬Markdownè½¬æ¢å™¨")
    parser.add_argument('input', help='è¾“å…¥çš„Gemini Pythonæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºMarkdownæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return 1
    
    # è½¬æ¢æ–‡ä»¶
    result = convert_gemini_to_markdown(args.input, args.output)
    
    if result:
        print(f"ğŸ‰ è½¬æ¢æˆåŠŸï¼è¾“å‡ºæ–‡ä»¶: {result}")
        return 0
    else:
        print("âŒ è½¬æ¢å¤±è´¥")
        return 1


if __name__ == '__main__':
    exit(main())