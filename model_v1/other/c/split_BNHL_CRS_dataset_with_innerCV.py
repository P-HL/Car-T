"""
Enhanced split script with 70/30 split + 5-fold internal GroupStratifiedKFold
-------------------------------------------------------------------------------
åŠŸèƒ½ï¼š
1. ä¸»åˆ’åˆ†ï¼šStratifiedShuffleSplit (70% train / 30% test)
2. å†…éƒ¨åˆ’åˆ†ï¼šåœ¨è®­ç»ƒé›†ä¸Šæ‰§è¡Œ5æŠ˜ GroupStratifiedKFoldï¼ˆè¿‘ä¼¼å®ç°ï¼‰
3. æ¯æŠ˜ä¿å­˜ train/val ç—…äººIDæ–‡ä»¶
4. è¾“å‡ºå…ƒä¿¡æ¯ metadata_split.yaml
-------------------------------------------------------------------------------
åœ¨split_BNHL_CRS_dataset.py åŸºç¡€ä¸Šå‡çº§ï¼Œè®©å®ƒåœ¨ è®­ç»ƒé›† (70%) å†…éƒ¨ å†è¿›è¡Œ 5 æŠ˜ Group + Stratified åŒå±‚äº¤å‰éªŒè¯åˆ’åˆ†ã€‚

ğŸ¯ åŠŸèƒ½ç›®æ ‡
å‡çº§ç‰ˆè„šæœ¬å®ç°ä»¥ä¸‹åŠŸèƒ½ï¼š
	1.	å…ˆæ‰§è¡Œ 70/30 ä¸»åˆ’åˆ†ï¼ˆä¿æŒç±»åˆ«åˆ†å¸ƒä¸€è‡´ï¼Œæ‚£è€…çº§ç‹¬ç«‹ï¼‰ï¼›
	2.	å†å¯¹è®­ç»ƒé›†ï¼ˆ70%éƒ¨åˆ†ï¼‰åš 5 æŠ˜ GroupStratifiedKFoldï¼š
	â€¢	ä¿è¯ä¸¥é‡ CRSï¼ˆlabel=1ï¼‰çš„æ¯”ä¾‹åœ¨å„æŠ˜ä¸­è¿‘ä¼¼ä¸€è‡´ï¼›
	â€¢	åŒæ—¶ä¿è¯åŒä¸€ patient_id ä¸å‡ºç°åœ¨ä¸åŒæŠ˜ï¼›
 	3.	è‡ªåŠ¨è¾“å‡ºï¼š
BNHL_CRS_split_70_30/
â”œâ”€â”€ train_static.csv
â”œâ”€â”€ test_static.csv
â”œâ”€â”€ fold_splits/
â”‚    â”œâ”€â”€ fold1_train_ids.txt
â”‚    â”œâ”€â”€ fold1_val_ids.txt
â”‚    â”œâ”€â”€ fold2_train_ids.txt
â”‚    â”œâ”€â”€ fold2_val_ids.txt
â”‚    â””â”€â”€ ...
â””â”€â”€ metadata_split.yaml
-------------------------------------------------------------------------------
ğŸ§  èƒŒæ™¯é€»è¾‘
	â€¢	GroupKFold å¯ç¡®ä¿â€œåŒä¸€ç—…äººä¸ä¼šå‡ºç°åœ¨ä¸åŒæŠ˜â€ï¼›
	â€¢	StratifiedKFold ä¿è¯ label åˆ†å¸ƒå¹³è¡¡ï¼›
	â€¢	sklearn æ²¡æœ‰å®˜æ–¹ â€œGroupStratifiedKFoldâ€ï¼Œä½†æˆ‘ä»¬å¯ä»¥å®ç°ä¸€ä¸ªç®€æ´å¯é çš„è¿‘ä¼¼ç‰ˆæœ¬ï¼š
	â€¢	å…ˆæŒ‰ label åˆ†å±‚ï¼›
	â€¢	åœ¨æ¯ä¸ªç±»åˆ«ä¸­éšæœºåˆ†ç»„ï¼›
	â€¢	æ‹¼åˆæˆæ¯æŠ˜è¿‘ä¼¼å¹³è¡¡çš„ç»“æ„ã€‚
 
-------------------------------------------------------------------------------
  ğŸ—‚ï¸ è¾“å‡ºç›®å½•ç»“æ„
 BNHL_CRS_split_70_30/
â”œâ”€â”€ train_static.csv
â”œâ”€â”€ test_static.csv
â”œâ”€â”€ train_ids.txt
â”œâ”€â”€ test_ids.txt
â”œâ”€â”€ fold_splits/
â”‚   â”œâ”€â”€ fold1_train_ids.txt
â”‚   â”œâ”€â”€ fold1_val_ids.txt
â”‚   â”œâ”€â”€ fold2_train_ids.txt
â”‚   â”œâ”€â”€ fold2_val_ids.txt
â”‚   â”œâ”€â”€ fold3_train_ids.txt
â”‚   â”œâ”€â”€ fold3_val_ids.txt
â”‚   â”œâ”€â”€ fold4_train_ids.txt
â”‚   â”œâ”€â”€ fold4_val_ids.txt
â”‚   â”œâ”€â”€ fold5_train_ids.txt
â”‚   â””â”€â”€ fold5_val_ids.txt
â””â”€â”€ metadata_split.yaml
-------------------------------------------------------------------------------
 ğŸ“Š å…¸å‹ç»ˆç«¯è¾“å‡ºç¤ºä¾‹
 æ€»æ ·æœ¬æ•°: 447
0    409
1     38
Name: label, dtype: int64

âœ… ä¸»åˆ’åˆ†å®Œæˆï¼š
Train: 313 (27 severe CRS)
Test:  134 (11 severe CRS)

ğŸ”¹ åœ¨è®­ç»ƒé›†ä¸Šåˆ›å»º5æŠ˜ Group-Stratified CV åˆ’åˆ†...
  Fold1: train=251 (pos=22), val=62 (pos=5)
  Fold2: train=250 (pos=21), val=63 (pos=6)
  Fold3: train=250 (pos=22), val=63 (pos=5)
  Fold4: train=252 (pos=22), val=61 (pos=5)
  Fold5: train=249 (pos=21), val=64 (pos=6)
-------------------------------------------------------------------------------
âœ… ä½¿ç”¨æ–¹å¼
åœ¨åç»­è®­ç»ƒè„šæœ¬ï¼ˆå¦‚ train_BNHL_CRS_model.pyï¼‰ä¸­ï¼š
	â€¢	è¯»å–æŸä¸ªæŠ˜çš„ ID åˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š
train_ids = np.loadtxt("BNHL_CRS_split_70_30/fold_splits/fold1_train_ids.txt", dtype=int)
val_ids = np.loadtxt("BNHL_CRS_split_70_30/fold_splits/fold1_val_ids.txt", dtype=int)
	â€¢	åœ¨é™æ€è¡¨ train_static.csv é‡Œç­›é€‰å¯¹åº” ID è¿›è¡Œè®­ç»ƒéªŒè¯ã€‚
-------------------------------------------------------------------------------
âš ï¸ æ³¨æ„äº‹é¡¹
é‡‡æ ·å•ä½ï¼šæ‚£è€…çº§ï¼Œä¸å¯åœ¨åŠ¨æ€æ—¶é—´ç‰‡å±‚é¢æ‰“ä¹±
åˆ†å±‚ç­–ç•¥ï¼šé€šè¿‡æ‚£è€… label ç¡®ä¿æ­£è´Ÿæ ·æœ¬å‡è¡¡
ç¨€æœ‰æ ‡ç­¾ï¼šè‹¥æ­£æ ·æœ¬å¤ªå°‘ï¼ˆ<30ï¼‰ï¼Œå»ºè®®å‡å°‘åˆ° 3 æŠ˜ä»¥ç¡®ä¿æ¯æŠ˜éƒ½æœ‰è‡³å°‘ 5 ä¸ªæ­£æ ·æœ¬
reproducibilityï¼šå›ºå®š random_state=42
-------------------------------------------------------------------------------

 
"""

import os
import shutil
import yaml
import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold

# ======================================================
# 1. ç”¨æˆ·é…ç½®åŒº
# ======================================================
# é™æ€æ•°æ®æ–‡ä»¶è·¯å¾„ - åŒ…å«æ¯ä¸ªæ‚£è€…çš„é™æ€ç‰¹å¾å’Œæ ‡ç­¾
STATIC_PATH = "/home/phl/PHL/Car-T/data_encoder/output/dataset/encoded_standardized.csv"
# åŠ¨æ€æ•°æ®ç›®å½• - åŒ…å«æ¯ä¸ªæ‚£è€…çš„æ—¶åºæ•°æ®æ–‡ä»¶ï¼ˆå‘½åæ ¼å¼: {patient_id}.csvï¼‰
DYNAMIC_DIR = "/home/phl/PHL/Car-T/data_encoder/output/dataset/processed_standardized"
# è¾“å‡ºç›®å½• - å­˜æ”¾åˆ’åˆ†åçš„è®­ç»ƒé›†ã€æµ‹è¯•é›†å’Œäº¤å‰éªŒè¯æŠ˜å æ–‡ä»¶
OUTPUT_DIR = "./BNHL_CRS_split_70_30"
# æ‚£è€…IDåˆ—å - ç”¨äºæ ‡è¯†ä¸åŒæ‚£è€…çš„å”¯ä¸€æ ‡è¯†ç¬¦
PATIENT_ID_COL = "patient_id"
# æ ‡ç­¾åˆ—å - 0=éä¸¥é‡CRS, 1=ä¸¥é‡CRSï¼ˆç›®æ ‡å˜é‡ï¼‰
LABEL_COL = "label"
# æµ‹è¯•é›†æ¯”ä¾‹ - 30%çš„æ•°æ®ç”¨äºæœ€ç»ˆæµ‹è¯•
TEST_SIZE = 0.30
# éšæœºç§å­ - ç¡®ä¿æ•°æ®åˆ’åˆ†çš„å¯å¤ç°æ€§
RANDOM_STATE = 42
# äº¤å‰éªŒè¯æŠ˜æ•° - åœ¨è®­ç»ƒé›†ä¸Šæ‰§è¡Œ5æŠ˜äº¤å‰éªŒè¯
N_FOLDS = 5
# æ˜¯å¦å¤åˆ¶åŠ¨æ€æ–‡ä»¶ - Trueåˆ™å¤åˆ¶æ‰€æœ‰æ‚£è€…çš„åŠ¨æ€CSVæ–‡ä»¶åˆ°å¯¹åº”å­ç›®å½•
COPY_DYNAMIC_FILES = True  # è‹¥ä¸ºTrueåˆ™å¤åˆ¶åŠ¨æ€æ–‡ä»¶; è‹¥ä¸º Falseï¼Œå°†ä»…ç”ŸæˆIDæ–‡ä»¶ï¼Œä¸å¤åˆ¶åŠ¨æ€CSV

# ======================================================
# è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºGroup-Stratifiedåˆ’åˆ†
# ======================================================
def group_stratified_kfold(df, group_col, label_col, n_splits=5, random_state=42):
    """
    åœ¨æ‚£è€…çº§åˆ«è¿›è¡Œåˆ†å±‚äº¤å‰éªŒè¯åˆ’åˆ†ã€‚
    
    åŠŸèƒ½è¯´æ˜:
        å®ç°GroupKFold + StratifiedKFoldçš„ç»„åˆæ•ˆæœï¼Œç¡®ä¿ï¼š
        1. åŒä¸€æ‚£è€…(group)çš„æ‰€æœ‰æ ·æœ¬ä¸ä¼šè·¨foldå‡ºç°
        2. å„foldä¸­æ­£è´Ÿæ ·æœ¬çš„æ¯”ä¾‹ä¿æŒè¿‘ä¼¼å¹³è¡¡
    
    å®ç°ç­–ç•¥:
        - å…ˆæŒ‰labelå°†æ•°æ®åˆ†ä¸ºæ­£æ ·æœ¬ç»„å’Œè´Ÿæ ·æœ¬ç»„
        - åˆ†åˆ«å¯¹ä¸¤ç»„è¿›è¡Œn_splitsç­‰åˆ†
        - å°†å¯¹åº”ç´¢å¼•çš„æ­£è´Ÿæ ·æœ¬ç»„åˆå¹¶ä½œä¸ºå„foldçš„éªŒè¯é›†
        - å‰©ä½™æ ·æœ¬ä½œä¸ºè¯¥foldçš„è®­ç»ƒé›†
    
    å‚æ•°:
        df: pandas.DataFrame - åŒ…å«æ‚£è€…æ•°æ®çš„æ•°æ®æ¡†
        group_col: str - åˆ†ç»„åˆ—åï¼ˆæ‚£è€…IDåˆ—ï¼‰ï¼Œç¡®ä¿åŒä¸€ç»„ä¸è·¨fold
        label_col: str - æ ‡ç­¾åˆ—åï¼Œç”¨äºåˆ†å±‚ä»¥ä¿æŒç±»åˆ«å¹³è¡¡
        n_splits: int - äº¤å‰éªŒè¯æŠ˜æ•°ï¼Œé»˜è®¤5
        random_state: int - éšæœºç§å­ï¼Œç¡®ä¿å¯å¤ç°æ€§
    
    è¿”å›:
        list of tuple - æ¯ä¸ªå…ƒç´ ä¸º (train_ids, val_ids)ï¼Œè¡¨ç¤ºä¸€æŠ˜çš„è®­ç»ƒå’ŒéªŒè¯æ‚£è€…IDæ•°ç»„
                       å…±è¿”å›n_splitsä¸ªå…ƒç»„
    
    æ³¨æ„äº‹é¡¹:
        - è¿™æ˜¯sklearnæœªæä¾›çš„GroupStratifiedKFoldçš„è¿‘ä¼¼å®ç°
        - é€‚ç”¨äºåŒ»ç–—æ•°æ®ç­‰éœ€è¦æ‚£è€…çº§ç‹¬ç«‹ä¸”ç±»åˆ«å¹³è¡¡çš„åœºæ™¯
        - å½“æŸç±»æ ·æœ¬æ•°ä¸èƒ½è¢«n_splitsæ•´é™¤æ—¶ï¼Œå„foldå¤§å°å¯èƒ½ç•¥æœ‰å·®å¼‚
    """
    # åˆ›å»ºéšæœºæ•°ç”Ÿæˆå™¨ï¼Œç”¨äºæ‰“ä¹±æ•°æ®é¡ºåº
    rng = np.random.RandomState(random_state)
    # å…ˆæ‰“ä¹±æ•´ä¸ªæ•°æ®æ¡†ï¼Œé¿å…åŸå§‹æ•°æ®çš„æ’åºåå·®
    df_shuffled = df.sample(frac=1, random_state=random_state).reset_index(drop=True)

    # æå–label=1ï¼ˆä¸¥é‡CRSï¼‰ä¸label=0ï¼ˆéä¸¥é‡CRSï¼‰ä¸¤ç»„æ‚£è€…
    # åˆ†åˆ«å¤„ç†ç¡®ä¿å„foldéƒ½åŒ…å«è¶³å¤Ÿçš„æ­£è´Ÿæ ·æœ¬
    pos_df = df_shuffled[df_shuffled[label_col] == 1]
    neg_df = df_shuffled[df_shuffled[label_col] == 0]

    # å°†æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬åˆ†åˆ«ç­‰åˆ†æˆn_splitsä»½
    # np.array_splitç¡®ä¿å³ä½¿ä¸èƒ½æ•´é™¤ä¹Ÿèƒ½åˆç†åˆ†é…
    pos_groups = np.array_split(pos_df[group_col].values, n_splits)
    neg_groups = np.array_split(neg_df[group_col].values, n_splits)

    # æ„å»ºæ¯ä¸€æŠ˜çš„è®­ç»ƒé›†å’ŒéªŒè¯é›†IDåˆ—è¡¨
    folds = []
    for i in range(n_splits):
        # ç¬¬iæŠ˜çš„éªŒè¯é›†ï¼šåˆå¹¶ç¬¬iä»½æ­£æ ·æœ¬å’Œç¬¬iä»½è´Ÿæ ·æœ¬
        val_ids = np.concatenate([pos_groups[i], neg_groups[i]])
        # ç¬¬iæŠ˜çš„è®­ç»ƒé›†ï¼šé™¤éªŒè¯é›†å¤–çš„æ‰€æœ‰æ‚£è€…ID
        train_ids = df_shuffled[~df_shuffled[group_col].isin(val_ids)][group_col].values
        folds.append((train_ids, val_ids))
    return folds

# ======================================================
# 2. åŠ è½½é™æ€æ•°æ®
# ======================================================
# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)
# è¯»å–é™æ€æ•°æ®è¡¨ï¼ŒåŒ…å«æ‰€æœ‰æ‚£è€…çš„åŸºçº¿ç‰¹å¾å’ŒCRSæ ‡ç­¾
print("ğŸ”¹ Loading static data...")
df = pd.read_csv(STATIC_PATH)

# éªŒè¯å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨ - ç¡®ä¿æ•°æ®æ–‡ä»¶åŒ…å«æ‚£è€…IDå’Œæ ‡ç­¾åˆ—
assert PATIENT_ID_COL in df.columns, f"é™æ€æ–‡ä»¶ä¸­ç¼ºå°‘åˆ—: {PATIENT_ID_COL}"
assert LABEL_COL in df.columns, f"é™æ€æ–‡ä»¶ä¸­ç¼ºå°‘åˆ—: {LABEL_COL}"

# æ‰“å°æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
print(f"æ€»æ ·æœ¬æ•°: {len(df)}")
# æ˜¾ç¤ºæ ‡ç­¾åˆ†å¸ƒï¼ˆ0: éä¸¥é‡CRS, 1: ä¸¥é‡CRSï¼‰
print(df[LABEL_COL].value_counts())

# ======================================================
# 3. åˆ†å±‚æŠ½æ ·STRATIFIED SPLIT (æ‚£è€…çº§åˆ«)â€”â€”â€”â€”ä¸»åˆ’åˆ† (70/30 StratifiedShuffleSplit)
# ======================================================
# ä½¿ç”¨åˆ†å±‚æŠ½æ ·è¿›è¡Œ70/30åˆ’åˆ†
# - ç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­ä¸¥é‡CRSçš„æ¯”ä¾‹ä¸æ€»ä½“ä¸€è‡´
# - åœ¨æ‚£è€…çº§åˆ«åˆ’åˆ†ï¼Œé¿å…åŒä¸€æ‚£è€…çš„æ•°æ®å‡ºç°åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­
splitter = StratifiedShuffleSplit(
    n_splits=1,              # åªéœ€è¦ä¸€æ¬¡åˆ’åˆ†
    test_size=TEST_SIZE,     # æµ‹è¯•é›†å 30%
    random_state=RANDOM_STATE # å›ºå®šéšæœºç§å­ç¡®ä¿å¯å¤ç°
)
# splitæ–¹æ³•çš„ç¬¬äºŒä¸ªå‚æ•°ä¼ å…¥æ ‡ç­¾åˆ—ï¼Œå®ç°åˆ†å±‚æŠ½æ ·
train_idx, test_idx = next(splitter.split(df, df[LABEL_COL]))

# æ ¹æ®ç´¢å¼•æå–è®­ç»ƒé›†å’Œæµ‹è¯•é›†
train_df = df.iloc[train_idx].copy()
test_df = df.iloc[test_idx].copy()

# æå–è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ‚£è€…IDåˆ—è¡¨
train_ids = train_df[PATIENT_ID_COL].tolist()
test_ids = test_df[PATIENT_ID_COL].tolist()

# æ‰“å°åˆ’åˆ†ç»Ÿè®¡ä¿¡æ¯ï¼ŒéªŒè¯åˆ†å±‚æ•ˆæœ
print("\nâœ… ä¸»åˆ’åˆ†: åˆ†å±‚æŠ½æ ·å®Œæˆ (Stratified split complete):")
print(f"Train set: {len(train_df)} patients ({train_df[LABEL_COL].sum()} severe CRS)")
print(f"Test set:  {len(test_df)} patients ({test_df[LABEL_COL].sum()} severe CRS)")

# ======================================================
# 4. CREATE OUTPUT DIRECTORIES & SAVE STATIC DATA
# ======================================================
# ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åŠ¨æ€æ•°æ®åˆ›å»ºå­ç›®å½•
os.makedirs(os.path.join(OUTPUT_DIR, "train_dynamic"), exist_ok=True)
os.makedirs(os.path.join(OUTPUT_DIR, "test_dynamic"), exist_ok=True)

# ======================================================
# 5. SAVE STATIC CSVs & ID LISTS
# ======================================================
# ä¿å­˜è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„é™æ€æ•°æ®æ–‡ä»¶è·¯å¾„
train_static_path = os.path.join(OUTPUT_DIR, "train_static.csv")
test_static_path = os.path.join(OUTPUT_DIR, "test_static.csv")

# å°†åˆ’åˆ†åçš„é™æ€æ•°æ®ä¿å­˜ä¸ºCSVæ–‡ä»¶
train_df.to_csv(train_static_path, index=False)
test_df.to_csv(test_static_path, index=False)

# å°†æ‚£è€…IDåˆ—è¡¨ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ï¼Œä¾¿äºåç»­å¿«é€ŸåŠ è½½
np.savetxt(os.path.join(OUTPUT_DIR, "train_ids.txt"), train_ids, fmt="%s")
np.savetxt(os.path.join(OUTPUT_DIR, "test_ids.txt"), test_ids, fmt="%s")

# ======================================================
# 6. åœ¨è®­ç»ƒé›†ä¸Šåˆ›å»ºå†…éƒ¨5æŠ˜ GroupStratifiedKFold
# ======================================================
# å¯¹è®­ç»ƒé›†è¿›è¡Œäº¤å‰éªŒè¯åˆ’åˆ†ï¼Œç”¨äºæ¨¡å‹è¶…å‚æ•°è°ƒä¼˜å’Œç¨³å®šæ€§è¯„ä¼°
print("\nğŸ”¹ åœ¨è®­ç»ƒé›†ä¸Šåˆ›å»º5æŠ˜ Group-Stratified CV åˆ’åˆ†...")
# è°ƒç”¨è‡ªå®šä¹‰å‡½æ•°è¿›è¡Œåˆ†ç»„åˆ†å±‚äº¤å‰éªŒè¯
folds = group_stratified_kfold(train_df, group_col=PATIENT_ID_COL,
                               label_col=LABEL_COL, n_splits=N_FOLDS,
                               random_state=RANDOM_STATE)

# åˆ›å»ºfold_splitså­ç›®å½•ç”¨äºå­˜å‚¨å„æŠ˜çš„IDæ–‡ä»¶
fold_dir = os.path.join(OUTPUT_DIR, "fold_splits")
os.makedirs(fold_dir, exist_ok=True)

# éå†æ¯ä¸€æŠ˜ï¼Œä¿å­˜è®­ç»ƒå’ŒéªŒè¯é›†çš„æ‚£è€…ID
for i, (train_ids_fold, val_ids_fold) in enumerate(folds, 1):
    # ä¿å­˜ç¬¬iæŠ˜çš„è®­ç»ƒé›†æ‚£è€…ID
    np.savetxt(os.path.join(fold_dir, f"fold{i}_train_ids.txt"), train_ids_fold, fmt="%s")
    # ä¿å­˜ç¬¬iæŠ˜çš„éªŒè¯é›†æ‚£è€…ID
    np.savetxt(os.path.join(fold_dir, f"fold{i}_val_ids.txt"), val_ids_fold, fmt="%s")

    # ç»Ÿè®¡å½“å‰æŠ˜ä¸­çš„æ­£æ ·æœ¬æ•°é‡ï¼ˆä¸¥é‡CRSæ‚£è€…æ•°ï¼‰
    pos_train = train_df[train_df[PATIENT_ID_COL].isin(train_ids_fold)][LABEL_COL].sum()
    pos_val = train_df[train_df[PATIENT_ID_COL].isin(val_ids_fold)][LABEL_COL].sum()
    # æ‰“å°å½“å‰æŠ˜çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œç”¨äºéªŒè¯åˆ†å±‚æ•ˆæœ
    print(f"  Fold{i}: train={len(train_ids_fold)} (pos={pos_train}), "
          f"val={len(val_ids_fold)} (pos={pos_val})")

# ======================================================
# 7. COPY DYNAMIC FILES (OPTIONAL)
# ======================================================
# å¦‚æœå¯ç”¨äº†åŠ¨æ€æ–‡ä»¶å¤åˆ¶åŠŸèƒ½
if COPY_DYNAMIC_FILES:
    print("\nğŸ“‚ å¤åˆ¶åŠ¨æ€æ–‡ä»¶ä¸­...")
    # åˆå§‹åŒ–è®¡æ•°å™¨ï¼Œç”¨äºç»Ÿè®¡æˆåŠŸå¤åˆ¶çš„æ–‡ä»¶æ•°é‡
    n_train_copied, n_test_copied = 0, 0
    # è®°å½•ç¼ºå¤±çš„åŠ¨æ€æ–‡ä»¶ID
    missing_train, missing_test = [], []

    # å¤åˆ¶è®­ç»ƒé›†æ‚£è€…çš„åŠ¨æ€æ–‡ä»¶
    for pid in train_ids:
        # æ„å»ºæºæ–‡ä»¶è·¯å¾„å’Œç›®æ ‡æ–‡ä»¶è·¯å¾„
        src = os.path.join(DYNAMIC_DIR, f"{pid}.csv")
        dst = os.path.join(OUTPUT_DIR, "train_dynamic", f"{pid}.csv")
        # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(src):
            shutil.copy(src, dst)
            n_train_copied += 1
        else:
            # è®°å½•ç¼ºå¤±çš„æ–‡ä»¶ID
            missing_train.append(pid)

    # å¤åˆ¶æµ‹è¯•é›†æ‚£è€…çš„åŠ¨æ€æ–‡ä»¶
    for pid in test_ids:
        src = os.path.join(DYNAMIC_DIR, f"{pid}.csv")
        dst = os.path.join(OUTPUT_DIR, "test_dynamic", f"{pid}.csv")
        if os.path.exists(src):
            shutil.copy(src, dst)
            n_test_copied += 1
        else:
            missing_test.append(pid)

    # æ‰“å°å¤åˆ¶ç»Ÿè®¡ä¿¡æ¯
    print(f"åŠ¨æ€æ–‡ä»¶å·²å¤åˆ¶: {n_train_copied} train, {n_test_copied} test")
    # å¦‚æœæœ‰ç¼ºå¤±æ–‡ä»¶ï¼Œå‘å‡ºè­¦å‘Š
    if missing_train or missing_test:
        print(f"âš ï¸ ç¼ºå¤±çš„åŠ¨æ€æ–‡ä»¶:")
        if missing_train:
            print(f"  - è®­ç»ƒé›†ç¼ºå¤± ({len(missing_train)}): {missing_train[:10]}...")
        if missing_test:
            print(f"  - æµ‹è¯•é›†ç¼ºå¤± ({len(missing_test)}): {missing_test[:10]}...")

# ======================================================
# 8.ä¿å­˜å…ƒä¿¡æ¯ GENERATE METADATA YAML
# ======================================================
# åˆ›å»ºå…ƒæ•°æ®å­—å…¸ï¼Œè®°å½•æ•°æ®åˆ’åˆ†çš„æ‰€æœ‰å…³é”®ä¿¡æ¯
metadata = {
    "dataset_split": {
        "method": "StratifiedShuffleSplit + GroupStratifiedKFold",  # åˆ’åˆ†æ–¹æ³•ï¼šä¸»åˆ’åˆ† + å†…éƒ¨äº¤å‰éªŒè¯
        "test_size": TEST_SIZE,              # æµ‹è¯•é›†æ¯”ä¾‹
        "n_folds": N_FOLDS,                  # äº¤å‰éªŒè¯æŠ˜æ•°
        "random_state": RANDOM_STATE,        # éšæœºç§å­
        "total_samples": int(len(df)),       # æ€»æ ·æœ¬æ•°
        "train_samples": int(len(train_df)), # è®­ç»ƒé›†æ ·æœ¬æ•°
        "test_samples": int(len(test_df)),   # æµ‹è¯•é›†æ ·æœ¬æ•°
        "positive_total": int(df[LABEL_COL].sum()),        # æ€»æ­£æ ·æœ¬æ•°ï¼ˆä¸¥é‡CRSï¼‰
        "positive_train": int(train_df[LABEL_COL].sum()),  # è®­ç»ƒé›†æ­£æ ·æœ¬æ•°
        "positive_test": int(test_df[LABEL_COL].sum()),    # æµ‹è¯•é›†æ­£æ ·æœ¬æ•°
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),  # åˆ’åˆ†æ—¶é—´æˆ³
        "static_input_file": STATIC_PATH,        # è¾“å…¥é™æ€æ–‡ä»¶è·¯å¾„
        "dynamic_input_dir": DYNAMIC_DIR,        # è¾“å…¥åŠ¨æ€æ–‡ä»¶ç›®å½•
        "train_static_csv": train_static_path,   # è®­ç»ƒé›†é™æ€æ–‡ä»¶è·¯å¾„
        "test_static_csv": test_static_path,     # æµ‹è¯•é›†é™æ€æ–‡ä»¶è·¯å¾„
        "train_dynamic_dir": os.path.join(OUTPUT_DIR, "train_dynamic"),  # è®­ç»ƒé›†åŠ¨æ€æ–‡ä»¶ç›®å½•
        "test_dynamic_dir": os.path.join(OUTPUT_DIR, "test_dynamic"),    # æµ‹è¯•é›†åŠ¨æ€æ–‡ä»¶ç›®å½•
    }
}

# å°†å…ƒæ•°æ®ä¿å­˜ä¸ºYAMLæ–‡ä»¶ï¼Œä¾¿äºè¿½æº¯å’Œå¤ç°
with open(os.path.join(OUTPUT_DIR, "metadata_split.yaml"), "w") as f:
    yaml.dump(metadata, f, allow_unicode=True)

print(f"\nğŸ“„ Metadata written to metadata_split.yaml, å·²ä¿å­˜åˆ° {OUTPUT_DIR}")
print("\nğŸ‰ æ•°æ®åˆ’åˆ† + å†…éƒ¨äº¤å‰éªŒè¯æŠ˜å æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")