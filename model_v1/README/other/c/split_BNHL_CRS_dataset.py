"""
æŠŠ 447 ä½æ‚£è€… æŒ‰æ¯”ä¾‹ 70% è®­ç»ƒé›† / 30% æµ‹è¯•é›†åˆ’åˆ†ï¼Œ
åŒæ—¶ä¿è¯ä»¥ä¸‹ä¸‰ç‚¹ï¼š
	1.	åˆ†å±‚æŠ½æ ·ï¼šä¸¥é‡ CRS (=1) å’Œ éä¸¥é‡ CRS (=0) çš„æ¯”ä¾‹åœ¨è®­ç»ƒé›†ä¸æµ‹è¯•é›†åŸºæœ¬ä¸€è‡´ï¼›
	2.	æ‚£è€…çº§ç‹¬ç«‹æ€§ï¼šæ¯ä¸ª patient_id åªå‡ºç°åœ¨ä¸€ä¸ªé›†åˆä¸­ï¼ˆé˜²æ­¢åŠ¨æ€ç‰‡æ®µæ³„æ¼ï¼‰ï¼›
	3.	å¯å¤ç°ï¼šå›ºå®š random_stateï¼Œç”Ÿæˆå¯¹åº” metadata ä¸ ID æ–‡ä»¶ã€‚
 ---------------------------------------------------------------
æ€»æ ·æœ¬æ•°447
CRS=1 (é«˜æ¯’)ï¼š38 (â‰ˆ 8.5%)
CRS=0 (ä½æ¯’/æ— æ¯’)ï¼š409 (â‰ˆ 91.5%)

åˆ†å±‚åˆ’åˆ†ç›®æ ‡ï¼š
è®­ç»ƒé›†çº¦ 313 ä¾‹ï¼ˆå…¶ä¸­ â‰ˆ 27â€“28 ä¾‹ CRS=1ï¼‰ï¼›
æµ‹è¯•é›†çº¦ 134 ä¾‹ï¼ˆå…¶ä¸­ â‰ˆ 10â€“11 ä¾‹ CRS=1ï¼‰ã€‚
Enhanced dataset split script for B-NHL CRS binary classification
---------------------------------------------------------------
ä½¿ç”¨ä¸€ç§æ··åˆæ–¹æ³•ï¼š
	â€¢	åˆ†å±‚æŠ½æ ·ï¼ˆStratifiedShuffleSplitï¼‰ æ¥ä¿æŒç±»åˆ«æ¯”ä¾‹ï¼›
	â€¢	æ‚£è€…çº§åˆ’åˆ†ï¼ˆæ¯ä¸ªç—…äººå”¯ä¸€ IDï¼‰ï¼›
	â€¢	ç”Ÿæˆï¼štrain_ids.txtã€test_ids.txtã€metadata_split.yamlï¼›
	â€¢	ä¿ç•™åŸå§‹ CSV ä¸åŠ¨ï¼Œä»…ä¿å­˜ ID åˆ—è¡¨ï¼Œä¾¿äºåç»­ Pipeline æŒ‰ ID ç­›é€‰ã€‚
---------------------------------------------------------------
é¢å¤–è¯´æ˜ä¸æ‰©å±•å»ºè®®
1. é˜²æ­¢æ—¶é—´æ³„æ¼
å¦‚æœä½ çš„åŠ¨æ€æ•°æ®ä¸­æ¯ä½ç—…äººè®°å½•åˆ° +30 å¤©ï¼Œä¸ºä¿è¯æœªæ¥é¢„æµ‹ä¸æ³„æ¼â€œæœªæ¥ä¿¡æ¯â€ï¼Œ
è¯·ç¡®ä¿åœ¨ç”Ÿæˆ patient_feature_table.csv æ—¶ï¼Œåªä½¿ç”¨ Day â‰¤ +2 çš„æ•°æ®ã€‚
---------------------------------------------------------------
2. äº¤å‰éªŒè¯æ‹“å±•
ä½ ä¹Ÿå¯ä»¥åœ¨è®­ç»ƒé›†ä¸Šå†åš 5 æŠ˜ GroupStratifiedKFold è¿›è¡Œå†…éƒ¨éªŒè¯ï¼š
from sklearn.model_selection import StratifiedKFold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
for tr_idx, val_idx in skf.split(train_df, train_df[LABEL_COL]):
    # æ¯æŠ˜ç‹¬ç«‹è®­ç»ƒéªŒè¯
---------------------------------------------------------------
3. ç±»åˆ«ä¸å¹³è¡¡
ä¸¥é‡ CRS çº¦ 8.5% â†’ å±äºä¸­åº¦ä¸å¹³è¡¡ï¼š
	â€¢	ä½¿ç”¨ scale_pos_weight = neg/pos ï¼ˆLightGBM å‚æ•°ï¼‰
	â€¢	è¯„ä¼°æ—¶ä¼˜å…ˆæŠ¥å‘Š AUPRC ä¸ æ•æ„Ÿåº¦@ç‰¹å¼‚åº¦=0.9
---------------------------------------------------------------
4.å¯è¿½æº¯æ€§
åœ¨è®ºæ–‡æˆ–æŠ¥å‘Šä¸­ï¼Œä½ å¯ä»¥ç›´æ¥å¼•ç”¨ï¼š
Data split: StratifiedShuffleSplit (70% train / 30% test, random_state=42)
Positive rate: 8.5% overall, preserved in both subsets
---------------------------------------------------------------
- Stratified 70/30 split by CRS label
- Patient-level unique split
- Copies per-patient dynamic CSV files into train/test subfolders
- Exports static CSVs (train/test)
- Generates reproducible metadata YAML
---------------------------------------------------------------
- æŒ‰ CRS æ ‡ç­¾è¿›è¡Œ 70/30 åˆ†å±‚
	â€¢	è‡ªåŠ¨è¯†åˆ«å¹¶åŠ è½½ä½ çš„é™æ€æ–‡ä»¶å’ŒåŠ¨æ€æ–‡ä»¶å¤¹ï¼›
	â€¢	å°†åŠ¨æ€æ–‡ä»¶ï¼ˆæ¯ä½æ‚£è€…ä¸€ä¸ª CSVï¼‰æŒ‰åˆ’åˆ†ç»“æœå¤åˆ¶åˆ°ä¸¤ä¸ªæ–°æ–‡ä»¶å¤¹ï¼ˆtrain_dynamic/ã€test_dynamic/ï¼‰ï¼›
	â€¢	åŒæ­¥ç”Ÿæˆé™æ€è¡¨çš„ train_static.csv å’Œ test_static.csvï¼›
	â€¢	ä¿å­˜æ‰€æœ‰åˆ’åˆ†ä¿¡æ¯åˆ° metadata_split.yamlï¼›
	â€¢	ç¡®ä¿éšæœºç§å­å›ºå®šã€ç±»åˆ«æ¯”ä¾‹ä¸€è‡´ã€æ‚£è€…çº§ç‹¬ç«‹ï¼Œç”Ÿæˆå¯å¤ç°çš„å…ƒæ•°æ® YAML æ–‡ä»¶ï¼›
	â€¢	ç»“æ„æ¸…æ™°ã€å¯ç›´æ¥è¿è¡Œåœ¨ä½ çš„æ•°æ®è·¯å¾„ä¸Šã€‚

æ‰§è¡Œåç›®å½•ç»“æ„å¦‚ä¸‹ï¼š
BNHL_CRS_split_70_30/
â”œâ”€â”€ train_static.csv           # è®­ç»ƒé›†é™æ€æ•°æ®
â”œâ”€â”€ test_static.csv            # æµ‹è¯•é›†é™æ€æ•°æ®
â”œâ”€â”€ train_ids.txt              # è®­ç»ƒé›†æ‚£è€…ID
â”œâ”€â”€ test_ids.txt               # æµ‹è¯•é›†æ‚£è€…ID
â”œâ”€â”€ train_dynamic/             # å„ç—…äººçš„åŠ¨æ€CSV
â”‚    â”œâ”€â”€ 1.csv
â”‚    â”œâ”€â”€ 2.csv
â”‚    â””â”€â”€ ...
â”œâ”€â”€ test_dynamic/
â”‚    â”œâ”€â”€ 12.csv
â”‚    â”œâ”€â”€ 37.csv
â”‚    â””â”€â”€ ...
â””â”€â”€ metadata_split.yaml
metadata_split.yaml ä¸­ä¼šä¿å­˜å½“å‰åˆ’åˆ†çš„ç»Ÿè®¡ä¸éšæœºç§å­ï¼Œä¿è¯ä½ æœªæ¥èƒ½å¤ç°åŒä¸€åˆ’åˆ†ã€‚
---------------------------------------------------------------
æ‰§è¡Œåä½ èƒ½ç«‹å³åšçš„äº‹
è®­ç»ƒæ¨¡å‹ï¼štrain_static.csv, train_dynamic/ä½œä¸º Pipeline çš„è®­ç»ƒè¾“å…¥
éªŒè¯æ¨¡å‹ï¼štest_static.csv, test_dynamic/ç”¨äºæœ€ç»ˆæ€§èƒ½è¯„ä¼°
æº¯æºï¼šmetadata_split.yamlåŒ…å«éšæœºç§å­ã€æ¯”ä¾‹ã€æ—¥æœŸï¼Œç¡®ä¿å¯å¤ç°
---------------------------------------------------------------
é™„åŠ å»ºè®®
æ ·æœ¬å•ä½ï¼šä¿æŒâ€œæ¯ç—…äººä¸€ä¾‹â€ä¸€è‡´ï¼Œé˜²æ­¢è·¨ç—…äººåŠ¨æ€ä¿¡æ¯æ³„æ¼
åŠ¨æ€æ—¶é—´çª—ï¼šä»…ä¿ç•™ Day â‰¤ +2 çš„åŠ¨æ€ç‰¹å¾ç”¨äºè®­ç»ƒ
ç±»åˆ«ä¸å¹³è¡¡ï¼šLightGBM ä¸­è®¾ç½® scale_pos_weight = neg/pos
äº¤å‰éªŒè¯ï¼šä»…åœ¨ train_static.csv ä¸Šåš 5-fold GroupStratifiedKFold
æµ‹è¯•é›†ï¼šç»å¯¹ä¸å‚ä¸ä»»ä½•æ’è¡¥æˆ–ç‰¹å¾é€‰æ‹©æ‹Ÿåˆ
---------------------------------------------------------------

"""

import os
import shutil
import yaml
import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.model_selection import StratifiedShuffleSplit

# ======================================================
# 1. ç”¨æˆ·é…ç½®åŒº
# ======================================================
# é™æ€æ•°æ®æ–‡ä»¶è·¯å¾„ - åŒ…å«æ¯ä¸ªæ‚£è€…çš„é™æ€ç‰¹å¾å’Œæ ‡ç­¾
STATIC_PATH = "/home/phl/PHL/Car-T/disease_partition/output/B-NHL_reindexed/csv/B-NHL_static_data_example.csv"
# åŠ¨æ€æ•°æ®ç›®å½• - åŒ…å«æ¯ä¸ªæ‚£è€…çš„æ—¶åºæ•°æ®æ–‡ä»¶ï¼ˆå‘½åæ ¼å¼: {patient_id}.csvï¼‰
DYNAMIC_DIR = "/home/phl/PHL/Car-T/disease_partition/output/B-NHL_reindexed/processed"
# è¾“å‡ºç›®å½• - å­˜æ”¾åˆ’åˆ†åçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†
OUTPUT_DIR = "./output/datasets/BNHL_CRS_split_70_30"
# æ‚£è€…IDåˆ—å - ç”¨äºæ ‡è¯†ä¸åŒæ‚£è€…çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆå¯¹åº”é™æ€æ•°æ®ä¸­çš„IDåˆ—ï¼‰
PATIENT_ID_COL = "ID"
# æ ‡ç­¾åˆ—å - 0=éä¸¥é‡CRS, 1=ä¸¥é‡CRSï¼ˆç›®æ ‡å˜é‡
LABEL_COL = "CRS_grade"
# æµ‹è¯•é›†æ¯”ä¾‹ - 30%çš„æ•°æ®ç”¨äºæœ€ç»ˆæµ‹è¯•
TEST_SIZE = 0.30
# éšæœºç§å­ - ç¡®ä¿æ•°æ®åˆ’åˆ†çš„å¯å¤ç°æ€§
RANDOM_STATE = 42
# æ˜¯å¦å¤åˆ¶åŠ¨æ€æ–‡ä»¶ - Trueåˆ™å¤åˆ¶æ‰€æœ‰æ‚£è€…çš„åŠ¨æ€CSVæ–‡ä»¶åˆ°å¯¹åº”å­ç›®å½•
COPY_DYNAMIC_FILES = True  # è‹¥ä¸ºTrueåˆ™å¤åˆ¶åŠ¨æ€æ–‡ä»¶; è‹¥ä¸º Falseï¼Œå°†ä»…ç”ŸæˆIDæ–‡ä»¶ï¼Œä¸å¤åˆ¶åŠ¨æ€CSV

# ======================================================
# 2. åŠ è½½é™æ€æ•°æ®
# ======================================================
# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(OUTPUT_DIR, exist_ok=True)
# è¯»å–é™æ€æ•°æ®è¡¨ï¼ŒåŒ…å«æ‰€æœ‰æ‚£è€…çš„åŸºçº¿ç‰¹å¾å’ŒCRSæ ‡ç­¾
print("ğŸ”¹ Loading static data...")
df = pd.read_csv(STATIC_PATH)

# éªŒè¯å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨ - ç¡®ä¿æ•°æ®æ–‡ä»¶åŒ…å«æ‚£è€…IDå’Œæ ‡ç­¾åˆ—
assert PATIENT_ID_COL in df.columns, f"é™æ€æ–‡ä»¶ä¸­ç¼ºå°‘åˆ—: {PATIENT_ID_COL}"
assert LABEL_COL in df.columns, f"é™æ€æ–‡ä»¶ä¸­ç¼ºå°‘åˆ—: {LABEL_COL}"

# æ‰“å°æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
print(f"æ€»æ ·æœ¬æ•°: {len(df)}")
# æ˜¾ç¤ºæ ‡ç­¾åˆ†å¸ƒï¼ˆ0: éä¸¥é‡CRS, 1: ä¸¥é‡CRSï¼‰
print(df[LABEL_COL].value_counts())

# ======================================================
# 3. åˆ†å±‚æŠ½æ ·STRATIFIED SPLIT (æ‚£è€…çº§åˆ«)
# ======================================================
# ä½¿ç”¨åˆ†å±‚æŠ½æ ·è¿›è¡Œ70/30åˆ’åˆ†
# - ç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­ä¸¥é‡CRSçš„æ¯”ä¾‹ä¸æ€»ä½“ä¸€è‡´
# - åœ¨æ‚£è€…çº§åˆ«åˆ’åˆ†ï¼Œé¿å…åŒä¸€æ‚£è€…çš„æ•°æ®å‡ºç°åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­
splitter = StratifiedShuffleSplit(
    n_splits=1,              # åªéœ€è¦ä¸€æ¬¡åˆ’åˆ†
    test_size=TEST_SIZE,     # æµ‹è¯•é›†å 30%
    random_state=RANDOM_STATE # å›ºå®šéšæœºç§å­ç¡®ä¿å¯å¤ç°
)
# splitæ–¹æ³•çš„ç¬¬äºŒä¸ªå‚æ•°ä¼ å…¥æ ‡ç­¾åˆ—ï¼Œå®ç°åˆ†å±‚æŠ½æ ·
train_idx, test_idx = next(splitter.split(df, df[LABEL_COL]))

# æ ¹æ®ç´¢å¼•æå–è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶é‡ç½®ç´¢å¼•
train_df = df.iloc[train_idx].copy().reset_index(drop=True)
test_df = df.iloc[test_idx].copy().reset_index(drop=True)

# æå–è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ‚£è€…IDåˆ—è¡¨
train_ids = train_df[PATIENT_ID_COL].tolist()
test_ids = test_df[PATIENT_ID_COL].tolist()

# æ‰“å°åˆ’åˆ†ç»Ÿè®¡ä¿¡æ¯ï¼ŒéªŒè¯åˆ†å±‚æ•ˆæœ
print("\nâœ… åˆ†å±‚æŠ½æ ·å®Œæˆ (Stratified split complete):")
print(f"Train set: {len(train_df)} patients ({train_df[LABEL_COL].sum()} severe CRS)")
print(f"Test set:  {len(test_df)} patients ({test_df[LABEL_COL].sum()} severe CRS)")

# ======================================================
# 4. CREATE OUTPUT DIRECTORIES & SAVE STATIC DATA
# ======================================================
# ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åŠ¨æ€æ•°æ®åˆ›å»ºå­ç›®å½•
os.makedirs(os.path.join(OUTPUT_DIR, "train_dynamic"), exist_ok=True)
os.makedirs(os.path.join(OUTPUT_DIR, "test_dynamic"), exist_ok=True)

# ======================================================
# 5. SAVE STATIC CSVs & ID LISTS
# ======================================================
# ä¿å­˜è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„é™æ€æ•°æ®æ–‡ä»¶è·¯å¾„
train_static_path = os.path.join(OUTPUT_DIR, "train_static.csv")
test_static_path = os.path.join(OUTPUT_DIR, "test_static.csv")

# å°†åˆ’åˆ†åçš„é™æ€æ•°æ®ä¿å­˜ä¸ºCSVæ–‡ä»¶
train_df.to_csv(train_static_path, index=False)
test_df.to_csv(test_static_path, index=False)

# å°†æ‚£è€…IDåˆ—è¡¨ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶ï¼Œä¾¿äºåç»­å¿«é€ŸåŠ è½½
np.savetxt(os.path.join(OUTPUT_DIR, "train_ids.txt"), train_ids, fmt="%s")
np.savetxt(os.path.join(OUTPUT_DIR, "test_ids.txt"), test_ids, fmt="%s")

# ======================================================
# 6. COPY DYNAMIC FILES (OPTIONAL)
# ======================================================
# å¦‚æœå¯ç”¨äº†åŠ¨æ€æ–‡ä»¶å¤åˆ¶åŠŸèƒ½
if COPY_DYNAMIC_FILES:
    print("\nğŸ“‚ Copying dynamic files...")
    # åˆå§‹åŒ–è®¡æ•°å™¨ï¼Œç”¨äºç»Ÿè®¡æˆåŠŸå¤åˆ¶çš„æ–‡ä»¶æ•°é‡
    n_train_copied, n_test_copied = 0, 0
    # è®°å½•ç¼ºå¤±çš„åŠ¨æ€æ–‡ä»¶ID
    missing_train, missing_test = [], []

    # å¤åˆ¶è®­ç»ƒé›†æ‚£è€…çš„åŠ¨æ€æ–‡ä»¶
    for pid in train_ids:
        # æ„å»ºæºæ–‡ä»¶è·¯å¾„å’Œç›®æ ‡æ–‡ä»¶è·¯å¾„
        src = os.path.join(DYNAMIC_DIR, f"{pid}.csv")
        dst = os.path.join(OUTPUT_DIR, "train_dynamic", f"{pid}.csv")
        # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(src):
            shutil.copy(src, dst)
            n_train_copied += 1
        else:
            # è®°å½•ç¼ºå¤±çš„æ–‡ä»¶ID
            missing_train.append(pid)

    # å¤åˆ¶æµ‹è¯•é›†æ‚£è€…çš„åŠ¨æ€æ–‡ä»¶
    for pid in test_ids:
        src = os.path.join(DYNAMIC_DIR, f"{pid}.csv")
        dst = os.path.join(OUTPUT_DIR, "test_dynamic", f"{pid}.csv")
        if os.path.exists(src):
            shutil.copy(src, dst)
            n_test_copied += 1
        else:
            missing_test.append(pid)

    # æ‰“å°å¤åˆ¶ç»Ÿè®¡ä¿¡æ¯
    print(f"åŠ¨æ€æ–‡ä»¶å·²å¤åˆ¶: {n_train_copied} train, {n_test_copied} test")
    # å¦‚æœæœ‰ç¼ºå¤±æ–‡ä»¶ï¼Œå‘å‡ºè­¦å‘Š
    if missing_train or missing_test:
        print(f"âš ï¸ ç¼ºå¤±çš„åŠ¨æ€æ–‡ä»¶:")
        if missing_train:
            print(f"  - è®­ç»ƒé›†ç¼ºå¤± ({len(missing_train)}): {missing_train[:10]}...")
        if missing_test:
            print(f"  - æµ‹è¯•é›†ç¼ºå¤± ({len(missing_test)}): {missing_test[:10]}...")

# ======================================================
# 7.ä¿å­˜å…ƒä¿¡æ¯ GENERATE METADATA YAML
# ======================================================
# åˆ›å»ºå…ƒæ•°æ®å­—å…¸ï¼Œè®°å½•æ•°æ®åˆ’åˆ†çš„æ‰€æœ‰å…³é”®ä¿¡æ¯
metadata = {
    "dataset_split": {
        "method": "StratifiedShuffleSplit",  # åˆ’åˆ†æ–¹æ³•
        "test_size": TEST_SIZE,              # æµ‹è¯•é›†æ¯”ä¾‹
        "random_state": RANDOM_STATE,        # éšæœºç§å­
        "total_samples": int(len(df)),       # æ€»æ ·æœ¬æ•°
        "train_samples": int(len(train_df)), # è®­ç»ƒé›†æ ·æœ¬æ•°
        "test_samples": int(len(test_df)),   # æµ‹è¯•é›†æ ·æœ¬æ•°
        "positive_total": int(df[LABEL_COL].sum()),        # æ€»æ­£æ ·æœ¬æ•°ï¼ˆä¸¥é‡CRSï¼‰
        "positive_train": int(train_df[LABEL_COL].sum()),  # è®­ç»ƒé›†æ­£æ ·æœ¬æ•°
        "positive_test": int(test_df[LABEL_COL].sum()),    # æµ‹è¯•é›†æ­£æ ·æœ¬æ•°
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),  # åˆ’åˆ†æ—¶é—´æˆ³
        "static_input_file": STATIC_PATH,        # è¾“å…¥é™æ€æ–‡ä»¶è·¯å¾„
        "dynamic_input_dir": DYNAMIC_DIR,        # è¾“å…¥åŠ¨æ€æ–‡ä»¶ç›®å½•
        "train_static_csv": train_static_path,   # è®­ç»ƒé›†é™æ€æ–‡ä»¶è·¯å¾„
        "test_static_csv": test_static_path,     # æµ‹è¯•é›†é™æ€æ–‡ä»¶è·¯å¾„
        "train_dynamic_dir": os.path.join(OUTPUT_DIR, "train_dynamic"),  # è®­ç»ƒé›†åŠ¨æ€æ–‡ä»¶ç›®å½•
        "test_dynamic_dir": os.path.join(OUTPUT_DIR, "test_dynamic"),    # æµ‹è¯•é›†åŠ¨æ€æ–‡ä»¶ç›®å½•
    }
}

# å°†å…ƒæ•°æ®ä¿å­˜ä¸ºYAMLæ–‡ä»¶ï¼Œä¾¿äºè¿½æº¯å’Œå¤ç°
with open(os.path.join(OUTPUT_DIR, "metadata_split.yaml"), "w") as f:
    yaml.dump(metadata, f, allow_unicode=True)

print(f"\nğŸ“„ Metadata written to metadata_split.yaml, å·²ä¿å­˜åˆ° {OUTPUT_DIR}")

# ======================================================
# 8. SUMMARY
# ======================================================
def ratio_info(df_input, name):
    """
    è®¡ç®—å¹¶æ ¼å¼åŒ–æ•°æ®é›†çš„ç±»åˆ«æ¯”ä¾‹ä¿¡æ¯
    
    å‚æ•°:
        df_input: pandas.DataFrame - æ•°æ®æ¡†
        name: str - æ•°æ®é›†åç§°ï¼ˆå¦‚"Train"æˆ–"Test"ï¼‰
    
    è¿”å›:
        str - æ ¼å¼åŒ–çš„æ¯”ä¾‹ä¿¡æ¯å­—ç¬¦ä¸²
    """
    total = len(df_input)                 # æ€»æ ·æœ¬æ•°
    pos = df_input[LABEL_COL].sum()      # æ­£æ ·æœ¬æ•°ï¼ˆä¸¥é‡CRSï¼‰
    ratio = pos / total * 100             # æ­£æ ·æœ¬æ¯”ä¾‹
    return f"{name}: {pos}/{total} = {ratio:.2f}% positive"

# æ‰“å°ç±»åˆ«å¹³è¡¡æ€»ç»“
print("\nğŸ“Š ç±»åˆ«å¹³è¡¡æ€»ç»“:")
print(ratio_info(train_df, "Train"))
print(ratio_info(test_df, "Test"))

print(f"\nğŸ‰ æ•°æ®åˆ’åˆ†å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_DIR}")