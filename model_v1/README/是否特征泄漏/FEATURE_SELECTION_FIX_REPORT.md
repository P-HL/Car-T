# ğŸ”§ ç‰¹å¾é€‰æ‹©æ•°æ®æ³„éœ²ä¿®å¤æŠ¥å‘Š

## ğŸ“‹ é—®é¢˜è¯Šæ–­

### âŒ åŸå§‹é—®é¢˜
å•å…ƒæ ¼23çš„å•å˜é‡é€»è¾‘å›å½’ç‰¹å¾é€‰æ‹©å­˜åœ¨**ä¸¥é‡çš„æ•°æ®æ³„éœ²é—®é¢˜**ï¼š

```python
# åŸå§‹é”™è¯¯ä»£ç 
univariate_results = univariate_logistic_regression(X_train_df, y_train, feature_names)
sig_features_fdr = univariate_results[univariate_results['FDR_Significant']]['Feature'].tolist()
```

**é—®é¢˜åˆ†æ**ï¼š
1. ç‰¹å¾é€‰æ‹©åœ¨å…¨éƒ¨è®­ç»ƒæ•°æ®ï¼ˆX_train_df, y_trainï¼‰ä¸Šè¿›è¡Œ
2. è¿™å‘ç”Ÿåœ¨äº¤å‰éªŒè¯**ä¹‹å¤–**æˆ–**ä¹‹å‰**
3. é€‰å‡ºçš„ç‰¹å¾ä¼šè¢«ç”¨äºåç»­çš„CVæ¨¡å‹è®­ç»ƒ
4. **éªŒè¯é›†çš„ä¿¡æ¯é€šè¿‡å…¨æ•°æ®ç‰¹å¾é€‰æ‹©æ³„éœ²åˆ°äº†è®­ç»ƒè¿‡ç¨‹ä¸­**

### ğŸš¨ æ•°æ®æ³„éœ²è·¯å¾„

```
é”™è¯¯æµç¨‹ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. åœ¨å…¨éƒ¨X_trainä¸Šè¿›è¡Œå•å˜é‡é€»è¾‘å›å½’         â”‚  â† åŒ…å«äº†æœªæ¥éªŒè¯é›†çš„ä¿¡æ¯
â”‚    è®¡ç®—på€¼ã€FDRæ ¡æ­£                         â”‚
â”‚    â†’ å¾—åˆ° sig_features_fdr                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. ä½¿ç”¨è¿™äº›ç‰¹å¾è¿›å…¥äº¤å‰éªŒè¯ï¼š               â”‚
â”‚    for fold in CV:                         â”‚
â”‚      train_fold, val_fold = split()        â”‚  â† val_foldå·²å½±å“ç‰¹å¾é€‰æ‹©
â”‚      model.fit(train_fold[sig_features])   â”‚  â† è®­ç»ƒæ—¶ä½¿ç”¨äº†"çœ‹è¿‡"éªŒè¯é›†çš„ç‰¹å¾
â”‚      score = model.score(val_fold)         â”‚  â† è¯„åˆ†è¢«é«˜ä¼°
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**åæœ**ï¼š
- æ¨¡å‹æ€§èƒ½è¢«**é«˜ä¼°**
- æ³›åŒ–èƒ½åŠ›è¯„ä¼°**ä¸å‡†ç¡®**
- å¯èƒ½é€‰å‡º**ä¸ç¨³å®š/è¿‡æ‹Ÿåˆ**çš„ç‰¹å¾
- å¤–éƒ¨éªŒè¯æ€§èƒ½å¯èƒ½**æ˜¾è‘—ä¸‹é™**

---

## âœ… ä¿®å¤æ–¹æ¡ˆ

### æ ¸å¿ƒåŸåˆ™
**ç‰¹å¾é€‰æ‹©å¿…é¡»ä¸¥æ ¼åµŒå¥—åœ¨æ¯ä¸€æŠ˜äº¤å‰éªŒè¯çš„å†…éƒ¨**

### æ­£ç¡®æµç¨‹

```
æ­£ç¡®æµç¨‹ï¼ˆåµŒå¥—CVï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ for fold_idx, (train_idx, val_idx) in CV:  â”‚
â”‚                                             â”‚
â”‚   1. åˆ†å‰²æ•°æ®                               â”‚
â”‚      X_fold_train = X[train_idx]           â”‚
â”‚      X_fold_val = X[val_idx]               â”‚
â”‚                                             â”‚
â”‚   2. âœ… ä»…åœ¨è®­ç»ƒæŠ˜ä¸Šåšç‰¹å¾é€‰æ‹©              â”‚
â”‚      univariate_fold = analyze(            â”‚
â”‚          X_fold_train, y_fold_train)       â”‚  â† ä¸æ¥è§¦éªŒè¯æŠ˜
â”‚      sig_features_fold = select(...)       â”‚
â”‚                                             â”‚
â”‚   3. ä½¿ç”¨é€‰å‡ºçš„ç‰¹å¾è®­ç»ƒæ¨¡å‹                 â”‚
â”‚      model.fit(                            â”‚
â”‚          X_fold_train[sig_features_fold],  â”‚
â”‚          y_fold_train)                     â”‚
â”‚                                             â”‚
â”‚   4. åœ¨éªŒè¯æŠ˜ä¸Šè¯„ä¼°                         â”‚
â”‚      score = model.score(                  â”‚
â”‚          X_fold_val[sig_features_fold],    â”‚
â”‚          y_fold_val)                       â”‚  â† æ— æ³„éœ²çš„çœŸå®è¯„ä¼°
â”‚                                             â”‚
â”‚   5. è®°å½•æ¯æŠ˜çš„ç‰¹å¾é€‰æ‹©ç»“æœ                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¨ å…·ä½“ä¿®æ”¹

### ä¿®æ”¹çš„å•å…ƒæ ¼

#### 1. **å•å…ƒæ ¼23** - ä¸»è¦ç‰¹å¾é€‰æ‹©ä»£ç 
   - **åŸå†…å®¹**ï¼šåœ¨å…¨æ•°æ®ä¸Šè¿›è¡Œå•å˜é‡é€»è¾‘å›å½’
   - **æ–°å†…å®¹**ï¼šåµŒå¥—CVç‰¹å¾é€‰æ‹©
   - **å˜æ›´**ï¼šå®Œå…¨é‡å†™

#### 2. **å•å…ƒæ ¼24** - å¯è§†åŒ–ä»£ç 
   - **åŸå†…å®¹**ï¼šFDRæ ¡æ­£æ•ˆæœå¯è§†åŒ–
   - **æ–°å†…å®¹**ï¼šåµŒå¥—CVç»“æœåˆ†æå’Œç¨³å®šæ€§å¯è§†åŒ–
   - **å˜æ›´**ï¼šå®Œå…¨é‡å†™

#### 3. **æ–°å¢markdownå•å…ƒæ ¼**
   - æ’å…¥ä½ç½®ï¼šå•å…ƒæ ¼23ä¹‹å‰
   - å†…å®¹ï¼šè§£é‡Šä¿®æ”¹åŸå› å’Œä½¿ç”¨æ–¹æ³•

### æ–°åŠŸèƒ½ç‰¹æ€§

#### 1. **åµŒå¥—äº¤å‰éªŒè¯ç‰¹å¾é€‰æ‹©**
```python
# æ¯ä¸€æŠ˜ç‹¬ç«‹è¿›è¡Œç‰¹å¾é€‰æ‹©
for fold_idx, (train_idx, val_idx) in enumerate(cv_splitter.split(X_train_df, y_train), 1):
    X_fold_train = X_train_df.iloc[train_idx]
    y_fold_train = y_train.iloc[train_idx]
    
    # ä»…åœ¨è®­ç»ƒæŠ˜ä¸Šè¿›è¡Œåˆ†æ
    univariate_fold = univariate_logistic_regression(X_fold_train, y_fold_train, feature_names)
    univariate_fold = apply_fdr_correction(univariate_fold, alpha=FDR_ALPHA)
    
    # ä¿å­˜æ¯æŠ˜ç»“æœ
    univariate_results_cv[f'fold_{fold_idx}'] = univariate_fold
```

#### 2. **ç‰¹å¾ç¨³å®šæ€§åˆ†æ**
```python
# ç»Ÿè®¡æ¯ä¸ªç‰¹å¾åœ¨å„æŠ˜ä¸­è¢«é€‰ä¸­çš„é¢‘ç‡
for fold_name, features_dict in selected_features_cv.items():
    for method, features in features_dict.items():
        for feat in features:
            feature_selection_counts[method][feat] += 1

# è®¡ç®—ç¨³å®šæ€§åˆ†æ•°
feature_stability['FDR_q005_Stability'] = count / N_SPLITS
```

#### 3. **ç¨³å®šç‰¹å¾æ¨è**
```python
# åªæ¨èåœ¨å¤§å¤šæ•°æŠ˜ä¸­éƒ½æ˜¾è‘—çš„ç‰¹å¾
STABILITY_THRESHOLD = 0.6  # è‡³å°‘60%çš„æŠ˜

sig_features_fdr_stable = feature_stability[
    feature_stability['FDR_q005_Stability'] >= STABILITY_THRESHOLD
]['Feature'].tolist()
```

#### 4. **å…¨æ•°æ®é›†å‚è€ƒå¯¹æ¯”**
```python
# ä»…ç”¨äºå¯è§†åŒ–å¯¹æ¯”ï¼Œä¸ç”¨äºæ¨¡å‹è®­ç»ƒ
univariate_results_full = univariate_logistic_regression(X_train_df, y_train, feature_names)
# âš ï¸ è­¦å‘Šï¼šæ­¤ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸åº”ç”¨äºåç»­å»ºæ¨¡
```

---

## ğŸ“Š æ–°å¢å¯è§†åŒ–

ä¿®æ”¹åçš„å•å…ƒæ ¼24æä¾›6ä¸ªå…³é”®å›¾è¡¨ï¼š

1. **ç‰¹å¾ç¨³å®šæ€§æŸ±çŠ¶å›¾** - Top 20æœ€ç¨³å®šç‰¹å¾
2. **å„æŠ˜æ˜¾è‘—ç‰¹å¾æ•°é‡å¯¹æ¯”** - ç›‘æ§å„æŠ˜çš„ä¸€è‡´æ€§
3. **ç¨³å®šæ€§åˆ†å¸ƒç›´æ–¹å›¾** - æ•´ä½“ç¨³å®šæ€§æ¨¡å¼
4. **å…¨æ•°æ®é›† vs åµŒå¥—CVå¯¹æ¯”** - é‡åŒ–æ³„éœ²å½±å“
5. **è·¨æŠ˜på€¼ä¸€è‡´æ€§æ•£ç‚¹å›¾** - æ£€éªŒç»“æœå¯é‡å¤æ€§
6. **ç‰¹å¾é€‰æ‹©æ–¹æ³•åˆ†å¸ƒé¥¼å›¾** - æ¸…æ™°å±•ç¤ºç­›é€‰ç»“æœ

---

## ğŸ¯ ä½¿ç”¨å»ºè®®

### æ¨èä½¿ç”¨çš„ç‰¹å¾åˆ—è¡¨

| å˜é‡å | æè¿° | æ¨èåº¦ | ä½¿ç”¨åœºæ™¯ |
|--------|------|--------|----------|
| `sig_features_fdr` | FDR q<0.05 ä¸”ç¨³å®šæ€§â‰¥60% | â­â­â­â­â­ | **ä¸»è¦æ¨è**ï¼Œå¹³è¡¡ä¸¥æ ¼æ€§å’Œç‰¹å¾æ•°é‡ |
| `sig_features_fdr_01` | FDR q<0.1 ä¸”ç¨³å®šæ€§â‰¥60% | â­â­â­â­ | éœ€è¦æ›´å¤šç‰¹å¾æ—¶ä½¿ç”¨ |
| `sig_features_005` | p<0.05 ä¸”ç¨³å®šæ€§â‰¥60% | â­â­â­ | ä¸è€ƒè™‘å¤šé‡æ£€éªŒæ ¡æ­£æ—¶ |
| `sig_features_01` | p<0.1 ä¸”ç¨³å®šæ€§â‰¥60% | â­â­ | æ¢ç´¢æ€§åˆ†æ |

### è°ƒæ•´ç¨³å®šæ€§é˜ˆå€¼

```python
# æ›´ä¿å®ˆï¼ˆæ¨èï¼‰
STABILITY_THRESHOLD = 0.8  # éœ€åœ¨80%çš„æŠ˜ä¸­è¢«é€‰ä¸­

# æœ€ä¿å®ˆ
STABILITY_THRESHOLD = 1.0  # å¿…é¡»åœ¨æ‰€æœ‰æŠ˜ä¸­è¢«é€‰ä¸­

# æ›´å®½æ¾ï¼ˆä¸æ¨èï¼‰
STABILITY_THRESHOLD = 0.4  # ä»…éœ€40%çš„æŠ˜
```

### âš ï¸ é‡è¦è­¦å‘Š

```python
# âŒ ä¸è¦ä½¿ç”¨
univariate_results_full  # ä»…ä¾›å¯è§†åŒ–å‚è€ƒ
full_dataset_features    # æœ‰æ•°æ®æ³„éœ²é£é™©

# âœ… åº”è¯¥ä½¿ç”¨
sig_features_fdr         # åŸºäºåµŒå¥—CVçš„ç¨³å®šç‰¹å¾
feature_stability        # åŒ…å«å®Œæ•´ç¨³å®šæ€§ä¿¡æ¯
univariate_results_cv    # å„æŠ˜çš„è¯¦ç»†ç»“æœ
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### ä¿®å¤å‰ vs ä¿®å¤å

| æŒ‡æ ‡ | ä¿®å¤å‰ | ä¿®å¤å |
|------|--------|--------|
| æ•°æ®æ³„éœ²é£é™© | âš ï¸ é«˜ | âœ… æ—  |
| æ€§èƒ½è¯„ä¼°å‡†ç¡®æ€§ | âŒ è¢«é«˜ä¼° | âœ… çœŸå® |
| ç‰¹å¾ç¨³å®šæ€§ | â“ æœªçŸ¥ | âœ… å·²é‡åŒ– |
| å¤–éƒ¨éªŒè¯ä¸€è‡´æ€§ | âŒ å¯èƒ½å·®å¼‚å¤§ | âœ… æ›´ä¸€è‡´ |
| å¯é‡å¤æ€§ | âš ï¸ ä½ | âœ… é«˜ |

### é¢„æœŸå˜åŒ–

1. **é€‰å‡ºçš„ç‰¹å¾æ•°é‡å¯èƒ½å‡å°‘**
   - ä¿®å¤å‰ï¼šå¯èƒ½è¿‡åº¦ä¹è§‚ï¼Œé€‰å‡ºä¸ç¨³å®šç‰¹å¾
   - ä¿®å¤åï¼šåªä¿ç•™çœŸæ­£ç¨³å®šçš„ç‰¹å¾

2. **CVæ€§èƒ½å¯èƒ½ç•¥å¾®ä¸‹é™**
   - ä¿®å¤å‰ï¼šç”±äºæ³„éœ²ï¼Œæ€§èƒ½è¢«é«˜ä¼°
   - ä¿®å¤åï¼šçœŸå®æ€§èƒ½ï¼Œä½†æ›´å¯é 

3. **å¤–éƒ¨éªŒè¯æ€§èƒ½ä¸€è‡´æ€§æé«˜**
   - ä¿®å¤å‰ï¼šè®­ç»ƒ/éªŒè¯å·®å¼‚å¯èƒ½è¾ƒå¤§
   - ä¿®å¤åï¼šå·®å¼‚å‡å°ï¼Œæ›´å¯ä¿¡

---

## ğŸ” éªŒè¯ä¿®å¤æ•ˆæœ

### 1. æ£€æŸ¥ç¨³å®šæ€§ç»Ÿè®¡
```python
# æŸ¥çœ‹ç‰¹å¾ç¨³å®šæ€§åˆ†å¸ƒ
print(feature_stability['FDR_q005_Stability'].value_counts().sort_index())

# æœŸæœ›ï¼šå¤§å¤šæ•°æ˜¾è‘—ç‰¹å¾çš„ç¨³å®šæ€§è¾ƒé«˜ï¼ˆ>0.6ï¼‰
```

### 2. å¯¹æ¯”å…¨æ•°æ®é›†ç»“æœ
```python
# å¯¹æ¯”ç‰¹å¾æ•°é‡
full_features = (univariate_results_full['FDR_Significant']).sum()
nested_features = len(sig_features_fdr)

print(f"å…¨æ•°æ®é›†: {full_features} ä¸ª")
print(f"åµŒå¥—CV: {nested_features} ä¸ª")
print(f"å·®å¼‚: {full_features - nested_features} ä¸ª (å¯èƒ½æ˜¯ä¸ç¨³å®š/è¿‡æ‹Ÿåˆç‰¹å¾)")
```

### 3. æ£€æŸ¥å„æŠ˜ä¸€è‡´æ€§
```python
# å„æŠ˜é€‰å‡ºçš„ç‰¹å¾æ•°åº”è¯¥ç›¸å¯¹ç¨³å®š
fold_counts = [len(selected_features_cv[f'fold_{i}']['fdr_q005']) 
               for i in range(1, N_SPLITS+1)]
print(f"å„æŠ˜ç‰¹å¾æ•°: {fold_counts}")
print(f"æ ‡å‡†å·®: {np.std(fold_counts):.2f}")

# æœŸæœ›ï¼šæ ‡å‡†å·®è¾ƒå°ï¼Œè¯´æ˜é€‰æ‹©è¿‡ç¨‹ç¨³å®š
```

---

## ğŸ“ åç»­å·¥ä½œ

### 1. æ›´æ–°åç»­å»ºæ¨¡ä»£ç 
ç¡®ä¿åç»­æ‰€æœ‰æ¨¡å‹è®­ç»ƒä½¿ç”¨åµŒå¥—CVç‰¹å¾ï¼š

```python
# âœ… ä½¿ç”¨ä¿®å¤åçš„ç‰¹å¾
X_train_selected = X_train_df[sig_features_fdr]
X_test_selected = X_test_df[sig_features_fdr]

# ç»§ç»­è¿›è¡Œæ¨¡å‹è®­ç»ƒ...
```

### 2. é‡æ–°è¿è¡Œæ‰€æœ‰ä¾èµ–å•å…ƒæ ¼
ä¿®å¤åéœ€è¦é‡æ–°æ‰§è¡Œï¼š
- å•å…ƒæ ¼23ï¼šæ–°çš„ç‰¹å¾é€‰æ‹©ä»£ç 
- å•å…ƒæ ¼24ï¼šæ–°çš„å¯è§†åŒ–ä»£ç 
- åç»­æ‰€æœ‰ä½¿ç”¨ç‰¹å¾åˆ—è¡¨çš„ä»£ç 

### 3. æ›´æ–°æ–‡æ¡£å’ŒæŠ¥å‘Š
- æ›´æ–°æ–¹æ³•å­¦è¯´æ˜
- è¯´æ˜é‡‡ç”¨åµŒå¥—CVé¿å…æ•°æ®æ³„éœ²
- åœ¨è®ºæ–‡/æŠ¥å‘Šä¸­å¼•ç”¨ç›¸å…³æ–‡çŒ®

### 4. è€ƒè™‘å…¶ä»–ç‰¹å¾é€‰æ‹©æ–¹æ³•
å¦‚æœå…¶ä»–ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼ˆå¦‚LASSOã€Borutaã€RFEï¼‰ä¹Ÿå­˜åœ¨ï¼Œéœ€è¦åŒæ ·ä¿®å¤ï¼š

```python
# æ£€æŸ¥è¿™äº›æ–¹æ³•æ˜¯å¦ä¹Ÿéœ€è¦ä¿®å¤
# - æ¨¡å—3: LASSOå›å½’ç‰¹å¾é€‰æ‹©
# - æ¨¡å—4: L1é€»è¾‘å›å½’ç‰¹å¾é€‰æ‹©
# - æ¨¡å—5: Borutaç‰¹å¾é€‰æ‹©
# - æ¨¡å—6: RFEç‰¹å¾é€‰æ‹©
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### ç›¸å…³æ¦‚å¿µ
1. **æ•°æ®æ³„éœ² (Data Leakage)**: è®­ç»ƒè¿‡ç¨‹ä¸­æ„å¤–ä½¿ç”¨äº†æµ‹è¯•/éªŒè¯é›†ä¿¡æ¯
2. **åµŒå¥—äº¤å‰éªŒè¯ (Nested Cross-Validation)**: å°†ç‰¹å¾é€‰æ‹©/è¶…å‚æ•°ä¼˜åŒ–åµŒå…¥CVå†…éƒ¨
3. **ç‰¹å¾ç¨³å®šæ€§ (Feature Stability)**: ç‰¹å¾åœ¨ä¸åŒæ•°æ®å­é›†ä¸Šè¢«é€‰ä¸­çš„ä¸€è‡´æ€§

### æ¨èé˜…è¯»
- Cawley, G. C., & Talbot, N. L. (2010). "On over-fitting in model selection and subsequent selection bias in performance evaluation." JMLR.
- Varma, S., & Simon, R. (2006). "Bias in error estimation when using cross-validation for model selection." BMC Bioinformatics.
- Saeys, Y., et al. (2008). "Robust Feature Selection Using Ensemble Feature Selection Techniques." ECML PKDD.

---

## âœ… æ€»ç»“

### å…³é”®æ”¹è¿›
1. âœ… **æ¶ˆé™¤æ•°æ®æ³„éœ²**ï¼šç‰¹å¾é€‰æ‹©ä¸¥æ ¼åµŒå¥—åœ¨CVå†…éƒ¨
2. âœ… **é‡åŒ–ç¨³å®šæ€§**ï¼šæä¾›ç‰¹å¾åœ¨å„æŠ˜ä¸­çš„é€‰æ‹©é¢‘ç‡
3. âœ… **æ¨èç¨³å®šç‰¹å¾**ï¼šè‡ªåŠ¨ç­›é€‰é«˜ç¨³å®šæ€§ç‰¹å¾
4. âœ… **æä¾›å‚è€ƒå¯¹æ¯”**ï¼šå¯è§†åŒ–æ³„éœ²vsæ— æ³„éœ²çš„å·®å¼‚
5. âœ… **è¯¦ç»†æ–‡æ¡£**ï¼šå®Œæ•´çš„ä½¿ç”¨è¯´æ˜å’Œè­¦å‘Š

### æ ¸å¿ƒå˜é‡
```python
# â­ ä¸»è¦ä½¿ç”¨
sig_features_fdr          # æ¨èç‰¹å¾åˆ—è¡¨ï¼ˆFDR q<0.05ï¼Œç¨³å®šï¼‰
feature_stability         # å®Œæ•´ç¨³å®šæ€§åˆ†æ
univariate_results_cv     # å„æŠ˜è¯¦ç»†ç»“æœ

# ğŸ“Š è¾…åŠ©å‚è€ƒ
univariate_results_full   # å…¨æ•°æ®é›†å‚è€ƒï¼ˆä»…å¯è§†åŒ–ï¼‰
selected_features_cv      # å„æŠ˜é€‰æ‹©çš„ç‰¹å¾

# âš™ï¸ å¯è°ƒå‚æ•°
STABILITY_THRESHOLD       # ç¨³å®šæ€§é˜ˆå€¼ï¼ˆé»˜è®¤0.6ï¼‰
FDR_ALPHA                 # FDRæ§åˆ¶æ°´å¹³ï¼ˆé»˜è®¤0.05ï¼‰
N_SPLITS                  # CVæŠ˜æ•°ï¼ˆé»˜è®¤5ï¼‰
```

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨
1. âœ… è¿è¡Œä¿®æ”¹åçš„å•å…ƒæ ¼23å’Œ24
2. âš ï¸ æ£€æŸ¥è¾“å‡ºç»“æœå’Œç¨³å®šæ€§ç»Ÿè®¡
3. âš ï¸ ç¡®è®¤æ¨èç‰¹å¾åˆ—è¡¨åˆç†
4. âš ï¸ æ›´æ–°åç»­æ‰€æœ‰ä½¿ç”¨ç‰¹å¾çš„ä»£ç 
5. âš ï¸ é‡æ–°è®­ç»ƒå’Œè¯„ä¼°æ‰€æœ‰æ¨¡å‹

---

**ä¿®å¤æ—¥æœŸ**: 2026-01-24  
**ä¿®å¤ç‰ˆæœ¬**: v2.0 (åµŒå¥—CVç‰ˆæœ¬)  
**çŠ¶æ€**: âœ… å®Œæˆ
