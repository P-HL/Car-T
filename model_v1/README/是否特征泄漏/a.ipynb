{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2bf28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 模块 2: 嵌套CV的单变量逻辑回归特征选择（含FDR多重检验校正）\n",
    "# =============================================================================\n",
    "# ✅ 正确做法：特征选择严格嵌套在交叉验证内部\n",
    "# 流程：每一折 CV 内：仅在训练折上做特征选择 → 训练模型 → 在验证折上评估\n",
    "# \n",
    "# 作用：对每个特征独立进行逻辑回归，评估其与目标变量的关系，评估每个特征的边际显著性\n",
    "# 方法：在每一折CV内独立进行单变量分析，计算每个特征的 p 值、OR 值和置信区间，并进行FDR多重检验校正\n",
    "# 输入：X_train_df, y_train, feature_names (来自模块 1)\n",
    "# 输出：\n",
    "#   - univariate_results_cv: 每折的特征选择结果\n",
    "#   - feature_stability: 特征在各折中被选中的稳定性统计\n",
    "#   - univariate_results_full: 全数据集上的参考结果（仅用于可视化对比，不用于模型训练）\n",
    "# =============================================================================\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from statsmodels.stats.multitest import multipletests  # 用于FDR校正\n",
    "\n",
    "# 配置参数\n",
    "UNIVARIATE_P_THRESHOLD = 0.1      # 宽松阈值，用于初筛\n",
    "UNIVARIATE_P_STRICT = 0.05        # 严格阈值\n",
    "FDR_ALPHA = 0.05                  # FDR校正的显著性水平\n",
    "N_SPLITS = 5                      # 交叉验证折数\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"模块 2: 嵌套CV的单变量逻辑回归特征选择（含FDR校正）\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n✅ 采用正确的嵌套CV方法 - 避免数据泄露\")\n",
    "print(\"   每一折内独立进行特征选择，确保验证集不影响特征筛选过程\\n\")\n",
    "\n",
    "def univariate_logistic_regression(X_df, y, feature_names):\n",
    "    \"\"\"\n",
    "    对每个特征独立进行逻辑回归，返回系数、p值和OR值\n",
    "    \n",
    "    参数:\n",
    "        X_df: 特征 DataFrame (已标准化)\n",
    "        y: 目标变量\n",
    "        feature_names: 特征名列表\n",
    "    \n",
    "    返回:\n",
    "        DataFrame: 包含每个特征的统计信息\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    y_array = np.array(y).ravel()\n",
    "    \n",
    "    for i, col in enumerate(feature_names):\n",
    "        try:\n",
    "            X_single = X_df.iloc[:, i].values.reshape(-1, 1)\n",
    "            \n",
    "            # 检查特征是否有变异\n",
    "            if np.std(X_single) < 1e-10:\n",
    "                results.append({\n",
    "                    'Feature': col,\n",
    "                    'Coefficient': np.nan,\n",
    "                    'Std_Error': np.nan,\n",
    "                    'Z_Score': np.nan,\n",
    "                    'P_Value': 1.0,\n",
    "                    'OR': np.nan,\n",
    "                    'OR_CI_Lower': np.nan,\n",
    "                    'OR_CI_Upper': np.nan,\n",
    "                    'Significant_0.05': False,\n",
    "                    'Significant_0.1': False\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # 拟合逻辑回归（无正则化）\n",
    "            model = LogisticRegression(\n",
    "                penalty=None,\n",
    "                solver='lbfgs',\n",
    "                max_iter=1000,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X_single, y_array)\n",
    "            \n",
    "            coef = model.coef_[0][0]\n",
    "            \n",
    "            # 计算标准误和p值 (Wald 检验)\n",
    "            pred_proba = model.predict_proba(X_single)[:, 1]\n",
    "            pred_proba = np.clip(pred_proba, 1e-10, 1 - 1e-10)\n",
    "            \n",
    "            # Hessian 矩阵的对角元素\n",
    "            W = pred_proba * (1 - pred_proba)\n",
    "            \n",
    "            # 添加截距项\n",
    "            X_with_intercept = np.hstack([np.ones((X_single.shape[0], 1)), X_single])\n",
    "            \n",
    "            # Fisher 信息矩阵\n",
    "            fisher_info = X_with_intercept.T @ np.diag(W) @ X_with_intercept\n",
    "            \n",
    "            try:\n",
    "                cov_matrix = np.linalg.inv(fisher_info)\n",
    "                std_error = np.sqrt(cov_matrix[1, 1])\n",
    "            except np.linalg.LinAlgError:\n",
    "                std_error = np.nan\n",
    "            \n",
    "            # Wald z统计量和p值\n",
    "            if std_error > 0 and not np.isnan(std_error):\n",
    "                z_score = coef / std_error\n",
    "                p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "            else:\n",
    "                z_score = np.nan\n",
    "                p_value = 1.0\n",
    "            \n",
    "            # 计算 OR 和 95% CI\n",
    "            OR = np.exp(coef)\n",
    "            if not np.isnan(std_error):\n",
    "                OR_CI_lower = np.exp(coef - 1.96 * std_error)\n",
    "                OR_CI_upper = np.exp(coef + 1.96 * std_error)\n",
    "            else:\n",
    "                OR_CI_lower = np.nan\n",
    "                OR_CI_upper = np.nan\n",
    "            \n",
    "            results.append({\n",
    "                'Feature': col,\n",
    "                'Coefficient': coef,\n",
    "                'Std_Error': std_error,\n",
    "                'Z_Score': z_score,\n",
    "                'P_Value': p_value,\n",
    "                'OR': OR,\n",
    "                'OR_CI_Lower': OR_CI_lower,\n",
    "                'OR_CI_Upper': OR_CI_upper,\n",
    "                'Significant_0.05': p_value < 0.05,\n",
    "                'Significant_0.1': p_value < 0.1\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'Feature': col,\n",
    "                'Coefficient': np.nan,\n",
    "                'Std_Error': np.nan,\n",
    "                'Z_Score': np.nan,\n",
    "                'P_Value': 1.0,\n",
    "                'OR': np.nan,\n",
    "                'OR_CI_Lower': np.nan,\n",
    "                'OR_CI_Upper': np.nan,\n",
    "                'Significant_0.05': False,\n",
    "                'Significant_0.1': False\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def apply_fdr_correction(univariate_df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    对单变量分析结果应用FDR校正\n",
    "    \n",
    "    参数:\n",
    "        univariate_df: 单变量分析结果DataFrame\n",
    "        alpha: FDR控制水平\n",
    "    \n",
    "    返回:\n",
    "        DataFrame: 添加了FDR校正结果的DataFrame\n",
    "    \"\"\"\n",
    "    valid_p_values = univariate_df['P_Value'].fillna(1.0).values\n",
    "    \n",
    "    # 使用Benjamini-Hochberg方法进行FDR校正\n",
    "    reject, p_corrected, alphacSidak, alphacBonf = multipletests(\n",
    "        valid_p_values, \n",
    "        alpha=alpha, \n",
    "        method='fdr_bh'\n",
    "    )\n",
    "    \n",
    "    # 添加校正结果\n",
    "    result_df = univariate_df.copy()\n",
    "    result_df['P_Value_FDR'] = p_corrected\n",
    "    result_df['FDR_Significant'] = reject\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# =============================================================================\n",
    "# 交叉验证循环 - 在每一折内独立进行特征选择\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"步骤 2.1: 在交叉验证的每一折内独立进行特征选择\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 初始化交叉验证\n",
    "cv_splitter = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "# 存储每一折的特征选择结果\n",
    "univariate_results_cv = {}\n",
    "selected_features_cv = {}\n",
    "\n",
    "print(f\"\\n开始 {N_SPLITS} 折交叉验证特征选择...\\n\")\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(cv_splitter.split(X_train_df, y_train), 1):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  折 {fold_idx}/{N_SPLITS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 1. 分割数据（仅在训练折上进行特征选择）\n",
    "    X_fold_train = X_train_df.iloc[train_idx]\n",
    "    y_fold_train = y_train.iloc[train_idx]\n",
    "    X_fold_val = X_train_df.iloc[val_idx]\n",
    "    y_fold_val = y_train.iloc[val_idx]\n",
    "    \n",
    "    print(f\"  训练集样本数: {len(train_idx)}\")\n",
    "    print(f\"  验证集样本数: {len(val_idx)}\")\n",
    "    print(f\"  训练集正样本比例: {y_fold_train.mean():.2%}\")\n",
    "    print(f\"  验证集正样本比例: {y_fold_val.mean():.2%}\")\n",
    "    \n",
    "    # 2. ✅ 仅在训练折上进行单变量分析（不接触验证折）\n",
    "    print(f\"\\n  正在训练折上进行单变量逻辑回归...\")\n",
    "    univariate_fold = univariate_logistic_regression(\n",
    "        X_fold_train, \n",
    "        y_fold_train, \n",
    "        feature_names\n",
    "    )\n",
    "    \n",
    "    # 3. FDR校正\n",
    "    print(f\"  正在应用FDR校正...\")\n",
    "    univariate_fold = apply_fdr_correction(univariate_fold, alpha=FDR_ALPHA)\n",
    "    \n",
    "    # 按p值排序\n",
    "    univariate_fold = univariate_fold.sort_values('P_Value').reset_index(drop=True)\n",
    "    \n",
    "    # 4. 筛选显著特征\n",
    "    sig_features_fdr_fold = univariate_fold[\n",
    "        univariate_fold['FDR_Significant']\n",
    "    ]['Feature'].tolist()\n",
    "    \n",
    "    sig_features_fdr_01_fold = univariate_fold[\n",
    "        univariate_fold['P_Value_FDR'] < 0.1\n",
    "    ]['Feature'].tolist()\n",
    "    \n",
    "    sig_features_01_fold = univariate_fold[\n",
    "        univariate_fold['P_Value'] < UNIVARIATE_P_THRESHOLD\n",
    "    ]['Feature'].tolist()\n",
    "    \n",
    "    sig_features_005_fold = univariate_fold[\n",
    "        univariate_fold['P_Value'] < UNIVARIATE_P_STRICT\n",
    "    ]['Feature'].tolist()\n",
    "    \n",
    "    # 存储结果\n",
    "    univariate_results_cv[f'fold_{fold_idx}'] = univariate_fold\n",
    "    selected_features_cv[f'fold_{fold_idx}'] = {\n",
    "        'fdr_q005': sig_features_fdr_fold,\n",
    "        'fdr_q01': sig_features_fdr_01_fold,\n",
    "        'p01': sig_features_01_fold,\n",
    "        'p005': sig_features_005_fold\n",
    "    }\n",
    "    \n",
    "    # 输出统计\n",
    "    print(f\"\\n  折 {fold_idx} 特征选择结果:\")\n",
    "    print(f\"    - FDR q < 0.05: {len(sig_features_fdr_fold)} 个特征\")\n",
    "    print(f\"    - FDR q < 0.10: {len(sig_features_fdr_01_fold)} 个特征\")\n",
    "    print(f\"    - 原始 p < 0.05: {len(sig_features_005_fold)} 个特征\")\n",
    "    print(f\"    - 原始 p < 0.10: {len(sig_features_01_fold)} 个特征\")\n",
    "    \n",
    "    print(f\"  Top 5 特征:\")\n",
    "    display_cols = ['Feature', 'P_Value', 'P_Value_FDR', 'OR']\n",
    "    print(univariate_fold.head(5)[display_cols].to_string(index=False))\n",
    "    print()\n",
    "\n",
    "# =============================================================================\n",
    "# 步骤 2.2: 计算特征稳定性（在各折中被选中的频率）\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"步骤 2.2: 分析特征选择稳定性\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 统计每个特征在各折中被选中的次数\n",
    "feature_selection_counts = {\n",
    "    'fdr_q005': {},\n",
    "    'fdr_q01': {},\n",
    "    'p01': {},\n",
    "    'p005': {}\n",
    "}\n",
    "\n",
    "for fold_name, features_dict in selected_features_cv.items():\n",
    "    for method, features in features_dict.items():\n",
    "        for feat in features:\n",
    "            if feat not in feature_selection_counts[method]:\n",
    "                feature_selection_counts[method][feat] = 0\n",
    "            feature_selection_counts[method][feat] += 1\n",
    "\n",
    "# 创建稳定性DataFrame\n",
    "stability_data = []\n",
    "for feat in feature_names:\n",
    "    stability_data.append({\n",
    "        'Feature': feat,\n",
    "        'FDR_q005_Count': feature_selection_counts['fdr_q005'].get(feat, 0),\n",
    "        'FDR_q01_Count': feature_selection_counts['fdr_q01'].get(feat, 0),\n",
    "        'P01_Count': feature_selection_counts['p01'].get(feat, 0),\n",
    "        'P005_Count': feature_selection_counts['p005'].get(feat, 0),\n",
    "        'FDR_q005_Stability': feature_selection_counts['fdr_q005'].get(feat, 0) / N_SPLITS,\n",
    "        'FDR_q01_Stability': feature_selection_counts['fdr_q01'].get(feat, 0) / N_SPLITS,\n",
    "        'P01_Stability': feature_selection_counts['p01'].get(feat, 0) / N_SPLITS,\n",
    "        'P005_Stability': feature_selection_counts['p005'].get(feat, 0) / N_SPLITS\n",
    "    })\n",
    "\n",
    "feature_stability = pd.DataFrame(stability_data)\n",
    "feature_stability = feature_stability.sort_values('FDR_q005_Stability', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n特征稳定性统计 (按 FDR q<0.05 稳定性排序):\")\n",
    "print(f\"  - 总特征数: {len(feature_names)}\")\n",
    "print(f\"  - 在所有 {N_SPLITS} 折中都被选中的特征 (FDR q<0.05): {(feature_stability['FDR_q005_Stability'] == 1.0).sum()} 个\")\n",
    "print(f\"  - 在至少 {N_SPLITS-1} 折中被选中的特征 (FDR q<0.05): {(feature_stability['FDR_q005_Stability'] >= (N_SPLITS-1)/N_SPLITS).sum()} 个\")\n",
    "print(f\"  - 在至少 {N_SPLITS//2+1} 折中被选中的特征 (FDR q<0.05): {(feature_stability['FDR_q005_Stability'] > 0.5).sum()} 个\")\n",
    "\n",
    "print(f\"\\nTop 20 最稳定特征:\")\n",
    "display_cols = ['Feature', 'FDR_q005_Count', 'FDR_q005_Stability', 'FDR_q01_Count', 'P005_Count']\n",
    "print(feature_stability.head(20)[display_cols].to_string(index=False))\n",
    "\n",
    "# 保存稳定性结果\n",
    "stability_path = f\"{output_dir}/univariate_feature_stability_cv.csv\"\n",
    "feature_stability.to_csv(stability_path, index=False)\n",
    "print(f\"\\n✅ 特征稳定性结果已保存至: {stability_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 步骤 2.3: 生成推荐的特征列表（基于稳定性）\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"步骤 2.3: 基于稳定性生成推荐特征列表\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 推荐：选择在大多数折中都显著的特征\n",
    "STABILITY_THRESHOLD = 0.6  # 至少在60%的折中被选中\n",
    "\n",
    "sig_features_fdr_stable = feature_stability[\n",
    "    feature_stability['FDR_q005_Stability'] >= STABILITY_THRESHOLD\n",
    "]['Feature'].tolist()\n",
    "\n",
    "sig_features_fdr_01_stable = feature_stability[\n",
    "    feature_stability['FDR_q01_Stability'] >= STABILITY_THRESHOLD\n",
    "]['Feature'].tolist()\n",
    "\n",
    "sig_features_01_stable = feature_stability[\n",
    "    feature_stability['P01_Stability'] >= STABILITY_THRESHOLD\n",
    "]['Feature'].tolist()\n",
    "\n",
    "sig_features_005_stable = feature_stability[\n",
    "    feature_stability['P005_Stability'] >= STABILITY_THRESHOLD\n",
    "]['Feature'].tolist()\n",
    "\n",
    "print(f\"\\n✅ 推荐特征列表（稳定性阈值 >= {STABILITY_THRESHOLD:.0%}）:\")\n",
    "print(f\"  - sig_features_fdr (FDR q<0.05, 稳定): {len(sig_features_fdr_stable)} 个 ⭐推荐\")\n",
    "print(f\"  - sig_features_fdr_01 (FDR q<0.1, 稳定): {len(sig_features_fdr_01_stable)} 个\")\n",
    "print(f\"  - sig_features_005 (p<0.05, 稳定): {len(sig_features_005_stable)} 个\")\n",
    "print(f\"  - sig_features_01 (p<0.1, 稳定): {len(sig_features_01_stable)} 个\")\n",
    "\n",
    "# 使用稳定的FDR特征作为主要推荐\n",
    "sig_features_fdr = sig_features_fdr_stable\n",
    "sig_features_fdr_01 = sig_features_fdr_01_stable\n",
    "sig_features_005 = sig_features_005_stable\n",
    "sig_features_01 = sig_features_01_stable\n",
    "\n",
    "# =============================================================================\n",
    "# 步骤 2.4: 在全数据集上计算参考结果（仅用于可视化，不用于模型训练）\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"步骤 2.4: 计算全数据集参考结果（仅用于可视化对比）\")\n",
    "print(\"=\" * 80)\n",
    "print(\"⚠️  注意: 此结果仅用于可视化和理解，不应用于后续模型训练\")\n",
    "\n",
    "univariate_results_full = univariate_logistic_regression(X_train_df, y_train, feature_names)\n",
    "univariate_results_full = apply_fdr_correction(univariate_results_full, alpha=FDR_ALPHA)\n",
    "univariate_results_full = univariate_results_full.sort_values('P_Value').reset_index(drop=True)\n",
    "\n",
    "# 保存全数据集参考结果\n",
    "reference_path = f\"{output_dir}/univariate_logistic_results_reference.csv\"\n",
    "univariate_results_full.to_csv(reference_path, index=False)\n",
    "\n",
    "print(f\"\\n全数据集参考结果 (不用于训练):\")\n",
    "print(f\"  - FDR q < 0.05: {(univariate_results_full['FDR_Significant']).sum()} 个\")\n",
    "print(f\"  - FDR q < 0.10: {(univariate_results_full['P_Value_FDR'] < 0.1).sum()} 个\")\n",
    "print(f\"  - 原始 p < 0.05: {(univariate_results_full['P_Value'] < 0.05).sum()} 个\")\n",
    "print(f\"  - 原始 p < 0.10: {(univariate_results_full['P_Value'] < 0.1).sum()} 个\")\n",
    "\n",
    "print(f\"\\nTop 10 特征 (全数据集参考):\")\n",
    "display_cols = ['Feature', 'P_Value', 'P_Value_FDR', 'OR']\n",
    "print(univariate_results_full.head(10)[display_cols].to_string(index=False))\n",
    "\n",
    "print(f\"\\n✅ 参考结果已保存至: {reference_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 总结输出\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ 嵌套CV单变量逻辑回归特征选择完成\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n可用变量:\")\n",
    "print(f\"  - univariate_results_cv: 字典，包含每折的特征选择详细结果\")\n",
    "print(f\"  - selected_features_cv: 字典，包含每折选出的特征列表\")\n",
    "print(f\"  - feature_stability: DataFrame，特征在各折中的稳定性统计\")\n",
    "print(f\"  - sig_features_fdr: 稳定的 FDR q<0.05 特征 ({len(sig_features_fdr)} 个) ⭐推荐使用\")\n",
    "print(f\"  - sig_features_fdr_01: 稳定的 FDR q<0.1 特征 ({len(sig_features_fdr_01)} 个)\")\n",
    "print(f\"  - sig_features_005: 稳定的 p<0.05 特征 ({len(sig_features_005)} 个)\")\n",
    "print(f\"  - sig_features_01: 稳定的 p<0.1 特征 ({len(sig_features_01)} 个)\")\n",
    "print(f\"  - univariate_results_full: 全数据集参考结果 (仅用于可视化)\")\n",
    "\n",
    "print(f\"\\n⚠️  重要说明:\")\n",
    "print(f\"  1. 所有推荐特征列表基于嵌套CV结果，不存在数据泄露\")\n",
    "print(f\"  2. 推荐使用 sig_features_fdr (FDR q<0.05 且稳定性>={STABILITY_THRESHOLD:.0%})\")\n",
    "print(f\"  3. univariate_results_full 仅供参考，不应用于后续模型训练\")\n",
    "print(f\"  4. 后续建模时应使用 sig_features_fdr 等稳定特征列表\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 可视化：嵌套CV特征选择结果分析\n",
    "# =============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"嵌套CV特征选择结果可视化\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# ---------------------- 图1: 特征稳定性柱状图 ----------------------\n",
    "ax1 = axes[0, 0]\n",
    "\n",
    "# 选择Top 20最稳定的特征\n",
    "top_stable = feature_stability.head(20).copy()\n",
    "colors_stable = ['#2ecc71' if s >= STABILITY_THRESHOLD else '#e74c3c' \n",
    "                 for s in top_stable['FDR_q005_Stability']]\n",
    "\n",
    "bars = ax1.barh(range(len(top_stable)), top_stable['FDR_q005_Stability'], \n",
    "                color=colors_stable, edgecolor='black', linewidth=0.5)\n",
    "ax1.set_yticks(range(len(top_stable)))\n",
    "ax1.set_yticklabels(top_stable['Feature'], fontsize=9)\n",
    "ax1.invert_yaxis()\n",
    "ax1.axvline(x=STABILITY_THRESHOLD, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'稳定性阈值 ({STABILITY_THRESHOLD:.0%})')\n",
    "ax1.set_xlabel('稳定性 (被选中折数/总折数)', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Top 20 特征稳定性 (FDR q<0.05)', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# ---------------------- 图2: 各折显著特征数量对比 ----------------------\n",
    "ax2 = axes[0, 1]\n",
    "\n",
    "fold_stats = []\n",
    "for fold_idx in range(1, N_SPLITS + 1):\n",
    "    fold_features = selected_features_cv[f'fold_{fold_idx}']\n",
    "    fold_stats.append({\n",
    "        'Fold': f'折{fold_idx}',\n",
    "        'FDR q<0.05': len(fold_features['fdr_q005']),\n",
    "        'FDR q<0.1': len(fold_features['fdr_q01']),\n",
    "        'p<0.05': len(fold_features['p005']),\n",
    "        'p<0.1': len(fold_features['p01'])\n",
    "    })\n",
    "\n",
    "fold_stats_df = pd.DataFrame(fold_stats)\n",
    "x_pos = np.arange(len(fold_stats_df))\n",
    "width = 0.2\n",
    "\n",
    "bars1 = ax2.bar(x_pos - 1.5*width, fold_stats_df['FDR q<0.05'], width, \n",
    "                label='FDR q<0.05', color='#2ecc71', alpha=0.8)\n",
    "bars2 = ax2.bar(x_pos - 0.5*width, fold_stats_df['FDR q<0.1'], width, \n",
    "                label='FDR q<0.1', color='#58d68d', alpha=0.8)\n",
    "bars3 = ax2.bar(x_pos + 0.5*width, fold_stats_df['p<0.05'], width, \n",
    "                label='p<0.05', color='#3498db', alpha=0.8)\n",
    "bars4 = ax2.bar(x_pos + 1.5*width, fold_stats_df['p<0.1'], width, \n",
    "                label='p<0.1', color='#5dade2', alpha=0.8)\n",
    "\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(fold_stats_df['Fold'], fontsize=10)\n",
    "ax2.set_ylabel('显著特征数量', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('各折显著特征数量对比', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# ---------------------- 图3: 稳定性分布直方图 ----------------------\n",
    "ax3 = axes[0, 2]\n",
    "\n",
    "stability_values = feature_stability['FDR_q005_Stability'].values\n",
    "ax3.hist(stability_values, bins=np.arange(0, 1.1, 0.2), \n",
    "         color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(x=STABILITY_THRESHOLD, color='red', linestyle='--', linewidth=2,\n",
    "            label=f'阈值 ({STABILITY_THRESHOLD:.0%})')\n",
    "ax3.set_xlabel('稳定性分数', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('特征数量', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('特征稳定性分布 (FDR q<0.05)', fontsize=13, fontweight='bold')\n",
    "ax3.legend(fontsize=9)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# ---------------------- 图4: 全数据集 vs 嵌套CV对比 ----------------------\n",
    "ax4 = axes[1, 0]\n",
    "\n",
    "# 统计全数据集的显著特征数\n",
    "full_fdr_005 = (univariate_results_full['FDR_Significant']).sum()\n",
    "full_fdr_01 = (univariate_results_full['P_Value_FDR'] < 0.1).sum()\n",
    "full_p_005 = (univariate_results_full['P_Value'] < 0.05).sum()\n",
    "full_p_01 = (univariate_results_full['P_Value'] < 0.1).sum()\n",
    "\n",
    "comparison_data = pd.DataFrame({\n",
    "    '方法': ['全数据集\\n(有泄露风险)', '嵌套CV\\n(稳定特征)'],\n",
    "    'FDR q<0.05': [full_fdr_005, len(sig_features_fdr)],\n",
    "    'FDR q<0.1': [full_fdr_01, len(sig_features_fdr_01)],\n",
    "    'p<0.05': [full_p_005, len(sig_features_005)],\n",
    "    'p<0.1': [full_p_01, len(sig_features_01)]\n",
    "})\n",
    "\n",
    "x_pos_comp = np.arange(len(comparison_data))\n",
    "width_comp = 0.2\n",
    "\n",
    "bars1_comp = ax4.bar(x_pos_comp - 1.5*width_comp, comparison_data['FDR q<0.05'], width_comp, \n",
    "                     label='FDR q<0.05', color='#2ecc71', alpha=0.8)\n",
    "bars2_comp = ax4.bar(x_pos_comp - 0.5*width_comp, comparison_data['FDR q<0.1'], width_comp, \n",
    "                     label='FDR q<0.1', color='#58d68d', alpha=0.8)\n",
    "bars3_comp = ax4.bar(x_pos_comp + 0.5*width_comp, comparison_data['p<0.05'], width_comp, \n",
    "                     label='p<0.05', color='#3498db', alpha=0.8)\n",
    "bars4_comp = ax4.bar(x_pos_comp + 1.5*width_comp, comparison_data['p<0.1'], width_comp, \n",
    "                     label='p<0.1', color='#5dade2', alpha=0.8)\n",
    "\n",
    "ax4.set_xticks(x_pos_comp)\n",
    "ax4.set_xticklabels(comparison_data['方法'], fontsize=10)\n",
    "ax4.set_ylabel('特征数量', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('全数据集 vs 嵌套CV特征数量对比', fontsize=13, fontweight='bold')\n",
    "ax4.legend(fontsize=9)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 添加数值标签\n",
    "for bars in [bars1_comp, bars2_comp, bars3_comp, bars4_comp]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# ---------------------- 图5: 跨折p值一致性散点图 ----------------------\n",
    "ax5 = axes[1, 1]\n",
    "\n",
    "# 计算各折的平均p值\n",
    "fold_pvalues = []\n",
    "for fold_idx in range(1, N_SPLITS + 1):\n",
    "    fold_result = univariate_results_cv[f'fold_{fold_idx}']\n",
    "    fold_pvalues.append(fold_result.set_index('Feature')['P_Value'])\n",
    "\n",
    "# 创建p值矩阵\n",
    "pvalue_matrix = pd.concat(fold_pvalues, axis=1)\n",
    "pvalue_matrix.columns = [f'折{i}' for i in range(1, N_SPLITS+1)]\n",
    "\n",
    "# 计算平均p值和标准差\n",
    "pvalue_matrix['Mean'] = pvalue_matrix.mean(axis=1)\n",
    "pvalue_matrix['Std'] = pvalue_matrix.std(axis=1)\n",
    "\n",
    "# 绘制全数据集p值 vs 平均折p值\n",
    "full_pvalues = univariate_results_full.set_index('Feature')['P_Value']\n",
    "common_features = pvalue_matrix.index.intersection(full_pvalues.index)\n",
    "\n",
    "ax5.scatter(full_pvalues[common_features], \n",
    "           pvalue_matrix.loc[common_features, 'Mean'],\n",
    "           alpha=0.5, s=30, c='steelblue', edgecolors='black', linewidths=0.5)\n",
    "\n",
    "# 添加对角线\n",
    "max_p = max(full_pvalues[common_features].max(), pvalue_matrix.loc[common_features, 'Mean'].max())\n",
    "ax5.plot([0, max_p], [0, max_p], 'r--', linewidth=2, label='y=x', alpha=0.7)\n",
    "\n",
    "# 添加显著性阈值线\n",
    "ax5.axhline(y=0.05, color='green', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "ax5.axvline(x=0.05, color='green', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "\n",
    "ax5.set_xlabel('全数据集 P-Value', fontsize=11, fontweight='bold')\n",
    "ax5.set_ylabel('嵌套CV 平均 P-Value', fontsize=11, fontweight='bold')\n",
    "ax5.set_title('P值一致性: 全数据集 vs 嵌套CV', fontsize=13, fontweight='bold')\n",
    "ax5.legend(fontsize=9)\n",
    "ax5.grid(alpha=0.3)\n",
    "\n",
    "# ---------------------- 图6: 特征选择方法对比（饼图）----------------------\n",
    "ax6 = axes[1, 2]\n",
    "\n",
    "method_counts = [\n",
    "    len(sig_features_fdr),\n",
    "    len(sig_features_fdr_01) - len(sig_features_fdr),\n",
    "    len(feature_names) - len(sig_features_fdr_01)\n",
    "]\n",
    "\n",
    "colors_pie = ['#2ecc71', '#58d68d', '#95a5a6']\n",
    "labels_pie = [\n",
    "    f'FDR q<0.05\\n({len(sig_features_fdr)} 个)',\n",
    "    f'FDR 0.05<q<0.1\\n({method_counts[1]} 个)',\n",
    "    f'未选中\\n({method_counts[2]} 个)'\n",
    "]\n",
    "\n",
    "wedges, texts, autotexts = ax6.pie(method_counts, labels=labels_pie, colors=colors_pie,\n",
    "                                     autopct='%1.1f%%', startangle=90,\n",
    "                                     textprops={'fontsize': 10, 'fontweight': 'bold'})\n",
    "\n",
    "ax6.set_title('嵌套CV稳定特征分布', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图表\n",
    "cv_plot_path = f\"{output_dir}/univariate_nested_cv_analysis.png\"\n",
    "plt.savefig(cv_plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n✅ 嵌套CV分析可视化已保存至: {cv_plot_path}\")\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 输出详细统计\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"嵌套CV特征选择详细统计\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n1. 交叉验证配置:\")\n",
    "print(f\"   - 折数: {N_SPLITS}\")\n",
    "print(f\"   - FDR控制水平: α = {FDR_ALPHA}\")\n",
    "print(f\"   - 稳定性阈值: {STABILITY_THRESHOLD:.0%}\")\n",
    "\n",
    "print(f\"\\n2. 各折显著特征数 (FDR q<0.05):\")\n",
    "for fold_idx in range(1, N_SPLITS + 1):\n",
    "    n_features = len(selected_features_cv[f'fold_{fold_idx}']['fdr_q005'])\n",
    "    print(f\"   - 折 {fold_idx}: {n_features} 个\")\n",
    "\n",
    "print(f\"\\n3. 稳定特征统计 (FDR q<0.05):\")\n",
    "print(f\"   - 在所有折中都被选中: {(feature_stability['FDR_q005_Stability'] == 1.0).sum()} 个\")\n",
    "print(f\"   - 在至少 {N_SPLITS-1} 折中被选中: {(feature_stability['FDR_q005_Stability'] >= (N_SPLITS-1)/N_SPLITS).sum()} 个\")\n",
    "print(f\"   - 稳定性 >= {STABILITY_THRESHOLD:.0%}: {len(sig_features_fdr)} 个 ⭐推荐使用\")\n",
    "\n",
    "print(f\"\\n4. 全数据集 vs 嵌套CV对比:\")\n",
    "print(f\"   全数据集 (有泄露风险):\")\n",
    "print(f\"     - FDR q<0.05: {full_fdr_005} 个\")\n",
    "print(f\"     - FDR q<0.1: {full_fdr_01} 个\")\n",
    "print(f\"   嵌套CV (稳定特征, 无泄露):\")\n",
    "print(f\"     - FDR q<0.05稳定: {len(sig_features_fdr)} 个\")\n",
    "print(f\"     - FDR q<0.1稳定: {len(sig_features_fdr_01)} 个\")\n",
    "\n",
    "if full_fdr_005 > len(sig_features_fdr):\n",
    "    diff = full_fdr_005 - len(sig_features_fdr)\n",
    "    print(f\"\\n   ⚠️  全数据集方法可能包含 {diff} 个不稳定/过拟合特征\")\n",
    "    print(f\"   建议使用嵌套CV稳定特征，避免数据泄露\")\n",
    "\n",
    "print(f\"\\n5. 推荐特征列表:\")\n",
    "print(f\"   ✅ 主要推荐: sig_features_fdr ({len(sig_features_fdr)} 个)\")\n",
    "print(f\"      - 基于FDR q<0.05\")\n",
    "print(f\"      - 稳定性 >= {STABILITY_THRESHOLD:.0%}\")\n",
    "print(f\"      - 无数据泄露风险\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ 嵌套CV特征选择可视化完成\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
